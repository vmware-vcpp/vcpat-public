[{"id":0,"href":"/docs/cloud-infrastructure/","title":"Cloud Infrastructure","section":"Docs","content":"About Cloud Infrastructure #  The Cloud Infrastructure validated solution provides detailed design, implementation, configuration, and operation guidance for a workload domain that runs VMware Cloud Director tenant workloads in the Software-Defined Data Center (SDDC).\nA VMware validated solution is a technical validated implementation that is built and tested by VMware and VMware cloud providers to help customers resolve common business use cases. VMware validated solutions are cost-effective, performant, reliable, and secure. Each solution contains a detailed design, implementation, and operational guidance.\nAutomation for This Design in VMware Cloud Foundation #  The implementation tasks for some design decisions are automated by SDDC Manager. You must perform the implementation manually for the rest of the design decisions as noted in the design implication. To provide a fast and efficient path to automating the Cloud Infrastructure implementation, this document provides Microsoft PowerShell cmdlets as code-based alternatives to completing certain procedures in each SDDC component\u0026rsquo;s user interface. You can directly reuse the PowerShell commands by replacing the provided sample values with values from your VMware Cloud Foundation Planning and Preparation Workbook. Additonal automation is provided using Postman collections for API automation and Terraform workflows for VMware Cloud Director automation.\nIntended Audience #  The Cloud Infrastructure documentation is intended for Cloud Provider Architects and Administrators who are familiar with and want to use VMware software and the Cloud Infrastructure solution for VMware Cloud Foundation.\nSupport Matrix #  The Cloud Infrastructure validated solution is compatible with certain versions of the VMware products that are used for implementing the solution.\nSoftware Components in Cloud Infrastructure #     VMware Cloud Foundation Version Product Group Component Versions     4.5 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.5 Release Notes    Solution-added products VMware Cloud Director 10.4.1VMware vCloud Usage Meter 4.6VMware Chargeback (Formerly vRealize Operations Tenant App) 8.10RabbitMQ 3.8VMware Cloud Provider Lifecycle Manager 1.4    4.4.1 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.4.1 Release Notes    Solution-added products VMware Cloud Director 10.4VMware vCloud Usage Meter 4.5VMware vRealize Operations Tenant App for VMware Cloud Director 8.6RabbitMQ 3.8VMware Cloud Provider Lifecycle Manager 1.3    4.4.0 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.4 Release Notes.    Solution-added products VMware Cloud Director 10.3VMware vCloud Usage Meter 4.4VMware vRealize Operations Tenant App for VMware Cloud Director 2.6RabbitMQ 3.8VMware Cloud Provider Lifecycle Manager 1.3    4.3.1 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.3.1 Release Notes.    Solution-added products VMware Cloud Director 10.3VMware vCloud Usage Meter 4.5VMware vRealize Operations Tenant App for VMware Cloud Director 2.6RabbitMQ 3.8VMware Cloud Provider Lifecycle Manager 1.3    4.3.0 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.3 Release Notes.    Solution-added products VMware Cloud Director 10.3VMware vCloud Usage Meter 4.5VMware vRealize Operations Tenant App for VMware Cloud Director 2.6RabbitMQ 3.8VMware Cloud Provider Lifecycle Manager 1.3     Please refer the interoperability matrix for more information about the supported products of VMware Cloud Provider Lifecycle Manager\nBefore You Apply This Guidance #  To design and implement the Cloud Infrastructure validated solution, your environment must have a certain configuration.\nSupported VMware Cloud Foundation Deployment #     Workload Domain / Component Deployment Details     Management domain Automated deployment using VMware Cloud Builder.Availability of overlay-backed or VLAN-backed NSX segments in NSX-T Data Center for traffic in the same VMware Cloud Foundation instance and between VMware Cloud Foundation instances not required.\nSee the following VMware Cloud Foundation Documentation:\nFor information on deploying the management domain, see VMware Cloud Foundation Getting Started Guide and VMware Cloud Foundation Deployment Guide.For information on designing the management domain, see VMware Cloud Foundation Design Guide for the Management Domain.   One or more virtual infrastructure workload domains Automated deployment using SDDC Manager\nSee the following VMware Cloud Foundation Documentation:\nFor information on deploying the VI workload domains, see Getting Started with VMware Cloud Foundation and VMware Cloud Foundation Operations and Administration Guide.For information on designing a VI workload domain, see VMware Cloud Foundation Design Guide for a Virtual Infrastructure Workload Domain.   NSX Edge cluster Automated deployment using SDDC Manager\nSee the following VMware Cloud Foundation Documentation:\nFor information on deploying the NSX Edge cluster, see VMware Cloud Foundation Getting Started Guide and VMware Cloud Foundation Operations and Administration Guide.For information on designing the NSX Edge cluster, see VMware Cloud Foundation Design Guide for a Virtual Infrastructure Workload Domain.   vRealize Suite Lifecycle Manager and clustered Workspace ONE Access Automated deployment of vRealize Suite Lifecycle Manager by using SDDC ManagerAutomated deployment of the clustered Workspace ONE Access instance by using vRealize Suite Lifecycle Manager.\nSee the following VMware Cloud Foundation Documentation:\nFor information on deploying vRealize Suite Lifecycle Manager and the clustered Workspace ONE Access instance, see Getting Started with VMware Cloud Foundation and VMware Cloud Foundation Operations and Administration Guide.For information on designing vRealize Suite Lifecycle Manager and the clustered Workspace ONE Access instance, see Design for vRealize Suite Lifecycle and Access Management.   Identity and Access Management Manual configuration using Identity and Access Management for VMware Cloud Foundation VMware Validated Solution\nSee the following VMware Validated Solutions Documentation:\nFor detailed design, implementation, configuration, and operation guidance on the use of Active Directory as an identity provider and authentication source, and on the use of role-based access control (RBAC) in SDDC Manager, vCenter Server, ESXi, and NSX-T Data Center, see Identity and Access Management for VMware Cloud Foundation.   Advanced Load Balancing Manual deployment using Advanced Load Balancing for VMware Cloud Foundation VMware Validated Solution\nSee the following VMware Validated Solutions Documentation:\nFor detailed design, implementation, configuration, and operation guidance on the use of NSX Advanced Load Balancer as a Load Balancing solution for workloads on VMware Cloud Foundation, see Advanced Load Balancing for VMware Cloud Foundation.   Intelligent Operations Management Manual deployment using Intelligent Operations Management for VMware Cloud Foundation VMware Validated Solution\nSee the following VMware Validated Solutions Documentation:\nFor detailed design, implementation, configuration, and operation guidance on the use of VMware vRealize Operations for centralized monitoring and alerting through a single interface to review and act on events and alerts to deliver proactive management of system failures, see Intelligent Operations Management for VMware Cloud Foundation.   Intelligent Logging and Analytics Manual deployment using Intelligent Logging and Analytics for VMware Cloud Foundation VMware Validated Solution\nSee the following VMware Validated Solutions Documentation:\nFor detailed design, implementation, configuration, and operation guidance on the use of VMware vRealize Log Insight as a log analysis tool that delivers highly scalable log management with intuitive and actionable dashboards and sophisticated analytics, see Intelligent Logging and Analytics for VMware Cloud Foundation.    Overview of Cloud Infrastructure #  By applying the Cloud Infrastructure validated solution, you implement VMware Cloud Director, vRealize Operations Manager Tenant App, Usage Meter and RabbitMQ on VMware Cloud Foundation using VMware Cloud Provider Lifecycle Manager\nImplementation Overview of Cloud Infrastructure #     Stage Steps     1. Plan and prepare the VMware Cloud Foundation environment. Work with the technology team of your organization on configuring the physical servers, network, and storage in the data center. Collect the environment details and write them down in the VMware Cloud Foundation Planning and Preparation Workbook.   2. Deploy VMware Validated Solutions. Follow the design and deployment guidance to deploy the required VMware Validated Solutions described above.   3. Deploy VMware Cloud Provider Lifecycle Manager Configure Pre-requisites for deploying VMware Cloud Provider Lifecycle Manager Deploy Postman and download Postman collection for product deployment. Deploy VMware Cloud Provider Lifecycle Manager ApplianceSetup the NFS share for product binaries   4. Deploy the Cloud Infrastructure components Deploy and configure VMware Cloud Director.Deploy and configure VMware vCloud Usage Meter.Deploy and configure VMware vRealize TenantApp.Deploy and configure RabbitMQ.   5. Enable solution interoperability Integrate all Cloud Infrastructure components with Identity and Access Management servicesConfigure VMware Cloud Director for Advanced Load Balancing. Integrate all Cloud Infrastructure components with vRealize Operations Manager. Integrate all Cloud Infrastructure components with vRealize Log Insight.    6. Enable tenant workload provisioning. Configure Provider resources.Configure next step. Configure next step. Configure next step. Configure next step.    7. Onboard Tenants. Configure tenant resources.Configure next step. Configure next step. Configure next step. Configure next step.     Update History #  This Cloud Infrastructure solution is updated when necessary.\n   Revision Description     1. 31 MAY 2022 Draft content collection   2. 28 APR 2022 Revision 1 descriptionRevision 2 descriptionRevision 3 descriptionRevision 4 description   3. 29 MAR 2022 Revision 1 descriptionRevision 2 descriptionRevision 3 description    "},{"id":1,"href":"/docs/developer-ready-cloud/","title":"Developer Ready Cloud","section":"Docs","content":"About Developer Ready Cloud #  The Developer Ready Cloud validated solution provides detailed design, implementation, configuration, and operation guidance on \u0026hellip; A VMware validated solution is a technical validated implementation that is built and tested by VMware and VMware cloud providers to help customers resolve common business use cases. VMware validated solutions are cost-effective, performant, reliable, and secure. Each solution contains a detailed design, implementation, and operational guidance.\nAutomation for This Design in VMware Cloud Foundation #  The implementation tasks for some design decisions are automated by SDDC Manager. You must perform the implementation manually for the rest of the design decisions as noted in the design implication. To provide a fast and efficient path to automating the Developer Ready Cloud implementation, this document provides Microsoft PowerShell cmdlets as code-based alternatives to completing certain procedures in each SDDC component\u0026rsquo;s user interface. You can directly reuse the PowerShell commands by replacing the provided sample values with values from your VMware Cloud Foundation Planning and Preparation Workbook.\nIntended Audience #  The Developer Ready Cloud documentation is intended for cloud provider architects and administrators who are familiar with and want to use VMware software and a {VVS for CP topic} for VMware Cloud Foundation.\nSupport Matrix #  The Developer Ready Cloud validated solution is compatible with certain versions of the VMware products that are used for implementing the solution.\nSoftware Components in Developer Ready Cloud #     VMware Cloud Foundation Version Product Group Component Versions     4.4.1 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.4.1 Release Notes.    Solution-added products Product One 2.2.xProduct Two 3.4.x   4.4.0 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.4 Release Notes.    Solution-added products Product One 2.0.xProduct Two 3.3.x   4.3.1 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.3.1 Release Notes.    Solution-added products Product One 1.1.xProduct Two 3.2.x   4.3.0 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.3 Release Notes.    Solution-added products Product One 1.0.xProduct Two 3.1.x    Before You Apply This Guidance #  To design and implement the Developer Ready Cloud validated solution, your environment must have a certain configuration.\nSupported VMware Cloud Foundation Deployment #     Workload Domain Deployment Details     Management domain Automated deployment using VMware Cloud Builder.Availability of overlay-backed or VLAN-backed NSX segments in NSX-T Data Center for traffic in the same VMware Cloud Foundation instance and between VMware Cloud Foundation instances not required.\nSee the following VMware Cloud Foundation Documentation:\nFor information on deploying the management domain, see VMware Cloud Foundation Getting Started Guide and VMware Cloud Foundation Deployment Guide.For information on designing the management domain, see VMware Cloud Foundation Design Guide for the Management Domain.   (Optional) One or more virtual infrastructure workload domains Automated deployment using VMware Cloud Builder.\nSee the following VMware Cloud Foundation Documentation:\nFor information on deploying the management domain, see VMware Cloud Foundation Getting Started Guide and VMware Cloud Foundation Deployment Guide.For information on designing the management domain, see VMware Cloud Foundation Design Guide for the Management Domain.    Overview of Developer Ready Cloud #  By applying the Developer Ready Cloud validated solution, you implement {describe outcome}.\nImplementation Overview of Developer Ready Cloud #     Stage Steps     1. Stage one description Long form description of stage   2. Stage two description Step 1 descriptionStep 2 descriptionStep 3 descriptionStep 4 description   3. Stage three description Step 1 descriptionStep 2 descriptionStep 3 description    Update History #  This Developer Ready Cloud solution is updated when necessary.\n   Revision Description     1. 31 MAY 2022 Long form description of revision   2. 28 APR 2022 Revision 1 descriptionRevision 2 descriptionRevision 3 descriptionRevision 4 description   3. 29 MAR 2022 Revision 1 descriptionRevision 2 descriptionRevision 3 description    "},{"id":2,"href":"/docs/developer-ready-cloud/planning/","title":"Developer Ready Cloud Planning and Preparation","section":"Developer Ready Cloud","content":"Developer Ready CloudPlanning and Preparation #  Before you start implementing the components of the Developer Ready Cloud solution, you must set up an environment that has a specific compute, storage, and network configuration, and that provides external services to the components of the solution.\nUse the VMware Cloud Foundation Planning and Preparation Workbook to capture environment specific input values that are required during the implementation.\nCarefully review the VMware Cloud Foundation Planning and Preparation Workbook before implementation to avoid costly rework and delays. Capture input values that are specific to your environment and verify that the components that are required by this solution are available.\nThe VMware Cloud Foundation Planning and Preparation Workbook contains inputs for each implementation and configuration procedure. Reference your values from the VMware Cloud Foundation Planning and Preparation Workbook to complete UI or PowerShell procedures.\n#External Services You use services that are external to VMware Cloud Foundation when implementing the solution-name solution.\n   External Service Description     Active Directory (AD) Active Directory (AD) is used to provide authentication and authorization to the VMware Cloud Foundation infrastructure.\nThis includes dedicated Domain Users with least privilege access to act as service accounts for component connectivity.   Domain Name Services (DNS) Domain Name Services is used to ensure components are resolvable by FQDN and by IP address.   Network Time Protocol (NTP) Network Time Protocol is used to synchronize time consistently across components.   Certificate Authority (CA) Certificate Authority is used to provide signed certificates for user facing interfaces.    "},{"id":3,"href":"/docs/dr-migration/","title":"DR and Migration","section":"Docs","content":"About DR and Migration #  The DR and Migration validated solution provides detailed design, implementation, configuration, and operation guidance on how to properly utilize VMware Cloud Director Availability. A VMware validated solution is a technical validated implementation that is built and tested by VMware and VMware cloud providers to help customers resolve common business use cases. VMware validated solutions are cost-effective, performant, reliable, and secure. Each solution contains a detailed design, implementation, and operational guidance. to migrate workloads to the cloud, they may use the Migration workflow to simplify the process. When a “New Migration” is configured, VMware Cloud Director Availability starts replication of the vApp/VM from the source to the destination.\nAutomation for This Design in VMware Cloud Foundation #  The implementation tasks for some design decisions are automated by SDDC Manager. You must perform the implementation manually for the rest of the design decisions as noted in the design implication. Currently, there are no automation options for the deployment and configuration of VMware Cloud Director Availability, so the process needs to be performed manually.\nIntended Audience #  The DR and Migration documentation is intended for cloud provider architects and administrators who are familiar with VMware software and and want to support the offering of DR and migration services.\nSupport Matrix #  The DR and Migration validated solution is compatible with certain versions of the VMware products that are used for implementing the solution.\nSoftware Components in DR and Migration #     VMware Cloud Foundation Version Product Group Component Versions     4.4.1 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.4.1 Release Notes.    Solution-added products VMware Cloud Director Availability 4.4.1   4.4.0 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.4 Release Notes.    Solution-added products VMware Cloud Director Availability 4.4.1   4.3.1 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.3.1 Release Notes.    Solution-added products VMware Cloud Director Availability 4.4.1   4.3.0 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.3 Release Notes.    Solution-added products VMware Cloud Director Availability 4.4.1    Before You Apply This Guidance #  To design and implement the DR and Migration validated solution, your environment must have a certain configuration.\nSupported VMware Cloud Foundation Deployment #     Workload Domain Deployment Details     Management domain * Automated deployment using VMware Cloud Builder.\n* Availability of overlay-backed or VLAN-backed NSX segments in NSX-T Data Center for traffic in the same VMware Cloud Foundation instance and between VMware Cloud Foundation instances not required.\nSee the following VMware Cloud Foundation Documentation:\n* For information on deploying the management domain, see VMware Cloud Foundation Getting Started Guide and VMware Cloud Foundation Deployment Guide.\n* For information on designing the management domain, see VMware Cloud Foundation Design Guide for the Management Domain.   One or more virtual infrastructure workload domains * Automated deployment using VMware Cloud Builder.\nSee the following VMware Cloud Foundation Documentation:\n* For information on deploying the management domain, see VMware Cloud Foundation Getting Started Guide and VMware Cloud Foundation Deployment Guide.\n* For information on designing the management domain, see VMware Cloud Foundation Design Guide for the Management Domain.   NSX Edge cluster * Automated deployment using SDDC Manager\nSee the following VMware Cloud Foundation Documentation:\n* For information on deploying the NSX Edge cluster, see VMware Cloud Foundation Getting Started Guide and VMware Cloud Foundation Operations and Administration Guide.\n* For information on designing the NSX Edge cluster, see VMware Cloud Foundation Design Guide for a Virtual Infrastructure Workload Domain.   VMware Cloud Director * Deployed via VMware Cloud Provider Lifecycle Manager\nSee the Cloud Infrastructure Implementation for more information.     Overview of DR and Migration #  By applying the DR and Migration validated solution, you manually implement the 3 VMware Cloud Director Availability appliances:\n VMware Cloud Director Availability Cloud Replication Management appliance VMware Cloud Director Availability Cloud Replicator VMware Cloud Director Availability Cloud Tunnel  Implementation Overview of DR and Migration #     Stage Steps     1. Prerequisites check Validate whether the VMware Cloud Foundation environment is in place and VMware Cloud Director is already deployed.   2. Deploy the VMware Cloud Director Availability appliances 1. Deploy the VMware Cloud Director Availability Cloud Replication Management appliance in the Management Domain.\n2. Deploy the VMware Cloud Director Availability Cloud Tunnel appliance in the Management Domain.\n3. Deploy at least one VMware Cloud Director Availability Replicator appliance in each VI Workload domain. It is highly recommended to deploy at least 2 Cloud Replicators per VI Workload Domain.   3. Initial setup 1. Run the VMware Cloud Director Availability initial setup wizard where the license, site details, and VMware Cloud Director details are provided.\n2. Verify that the VMware Cloud Director Availability Plug-in for VMware Cloud Director is successfully deployed after the initial setup wizard is completed.\n3. (Optional) Configure additional network adapters for the appliances if needed.\n4. (Optional) Pair with other VMware Cloud Director Availability Cloud sites if present.   4. Tenant onboarding 1. Create and assign a replication policy to each tenant organization and customize their replication options.\n2. Create and assign SLA profiles to each tenant organization.\n3. Provide the VMware Cloud Director Availability On-Premises appliance bits and Organization Administrator credentials to each of the tenant organizations so they can pair their on-premises sites to the Cloud.    Update History #  This DR and Migration solution is updated when necessary.\n   Revision Description     1. 01 NOV 2022 Initial version of this solution is published.    "},{"id":4,"href":"/feedback/","title":"Feedback / Suggestions","section":"Welcome","content":"Feedback / Suggestions #  Would you have any feedback on the current content or some suggestions, please create a new discussion here.\n"},{"id":5,"href":"/docs/networking-security/","title":"Networking and Security","section":"Docs","content":"About Networking and Security #  The Networking and Security validated solution provides detailed design, implementation, configuration, and operation guidance on \u0026hellip; A VMware validated solution is a technical validated implementation that is built and tested by VMware and VMware cloud providers to help customers resolve common business use cases. VMware validated solutions are cost-effective, performant, reliable, and secure. Each solution contains a detailed design, implementation, and operational guidance.\nAutomation for This Design in VMware Cloud Foundation #  The implementation tasks for some design decisions are automated by SDDC Manager. You must perform the implementation manually for the rest of the design decisions as noted in the design implication. To provide a fast and efficient path to automating the Networking and Security implementation, this document provides Microsoft PowerShell cmdlets as code-based alternatives to completing certain procedures in each SDDC component\u0026rsquo;s user interface. You can directly reuse the PowerShell commands by replacing the provided sample values with values from your VMware Cloud Foundation Planning and Preparation Workbook.\nIntended Audience #  The Networking and Security documentation is intended for cloud provider architects and administrators who are familiar with and want to use VMware software and a {VVS for CP topic} for VMware Cloud Foundation.\nSupport Matrix #  The Networking and Security validated solution is compatible with certain versions of the VMware products that are used for implementing the solution.\nSoftware Components in Networking and Security #     VMware Cloud Foundation Version Product Group Component Versions     4.4.1 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.4.1 Release Notes.    Solution-added products Product One 2.2.xProduct Two 3.4.x   4.4.0 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.4 Release Notes.    Solution-added products Product One 2.0.xProduct Two 3.3.x   4.3.1 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.3.1 Release Notes.    Solution-added products Product One 1.1.xProduct Two 3.2.x   4.3.0 Products part of VMware Cloud Foundation See VMware Cloud Foundation 4.3 Release Notes.    Solution-added products Product One 1.0.xProduct Two 3.1.x    Before You Apply This Guidance #  To design and implement the Networking and Security validated solution, your environment must have a certain configuration.\nSupported VMware Cloud Foundation Deployment #     Workload Domain Deployment Details     Management domain Automated deployment using VMware Cloud Builder.Availability of overlay-backed or VLAN-backed NSX segments in NSX-T Data Center for traffic in the same VMware Cloud Foundation instance and between VMware Cloud Foundation instances not required.\nSee the following VMware Cloud Foundation Documentation:\nFor information on deploying the management domain, see VMware Cloud Foundation Getting Started Guide and VMware Cloud Foundation Deployment Guide.For information on designing the management domain, see VMware Cloud Foundation Design Guide for the Management Domain.   (Optional) One or more virtual infrastructure workload domains Automated deployment using VMware Cloud Builder.\nSee the following VMware Cloud Foundation Documentation:\nFor information on deploying the management domain, see VMware Cloud Foundation Getting Started Guide and VMware Cloud Foundation Deployment Guide.For information on designing the management domain, see VMware Cloud Foundation Design Guide for the Management Domain.    Overview of Networking and Security #  By applying the Networking and Security validated solution, you implement {describe outcome}.\nImplementation Overview of Networking and Security #     Stage Steps     1. Stage one description Long form description of stage   2. Stage two description Step 1 descriptionStep 2 descriptionStep 3 descriptionStep 4 description   3. Stage three description Step 1 descriptionStep 2 descriptionStep 3 description    Update History #  This Networking and Security solution is updated when necessary.\n   Revision Description     1. 31 MAY 2022 Long form description of revision   2. 28 APR 2022 Revision 1 descriptionRevision 2 descriptionRevision 3 descriptionRevision 4 description   3. 29 MAR 2022 Revision 1 descriptionRevision 2 descriptionRevision 3 description    Welcome! Here you can find suggestions on how to plan, set up and operate your networking and security services, either in a self-service mode, or via managed services.\nConfiguring VMware Cloud Director service for Load Balancing as a Service #  See the instructions below on how to deploy and configure VMware NSX Advanced Load Balancer in combination with VMware Cloud Director to provide Load Balancing as a Service capabitilies for end users.\n Load Balancing as a Service in VMware Cloud Director  "},{"id":6,"href":"/docs/sovereign-cloud/","title":"Sovereign Cloud","section":"Docs","content":"About Sovereign Cloud #  The Sovereign Cloud validated solution provides detailed design, implementation, configuration, and operational guidance on VMware Cloud Director with a single tenant SDDC. A VMware validated solution is a technical validated implementation that is built and tested by VMware and VMware cloud providers to help customers resolve common business use cases. VMware validated solutions are cost-effective, performant, reliable, and secure. Each solution contains a detailed design, implementation, and operational guidance.\nAutomation for This Design #  The automation of implementation tasks for some design decisions are provided. You must perform the implementation manually for the rest of the design decisions as noted in the design implication. To provide a fast and efficient path to automating the Sovereign Cloud implementation, this document provides reference to different cmdlets, shell scripts , or other automation based tools as code-based alternatives to completing certain procedures in configuring or implementing each component of the Sovereign Cloud. You can directly reuse these examples by replacing the provided sample values with values from your own environmental variables.\nIntended Audience #  The Sovereign Cloud documentation is intended for cloud provider architects and administrators who are familiar with and want to use VMware software and the VMware Sovereign Cloud solution for Cloud Providers.\nSupport Matrix #  The Sovereign Cloud validated solution is compatible with certain versions of the VMware products that are used for implementing the solution.\nSoftware Components in Sovereign Cloud #     Component Core/Optional Notes     VMware Cloud Foundation Core See Cloud Infrastructure Validated Solution for curent versions.   VMware vSAN Core This installs along with VMware Cloud Foundation. See Cloud Infrastructure Validated Solution for more information.   VMware NSX Core See Networking and Security Validated Solution for current versions.   VMware Cloud Director Core See Cloud Infrastructure Validated Solution for current version.   VMware Usage Meter Core See Cloud Infrastructure Validated Solution for current versions.   VMware Cloud Verified Certification Core See How to Achieve Cloud Verified for more information.    Before You Apply This Guidance #  To design and implement the Sovereign Cloud validated solution, your environment must have a certain configuration.\nSupported VMware Sovereign Cloud Deployment #     Component Component Details     VMware Validated Solution for Cloud Infrastructure This VVS should be implemented as a core requirement to allow for the proper configuration of a VMware Sovereign Cloud. Please see Cloud Infrastructure Validated Solution for this guidance.   VMware Validated Solution for Networking and Security The networking and secuirty VVS is a core component of the VMware Sovereign Cloud. However the final configuration of these components will be dictated by the design of the Sovereign Cloud requirements for the jurisdiction where it is deployed. Please see the Networking and Security Validated Solution to implement this component.   VMware Validated Solution for DR and Migration Having a validated Disaster Recovery and Migration strategy and implementation is critical for a successful Sovereign Cloud solution. This is a core component. Please refer to the DR and Migration section in this document to implemment this solution.   VMware Validated Solution for Developer Ready Cloud This component is optional, however, may in many cases be deemed as a core component and can be implemented by following the guidance in the Developer Ready Cloud section of this toolkit.    Overview of Sovereign Cloud #  By applying the Sovereign Cloud validated solution, you implement a highly secure, flexible, and efficient environment which will provide enforcement of data and workload residency, extend data sovereignty protections beyond the immediate platform where possible and to enable secure, audited connectivity and data transaction between resident, sovereign and non-sovereign data classifications.\nImplementation Overview of Sovereign Cloud #     Stage Steps     1. Plan and prepare the different default customer use cases for the Sovereign Cloud  Determine the jurisdictional policies that are applicable to your region/country.  Research and document how these policies will affect the design and implementation of the Sovereign Cloud.  Work with the architecture, security. and business teams to determine the different default use-cases that will be designed that will accomodate the jurisdictional requirments for the sovereign cloud.   2. Develop the design objectives and detailed design  Based on the determined use-cases, build out the design objectives that incorportate the compliance policies that are required for your jurisdiction. Document a detailed design for the implementation of the design objectives with a conceptual, logical, and physical design. This design will include considerations and requirements in order to result in a successful implementation.   3. Implement Design  Impleement all design requirements and considerations that are applicable to your environment and jurisdiction. Validate and test the implementation of the design to make sure all components still interoperate efficiently.    4. Onboard Tenants  Configure tenant environment and validate that all sovereign controls are functioning correctly. Onboard a production tenant as your first Sovereign Cloud customer.    Update History #  This Sovereign Cloud solution is updated when necessary.\n   Revision Description     1. 21 OCT 2022 Initial document configuration for Sovereign Cloud    "},{"id":7,"href":"/docs/cloud-director-service/","title":"VMware Cloud Director service","section":"Docs","content":"About VMware Cloud Director service #  VMware Cloud Director service is a cloud-service delivery application that uses an underlying infrastructure, such as the infrastructure provided by VMware Cloud on AWS, by Google Cloud VMware Engine, or by on-premises environments. By using the VMware Cloud Director service, service providers can deliver virtual infrastructure resources in a multitenant cloud environment.\nWith VMware Cloud Director service, cloud providers can build secure, multitenant clouds by pooling virtual infrastructure resources into virtual data centers. Cloud providers can then expose the clouds to users by using Web-based portals and programmatic interfaces as a fully automated, catalog-based service.\nIntended Audience #  The VMware Cloud Director service documentation is intended for Cloud Provider Architects and Administrators who are familiar with and want to use VMware software and the Cloud Infrastructure solution for VMware Cloud Foundation.\nSupport Matrix #  The VMware Cloud Director service solution is compatible with certain versions of the VMware and third party products that are used for implementing the solution.\nSoftware Components in VMware Cloud Director service #  VMware Cloud Director service is compatible with certain versions of VMware and third party products that are used for implementing the solution.\nPlease refer the interoperability matrix for more information about the supported products of VMware Cloud Director service.\nBefore You Apply This Guidance #  Before getting started with VMware Cloud Director service, you should complete the steps described here Before You Begin with VMware Cloud Director service.\nOverview of VMware Cloud Director service #  By applying the VMware Cloud Director solution, you implement VMware Cloud Director service, SDDC endpoint(s), and associate the SDDC endpoint to the VMware Cloud Director service instance.\nImplementation Overview of Cloud Infrastructure #     Stage Steps     1. Plan for the VMware Cloud Director service environment. VMware Cloud Director service decisions include what type of use case will the environment serve (product, disaster recovery), connectivity requirements from any on-prem services to the cloud provider and how many workloads you desire to support per SDDC. For details about the configuration maximums for VMware Cloud Director service see Configuration Maximums for VMware Cloud Director service.  Plan for your VMware Cloud on AWS SDDC Getting Started With VMware Cloud on AWS. Plan for your Google Cloud VMware Engine SDDC Google Cloud VMware Engine documentation. Plan for your Microsoft Azure VMware Solution SDDC Plan the Azure VMware Solution deployment.   2. Create VMware Cloud Director Service instance(s). Follow the deployment guidance to create required instance(s) How Do I Create a VMware Cloud Director Instance.   3. Deploy an SDDC Instance for VMware Cloud Director service to consume for tenants. To deploy a VMware Cloud on AWS SDDC instace, see Deploy an SDDC from the VMware Cloud Console To deploy a Google Cloud VMware Engine SDDC instance, first configure the provider project requirements per Configure the Provider Project, then create the SDDC Creating a VMware Engine private cloud. To deploy a Microsoft Azure VMware Solution SDDC instance, see Deploy and configure Azure VMware solution.   4. Associate VMware Cloud Director service instance with the SDDC. To associate a VMware Cloud on AWS SDDC, see How Do I Associate My VMware Cloud Director Instance with a VMware Cloud on AWS SDDC.To associate an Google Cloud VMware Engine, Azure VMware Solution, or on-premises SDDC, see How Do I Associate a VMware Cloud Director Instance with an SDDC via VMware Reverse Proxy.   5. Configure VMware Cloud Director service and Cloud Specific Networking. To configure VMware Cloud Director service with VMware Cloud on AWS networking, see Configure the External NetworkTo configure VMware Cloud Director service with Google Cloud VMware Engine, configure the required tenant projects per Configure the Tenant Project, then deploy and configure the required IPsec VPN tunnels per Deploy and Configure IPsec Tunnel To configure VMware Cloud Director service with Microsoft Azure VMware Solution, see Configure Network Connections.   6. Onboard Tenants. To onboard tenant organizations see Managing Organizations.To onboard organization virtual datacenters see Managing Organization Virtual Data Centers. To onboard tenant edge gateway see Add an Edge Gateway Backed by a NSX-T Data Center Tier-0 Gateway.    Update History #  This VMware Cloud Director service solution is updated when necessary.\n   Revision Description     1. 29 SEPTEMBER 2022 Draft content collection    "},{"id":8,"href":"/docs/dr-migration/attach-um-to-vcda/","title":"Add the VMware Cloud Director Availability Instance to Usage Meter","section":"DR and Migration","content":"Add the VMware Cloud Director Availability Instance to Usage Meter #  Prerequisites #   vCloud Usage Meter can connect to VMware Cloud Director Availability. You have the root credentials for the VMware Cloud Director Availability appliance. The VMware Cloud Director Availability certificate is FIPS compliant.  Procedure #   In the main menu bar of the vCloud Usage Meter Web interface, click Products. In the left navigation pane, click VMware Cloud Director Availability. On the VMware Cloud Director Availability page, click the Add. In the Endpoint text box, enter the host name or IP address of the VMware Cloud Director Availability Cloud Replication Management Appliance. In the Username and Password text boxes, enter the credentials of a VMware Cloud Director Availability root user. Click Add.  "},{"id":9,"href":"/docs/dr-migration/cloud-director-availability-metering/","title":"Cloud Director Availability Metering","section":"DR and Migration","content":"Cloud Director Availability Metering #  Usage Meter collects the number of all replications (migrations and protections) configured in VMware Cloud Director Availability during the month. The collection is performed on an hourly basis. Replications for both powered-on and powered-off VMs are counted. At the end of the month, the report shows the number of all the unique migrated VMs and all the unique protected VMs.\nPrerequisites #   vCloud Usage Meter can connect to VMware Cloud Director Availability. You have the root credentials for the VMware Cloud Director Availability appliance. The VMware Cloud Director Availability certificate is FIPS compliant.  Configuration #   In the main menu bar of the vCloud Usage Meter Web interface, click Products. In the left navigation pane, click VMware Cloud Director Availability. On the VMware Cloud Director Availability page, click the Add. In the Endpoint text box, enter the host name or IP address of your Cloud Replication Management Appliance. In the Username and Password text boxes, enter the credentials of a VMware Cloud Director Availability root user. Click Add.  Note: If you deploy vCloud Usage Meter in an external network and has no direct access to VMware Cloud Director Availability, Cloud Replication Management Appliance, or the vCenter Replication Management Appliance, as Endpoint, provide the Service Endpoint address. For Cloud Replication Management Appliance, set the Restrict Admin APIs by source IP configuration to Allow admin access from anywhere.\nIf the metering fails due to VMware Cloud Director Availability not being available or Usage Meter is not functioning, Usage Meter will report the last known \u0026ldquo;Protected VMs\u0026rdquo; count. This can lead to some replications not reported in the total number of unique replications for the month. If there is no successful collection during the month, VMware Cloud Director Availability usage will not be reported.\nMetered cases #   VMware Cloud Director Availability vCenter Cloud-to-vCenter Cloud Protections VMware Cloud Director Availability vCenter Cloud-to-vCenter Cloud Migrations VMware Cloud Director Availability vCenter Cloud-to-vCenter Protections VMware Cloud Director Availability vCenter Cloud-to-vCenter Migrations VMware Cloud Director Availability vCenter-to-vCenter Cloud Protections VMware Cloud Director Availability vCenter-to-vCenter Cloud Migrations  Reporting #  VMware Cloud Director Availability ™ reporting consists of:\n Disaster Recovery: The number of VMs under protection - 10 points per protected virtual machine per month. A protected VM is any virtual machine that is replicated from the primary site to the recovery site, regardless of whether the VM is powered on or off. Migration: The number of VMs configured for migration (no charge) - 0 points per migration. To be counted as migration, the workload replication must be configured by using the button “New migration” from the UI or by invoking an API call that sets the replication type to migration.  Please note that all usage should be reported to the following SKUs, regardless of the version in use:\n VMW-VCAN-CA-C – VMware Cloud Director Availability – Disaster Recovery VMW-VCAN-CA-MIG-C – VMware Cloud Director Availability – Migration  "},{"id":10,"href":"/docs/cloud-infrastructure/cloud-director-availability-metering/","title":"Cloud Director Availability Metering and Reporting","section":"Cloud Infrastructure","content":"Cloud Director Availability Metering and Reporting #  Usage Meter 4.5.0.1 can detect configured for protection or migration virtual machines using VMware Cloud Director Availability, where the source or destination is a replication-enabled VMware Cloud Director.\nConfiguration #  VMware Cloud Director Availability Management Appliance instance must be registered with Usage Meter by providing the appliance IP address or hostname and root credentials.\nFeature Detection #  Usage Meter collects the number of all replications (migrations and protections) during the month. The collection is performed on an hourly basis. Replications for both powered-on and powered-off VMs are counted. At the end of the month, the report shows the number of all the unique migrated VMs and all the unique protected VMs. Replications are reported in the following cases:\n Cloud-to-Cloud migrations and protection, where the registered VMware Cloud Director Availability is the destination vCenter-to-Cloud migrations and protection, where the registered VMware Cloud Director Availability is the destination Cloud-to-vCenter migrations and protections where the registered VMware Cloud Director Availability is the source  When Usage Meter fails to connect to a registered VMware Cloud Director Availability Management Appliance instance, the following actions are taken:\n The failure is logged in the Usage Meter log files An error message is shown on the Notifications page in the Usage Meter web application An email is sent to the defined Usage Meter admin email account If the metering fails due to VMware Cloud Director Availability not being available or Usage Meter is not functioning, Usage Meter will report the last known \u0026ldquo;Protected VMs\u0026rdquo; count. This can lead to some replications not being reported in the total number of unique replications for the month.  If there is no successful collection during the month, VMware Cloud Director Availability usage will not be reported.\nReporting #  A sample Monthly Usage Report for VMware Cloud Director Availability can be seen below.\n   Product Unit of Measure Units to be Reported     VMware Cloud Director Availability Cloud-to-Cloud Migrations Protected VMs 100   VMware Cloud Director Availability Cloud-to-Cloud Protections Protected VMs 200   VMware Cloud Director Availability Cloud-to-vCenter Migrations Protected VMs 75   VMware Cloud Director Availability Cloud-to-vCenter Protections Protected VMs 105   VMware Cloud Director Availability vCenter-to-Cloud Migrations Protected VMs 46   VMware Cloud Director Availability vCenter-to-Cloud Protections Protected VMs 27    "},{"id":11,"href":"/docs/cloud-infrastructure/cloud-director-metering/","title":"Cloud Director Metering and Reporting","section":"Cloud Infrastructure","content":"Cloud Director Metering and Reporting #  Configuration #  Usage meter collects product usage information from all VMware Cloud Director endpoints that are registered with Usage Meter. The Usage Meter administrator must configure the endpoint and credentials through the Usage Meter web application.\nFeature Detection #  Usage Meter calculates an Average Capped Billed vRAM (GB) value for all virtual machines managed by Cloud Director. Refer to the vCenter Server section for a detailed description of the Average Capped Billed vRAM formula. The different reservation models in VMware Cloud Director are only relevant if memory reservations are applied directly to the VM, not on resource pool level. When Usage Meter fails to connect to a registered Cloud Director instance, the following actions are taken:\n The failure is logged in the Usage Meter log An indication of the failure is shown on the Notifications page in the Usage Meter web application  "},{"id":12,"href":"/docs/cloud-infrastructure/cert-management/","title":"Cloud Infrastructure Certificate Management","section":"Cloud Infrastructure","content":"Cloud Infrastructure Certificate Management #  "},{"id":13,"href":"/docs/cloud-infrastructure/deployment-spec/","title":"Cloud Infrastructure Deployment Specification","section":"Cloud Infrastructure","content":"Cloud Infrastructure Deployment Specification #  "},{"id":14,"href":"/docs/developer-ready-cloud/deployment-spec/","title":"Cloud Infrastructure Deployment Specification","section":"Developer Ready Cloud","content":"Cloud Infrastructure Deployment Specification #  "},{"id":15,"href":"/docs/networking-security/deployment-spec/","title":"Cloud Infrastructure Deployment Specification","section":"Networking and Security","content":"Cloud Infrastructure Deployment Specification #  "},{"id":16,"href":"/docs/sovereign-cloud/deployment-spec/","title":"Cloud Infrastructure Deployment Specification","section":"Sovereign Cloud","content":"Cloud Infrastructure Deployment Specification #  "},{"id":17,"href":"/docs/cloud-infrastructure/design-decisions/","title":"Cloud Infrastructure Design Decisions","section":"Cloud Infrastructure","content":"Cloud Infrastructure Design Decisions #  NOTE: For each section below, use either a dedicated decision table for each component in the VVS or a single table with decisions for all components depending on the number of decisions listed. #  Deployment Model for Cloud Infrastructure #  Design Decisions for deploying VMware Cloud Director #     Design ID Design Decision Design Justification Design Implication     VCPLCM-VCD-001 Use VCD appliances instead of installing VCD binaries on Linux VMs. Linux-based deployment of VMware Cloud Director (VCD) isn’t supported by VMware Cloud Provider Lifecycle Manager (CPLCM).\nThe VVS for Cloud Providers recommends the use of a VMware Cloud Director virtual appliance.\nVCD appliances are the newest format for vCloud Director cells and are optimized to run VCD. They are easier to deploy and manage and easier to support and troubleshoot. VMware recommends the use of appliances instead of Linux cells.\nNo need for Linux licensing as the case in vCloud Director on Linux. No need for external database, as VCD appliances come with internal Postgres database. VCD appliances requirements must be considered when designing the primary pod and the associated management cluster.   VCPLCM-VCD-002 Deploy VMware Cloud Director as a cluster of five nodes in the default management vSphere cluster. VCD appliances host embedded Postgres database. Clustering these instances using five nodes, one primary + two stand-by + two application cells.\n5 cells would allow for hosting up to 10,000 VMs and 400 tenants. More resources are required in the management cluster associated with the primary pod.   VCPLCM-VCD-003 Protect the VMware Cloud Director cluster virtual machines by using vSphere High Availability. Supports the availability objectives for VMware Cloud Director without requiring manual intervention during an ESXi host failure event. None.   VCPLCM-VCD-004 Apply vSphere Distributed Resource Scheduler anti-affinity rules for the VMware Cloud Director cluster virtual machines. vSphere Distributed Resource Scheduler prevents the VMware Cloud Director cluster virtual machines from residing on the same ESXi host and risking the high availability of the deployment. You must perform an additional configuration to set up an anti-affinity rule.\nFor a default management vSphere cluster that consists of four ESXi hosts, you can put in maintenance mode only a single ESXi host at a time.   VCPLCM-VCD-005 Place the VMware Cloud Director cluster virtual machines in a designated virtual machine folder. Provides the organization of the VMware Cloud Director cluster virtual machines in the management domain vSphere inventory. You must create the virtual machine folder during or after the deployment.   VCPLCM-VCD-006 Use embedded Postgres database for VCD. The virtual appliance includes an embedded PostgreSQL database fully managed by VMware Cloud Director with built-in replication for maintaining consistency between cells. External database nodes can increase licensing costs and management overhead. Using embedded database will require a dedicated network for Postgres database replication. This affects management cluster networking design.   VCPLCM-VCD-007 A single NFS Mount Point will be used for each VCD cells group. The VMware Cloud Director appliance supports only NFS type of shared storage.\nThe appliance deployment process involves mounting the NFS shared transfer server storage.\nVCD cells requires this shared storage to store VCD cells group configuration files. VCD appliances can’t start if this storage is not available. This NFS share is also used as a temporary storage for uploads, downloads, and cloning operations across different VMware vCenter instances. Once the transfer operation is completed the data is deleted from the transfer storage.\nVMware Cloud Director stores the appliance database backups in the pgdb-backup directory in the transfer share. These backup bundles might consume significant space.\nThe multi-cell log bundle collector occupies this space.\nThe multi-cell log bundle collector occupies this space. NFS share is required to be available to be able to deploy VCD cells.   VCPLCM-VCD-008 Use vSAN File Services for the NFS share of VCD cells rather than external NFS share on Linux/Windows Virtual Machine Use NFS File Service Functionality.\nStarting with vSAN 7.0, you can use the vSAN File Service functionality to export NFS shares by using NFS 3.0 and NFS 4.1 protocols.\nIt’s easier to configure and manage. It has its limitations as that of NFS File share and supports SMB, NFSv3 and NFSv4.1 file shares.    \nDesign Decisions for deploying VMware Cloud Provider Lifecycle Manager #     Design ID Design Decision Design Justification Design Implication     VCPLCM-001 Deploy the latest version of VMware Cloud Provider Lifecycle Manager, i.e., 1.3 VMware Cloud Provider Lifecycle Manager 1.3 provides GUI feature, in addition to API and CLI and supports the latest products for deployment \u0026amp; management. N/A   VCPLCM-002 Deploy the latest VMware Provider Lifecycle Manager interop bundle. Interop Bundle contains definitions for new product interoperability and is made available whenever a new version of the supported product is released. Need to check for the latest interop bundle and download it manually in VMwaer Cloud Provider Lifecycle Manager host.   VCPLCM-003 In VMware Cloud Provider Lifecycle Manager, you can use various methods to deploy or manage products like CLI, API and GUI. In this design document, The API method is suggested. Use API to deploy VMware Cloud Director. API is a simplified method for the product deployment. Either an existing JSON containing the environment details can be used or can manually deploy the products. The data center feature automates the configuration of underline deployment infrastructure every time a product is deployed.\nOnce can refer the sample postman collection for the deployment of VMware Cloud Director\n Need to have a knowledge of API and understanding of JSON structure.   VCPLCM-004 Use vSAN FS rather than external NFS share on Linux/Windows Virtual Machine Configure the VMware Cloud Provider Lifecycle Manager repository on an NFS server configured externally as it reduces the risk of consuming space on the VMware Cloud Provider Lifecycle Manager server when more products get deployed and subsequent binaries are copied. Need to configure an NFS server    Design Decisions for deploying {VVS component 3} #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Integration of Cloud Infrastructure #  Design Decisions for integrating VMware Cloud Director with NSX-T and vCenter for VMware Cloud Foundation #     Design ID Design Decision Design Justification Design Implication     VCPLCM-CI-001 Deploy VMware Cloud Director on the management vCenter Server of VMware Cloud Foundation Easy to manage and configure as it comes bundled with VMware Cloud Foundation.\n N/A   VCPLCM-CI-002 Use NSX-T with comes bundled with VMware Cloud Foundation to integrate with VMware Cloud Director Easier to configure and manage.\nDeployed as a part of validated solution with VMware Cloud Foundation.\n N/A   VCPLCM-CI-003 Dedicate VI workloads domains vCenter for tenant workload consumption Resource Isolation\nResource constraints can be avoided as it can be scaled easily based on demand. N/A    Design Decisions for integrating VMware Cloud Director with RabbitMQ #     Design ID Design Decision Design Justification Design Implication     VCPLCM-CI-004 Deploy and Configure RabbitMQ for blocking tasks \u0026amp; notifications. \nIf you want to use blocking tasks, notifications, or VMware Cloud Director API extensions, like Container Service Extension (CSE) and VMware Cloud Director App Launchpad, you need to install and configure a RabbitMQ AMQP Broker. Need to deploy and manage RabbitMQ    Design Decisions for integrating {VVS component 3} #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Isolation Model for Cloud Infrastructure #  Design Decisions for creating Tenants {VVS component 1} #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP1-001 Decision comment Justification comments Implication comments   VVS-COMP1-002 Decision comment Justification comments Implication comments   VVS-COMP1-002 Decision comment Justification comments Implication comments    Design Decisions for creating Tenants {VVS component 2} #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP2-001 Decision comment Justification comments Implication comments   VVS-COMP2-002 Decision comment Justification comments Implication comments   VVS-COMP2-002 Decision comment Justification comments Implication comments    Design Decisions for creating Tenants in {VVS component 3} #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Physical Design of the Cloud Infrastructure #  Design Decisions for Physical Design of ESXi Hosts to support Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP1-001 Decision comment Justification comments Implication comments   VVS-COMP1-002 Decision comment Justification comments Implication comments   VVS-COMP1-002 Decision comment Justification comments Implication comments    vCenter Design for the Cloud Infrastructure #  Design Decisions for the Virtual Infrastructure to support Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP2-001 Decision comment Justification comments Implication comments   VVS-COMP2-002 Decision comment Justification comments Implication comments   VVS-COMP2-002 Decision comment Justification comments Implication comments    vCenter Server Design for the Cloud Infrastructure #  Design Decisions for vCenter Server Access Control for Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP2-001 Decision comment Justification comments Implication comments   VVS-COMP2-002 Decision comment Justification comments Implication comments   VVS-COMP2-002 Decision comment Justification comments Implication comments    NSX Design for the Cloud Infrastructure #  Design Decisions for NSX Access Control for Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Design Decisions for NSX Distributed Firewall Rules for Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Licensing the Cloud Infrastructure #  Design Decisions for licensing Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    NSX Design for the Cloud Infrastructure #  Design Decisions for creating Tenants Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    How to size the Cloud Infrastructure #  Design Decisions for sizing {VVS component 1} for the Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Design Decisions for sizing {VVS component 2} for the Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Design Decisions for sizing {VVS component 3} for the Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Network Design for the Cloud Infrastructure #  Design Decisions for the Networking Design for Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Design Decisions for the IP Addressing Scheme for Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Design Decisions for the Time Synchronization for Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Lifecycle Management for the Cloud Infrastructure #  Design Decisions for Lifecycle Management of the Cloud Infrastructure #     Design ID Design Decision Design Justification Design Implication     VCPLCM-VCD-009 Use VMware Cloud Provider Lifecycle Manager for Lifecycle Management of VMware Cloud Director, Usage Meterand vRealize Operations Manager Tenant App VMware Cloud Provider Lifecycle Manager can help upgrade VMware Cloud Director, Usage Meter, vRealize Operations Manager Tenant App with the expection of RabbitMQ You must deploy VMware Cloud Provider Lifecycle Manager in your invironment.   VCPLCM-VCD-0010 Use VMware Cloud Provider Lifecycle Manager for Lifecycle Management of VMware Cloud Director, Usage Meter, RabbitMQ and vRealize Operations Manager Tenant App Below Day-2 Operations can be performed using VMware Cloud Provider Lifecycle Manager\nCertificate amanagement: Add and Update product Certificates\nNode management- Add, delete a node and updating node properties like CPU and memory. VMware Cloud Provider Lifecycle Manager needs to be deployed first.    Information Security and Access of the Cloud Infrastructure #  Design Decisions for Information Security and Access of the Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Monitoring and Alerting of the Cloud Infrastructure #  Design Decisions for Monitoring and Alerting for Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    Data Protection of the Cloud Infrastructure #  Design Decisions for Data Protection of Cloud Infrastructure #     Decision ID Design Decision Design Justification Design Implications     VVS-COMP3-001 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments   VVS-COMP3-002 Decision comment Justification comments Implication comments    "},{"id":18,"href":"/docs/cloud-infrastructure/design/","title":"Cloud Infrastructure Design Objectives","section":"Cloud Infrastructure","content":"Cloud Infrastructure Design Objectives #  The deployment of VMware Cloud Director on VMware Cloud Foundation using VMware Cloud Provider Lifecycle Manager validated solution has objectives to deliver prescriptive content about the solution so that it is fast to deploy and is suitable for use in production environments.\n   Objective Description     Main Objective Provide enterprise-grade validated VMware Cloud Director infrastructure on VMware Cloud Foundation deployed by VMware Cloud Provider Lifecycle Manager   VMware Cloud Foundation Architecture Support vSAN Ready Nodes Standard\nSingle VMware Cloud Foundation Instance\n VxRail Nodes Standard\n Single VMware Cloud Foundation Instance    Scope of Implementation VMware Cloud Provider Lifecycle Manager\n Appliance based deployment\nConfiguration of NFS share for VMware Cloud Provider Lifecycle Manager\n  vSAN FS – 100GB Size\nVMware Cloud Director\n 5 Node Deployment (1 Primary + 2 Standby +2 Application)\n Single Site\n Appliance Based  Large sized cell deployment\nConfiguration of NFS for VMware Cloud Director\nvSAN File System Configuration of NSX for VMware Cloud Director\n Deploy and configure NSX-T Data Center for VMware Cloud Director\nUsage Meter\nAppliance deployment\nvRealize Operations Manager Tenant App\nAppliance based deplioyment\nNode details to be updated Note: As a part of pre-requisites vRealize Operations needs to be deployed and pre-configured for vROPS TA to use.VMware Cloud Provider Lifecycle Manager doesn\u0026rsquo;t support deployment of vRealize Operations Manager.\nRabbitMQ\n Linux based deployment\n 2 Node Deployment    Workload Domain Type Support  Management workload domain  Virtual Infrastructure (VI) workload domains.   Scope of guidance Detailed design for solution components.\nImplementation\nOperational Guidance\nSolution Interoperability\nDeployment of VMware Cloud Provider Lifecycle Manager\nDeployment of VMware Cloud Director, Usage Meter, vRealize Operations Manager Tenant App and RabbitMQ on VMware Cloud Foundation using VMware Cloud Provider Lifecycle Manager   Cloud Type Private Cloud   Tenancy Multi-Tenant   Load Balancing NSX Advanced Load Balancer (Avi)   Availability 99%   Certificate Signing Certificates are signed by a certificate authority (CA) that consists of a root and intermediate certificate authority layers    "},{"id":19,"href":"/docs/cloud-infrastructure/detailed-design/","title":"Cloud Infrastructure Detailed Design","section":"Cloud Infrastructure","content":"Cloud Infrastructure Detailed Design #  The Cloud Infrastructure validated solution uses VMware Cloud Director, Usage Meter, vRealize Operations Manager Tenant App, RabbitMQ and VMware Cloud Provider Lifecycle Manager deployed on top of а VMware Cloud Foundation VI workload domain to build an hybrid cloud environment.\nLogical Design for Cloud Infrastructure #  The logical design consists of multiple elements that enable you to deploy and manage infrastructure used for setting up a robust Cloud Infrastructure based on VMware Cloud Director.[Read more]\nDeployment Specification for Cloud Infrastructure #  When {VVS Product} is enabled on \u0026hellip; [Read more]\nNetwork Design for Cloud Infrastructure #  The Cloud Infrastructure requires multiple networks. This section discusses networking design not covered in the NSX-T Data Center detailed design. [Read more]\nLifecycle Management for Cloud Infrastructure #  Lifecycle Management design details the decisions for lifecycle management of the products which are included in Cloud Infrastructure like VMware Cloud Director, Usage Meter, RabbitMQ and vRealize Operations Manager Tenant App using VMware Cloud Provider Lifecycle Manager. [Read more]\nUsage Meter Design for Cloud Infrastructure #  VMware vCloud Usage Meter statement of purpose in an instance of {VVS Product}. [Read more]\nTenant App Design for Cloud Infrastructure #  VMware vRealize Tenant App statement of purpose in an instance of {VVS Product}. [Read more]\nRabbitMQ Design for Cloud Infrastructure #  RabbitMQ statement of purpose in an instance of {VVS Product}. [Read more]\nInformation Security and Access for Cloud Infrastructure #  You design authentication access, controls, and certificate management for the products in Cloud Infrastructure according to industry standards and the requirements of your organization. [Read more]\n"},{"id":20,"href":"/docs/cloud-infrastructure/implementation/","title":"Cloud Infrastructure Implementation","section":"Cloud Infrastructure","content":"Cloud Infrastructure Implementation #  Implementing VMware Cloud Provider Lifecycle Manager validated solution includes deployment of Appliance and setting up the product binary.\nTo deploy and configure VMware Cloud Provider Lifecycle Manager, please follow VMware Documentation\nThis guidance provides a prescriptive path for deploying VMware Cloud Director, vRealize Operations Manager Tenant App, Usage Meter and RabbitMQ using API feature of VMware Cloud Provider Lifecycle Manager in a management domain of VMware Cloud Foundation . For more information on other deployment options, refer the VMware documentation.\nPrerequisites #   Verify that your environment is configured according to Before You Apply This Guidance and the Developer Ready Infrastructure tab of the VMware Cloud Foundation Planning and Preparation Workbook. If you want to use the included Microsoft PowerShell cmdlets to perform implementation and configuration procedures, verify that your system fulfils the following prerequisites.  Verify that your system has Microsoft PowerShell 5.1 installed. See Microsoft PowerShell. Install the PowerValidatedSolutions PowerShell module together with the supporting modules from the PowerShell Gallery by running the following commands. Install-Module -Name VMware.PowerCLI -MinimumVersion 12.4.1 Install-Module -Name VMware.vSphere.SsoAdmin -MinimumVersion 1.3.7 Install-Module -Name ImportExcel -MinimumVersion 7.1.1 Install-Module -Name PowerVCF -MinimumVersion 2.2.0 Install-Module -Name PowerValidatedSolutions -MinimumVersion 1.7.0  Import the PowerValidatedSolutions and the PowerCLI PowerShell modules by running the following commands. Import-Module -Name VMware.PowerCLI -MinimumVersion 12.4.1 Import-Module -Name PowerValidatedSolutions -MinimumVersion 1.7.0    Verify that your environment is configured according to Before You Apply This Guidance Download Postman 9.x if you want to use the postman collection for the deployment and management of the above mentioned products.  Procedure #    Deploy and configure VMware Cloud Provider Lifecycle Manager The following secion describes the procedutre to deploy and configure VMware Cloud Provider Lifecycle Manager. Read more\n  Deploy VMware Cloud Director using VMware Cloud Provider Lifecycle Manager  The below secion explains the deployment procedure of VMware Cloud Director using API functionality VMware Cloud Provider Lifecycle Manager Read more\n  Deploy vRealize Operations Tenant App(vROPS TA) using VMware Cloud Provider Lifecycle Manager\nThe below secion explains the deployment procedure of vROPS TA using API functionality VMware Cloud Provider Lifecycle Manager Read more\n  Deploy Usage Meter using VMware Cloud Provider Lifecycle Manager The below secion explains the deployment procedure of Usage Meter using API functionality VMware Cloud Provider Lifecycle Manager Read more\n  Deploy RabbitMQ using VMware Cloud Provider Lifecycle Manager The below secion explains the deployment procedure of RabbitMQ using API functionality VMware Cloud Provider Lifecycle Manager Read more\n  "},{"id":21,"href":"/docs/cloud-infrastructure/info-sec-access/","title":"Cloud Infrastructure Information Security and Access","section":"Cloud Infrastructure","content":"Cloud Infrastructure Information Security and Access #  "},{"id":22,"href":"/docs/developer-ready-cloud/info-sec-access/","title":"Cloud Infrastructure Information Security and Access","section":"Developer Ready Cloud","content":"Cloud Infrastructure Information Security and Access #  "},{"id":23,"href":"/docs/networking-security/info-sec-access/","title":"Cloud Infrastructure Information Security and Access","section":"Networking and Security","content":"Cloud Infrastructure Information Security and Access #  "},{"id":24,"href":"/docs/sovereign-cloud/info-sec-access/","title":"Cloud Infrastructure Information Security and Access","section":"Sovereign Cloud","content":"Cloud Infrastructure Information Security and Access #  "},{"id":25,"href":"/docs/cloud-infrastructure/lifecycle-mgmt/","title":"Cloud Infrastructure Lifecycle Management","section":"Cloud Infrastructure","content":"Cloud Infrastructure Lifecycle Management #  "},{"id":26,"href":"/docs/developer-ready-cloud/lifecycle-mgmt/","title":"Cloud Infrastructure Lifecycle Management","section":"Developer Ready Cloud","content":"Cloud Infrastructure Lifecycle Management #  "},{"id":27,"href":"/docs/networking-security/lifecycle-mgmt/","title":"Cloud Infrastructure Lifecycle Management","section":"Networking and Security","content":"Cloud Infrastructure Lifecycle Management #  "},{"id":28,"href":"/docs/sovereign-cloud/lifecycle-mgmt/","title":"Cloud Infrastructure Lifecycle Management","section":"Sovereign Cloud","content":"Cloud Infrastructure Lifecycle Management #  "},{"id":29,"href":"/docs/cloud-infrastructure/logical-design/","title":"Cloud Infrastructure Logical Design","section":"Cloud Infrastructure","content":"Cloud Infrastructure Logical Design #  The logical design provides a high-level overview of the solution design.\nVMware Cloud Provider Lifecycle Manager simplifies the operational experience by providing a comprehensive solution to deploy, upgrade, configure, and manage the VMware Cloud Provider Program products.\nThe Cloud Infrastucture stack is comprised of the following components:\nVMware VMware Cloud Director\nVMware VMware Cloud Director is VMware’s flagship cloud services platform for Cloud Providers. It is a pervasive cloud infrastructure control plane for cloud providers’ service-delivery needs, and the management entity for a global VMware cloud estate. VMware Cloud Director allows seamless provisioning and consumption of cloud computing resources and services to geographically distributed lines of business and IT teams in an API-driven approach\nVMware vCloud Usage Meter\nVMware vCloud Usage Meter is a virtual appliance that collects usage data VMware products that are added for metering. The collected data is sent to vCloud Usage Insight, which aggregates the data and sends it to the VMware Commerce Portal. In that portal, the aggregated usage data automatically populates each month the partner\u0026rsquo;s MBO if automatic reporting is selected.\nVMware vRealize Tenant App for VMware Cloud Director\nVMware vRealize Tenant App for VMware Cloud Director is used for metering the infrastructure services provided by a service provider to their tenants. Further, it provides options to configure different models for pricing the metered infrastructure.\nRabbitMQ\nRabbitMQ is an open source distributed message broker. It facilitates the efficient delivery of messages in complex routing scenarios. Initially built around the popular AMQP protocol, it’s also highly compatible with existing technologies, while its capabilities can be expanded through plug-ins enabled on the server. RabbitMQ brokers can be distributed and configured to be reliable in case of network or server failure.\nCloud Infrastructure Architecture for VMware Cloud Foundation #  Description comment\nVMware VMware Cloud Director\nVCD diagram here\nVMware vCloud Usage Meter\nUM diagram here\nVMware vRealize Tenant App for VMware Cloud Director\nTenant App diagram here\nRabbitMQ\nRabbitMQ diagram here\nLogical Design For Product Deployment Using VMware Cloud Provider Lifecycle Manager #  The logical design provides a high-level overview of the solution design.\nDeployment Architecture\nTwo different deployment architectures are envisioned to be supported by VVS for Cloud Providers namely Standard and Consolidated. For the standard architecture, two workload domains are considered for the VCPP deployment: VI workload domain and Private Cloud Workload Domain\nThe SDDC management components and workload domains will be managed by the SDDC manager.\nStandard Architecture\nThis design is based on Standard Architecture where differemt Management and Workload Domains are used to segregate resources.\nVI Workload Domain\nThis deployment is based on the standard VCF deployment, consisting of a management domain and at least one workload domain.\nAll infrastructure and cloud management components are deployed in the management domain, being physically and logically isolated from the tenant workload. Workload domains (Compute (vCenter), storage (vSAN) and network (NSX-T)) are deployed on separate hosts and configured as provider VDCs in vCloud Director.\nAll vCenters are running in enhanced link mode.\nPrivate Cloud Workload Domain\nThis is required to support VCD\u0026rsquo;s CPOM (Central Point of Management) feature to allow direct access to dedicated vCenters. The vCenter provisioned for this domain must not have ELM enabled, as otherwise, users accessing the dedicated vCenter would be able to automatically have access to other vCenters as well.\nIn this architecture, each customer will get a dedicated workload domain (aka vSphere Cluster), managed by a single instance of VMware Cloud Director. The customer will consume infrastructure as a Cloud Director tenant without having vCenter server access due to ELM architecture in VCF 4.4.x release.\nConsolidated Architecture\nThis deployment is intended for smaller environments, requiring a minimum of 4 hosts for the complete deployment. Both management and customer workloads are deployed in a single vCenter (cluster) \u0026amp; resources are provided using vCenter server resource pools.\nVCPP Components in VMware Cloud Foundation.\nFor this design document, the following VCPP components must be deployed in the management domain of VMware Cloud Foundation.\nCore Components:\n  VMware Cloud Director cells (VCD)\n  NFS Share for VMware Cloud Director\n  VMware Cloud Provider Lifecycle Manager\n  External NFS share for VMware Cloud Provider Lifecycle Manager\n  Optional products that can be deployed using VMware Cloud Provider Lifecycle Manager\n  Usage Meter (UM)\n  RabbitMQ\n  vRealize Operations Manager Tenant App\n  Most of the components will be deployed in the management domain except for tenant \u0026amp; development workloads.\nThe following diagram shows the standard architecture with VI and private cloud workload domains (consolidated architecture cannot be combined with standard architecture).\nVMware Cloud Provider Lifecycle Manager Architecture #  VMware Cloud Provider Lifecycle Manager is designed as an application that provides a REST API and GUI to perform the required tasks. The underlying implementation to integrate with the corresponding products VMware Cloud Director, vRealize\nOperations Manager Tenant App, RabbitMQ and Usage Meter are designed as generic product tasks.\nTo deploy or manage a solution, VMware Cloud Provider Lifecycle Manager requires a definition of the necessary tasks (deployment + validation, configuration, upgrade tasks) and product binaries (e.g., OVA). The REST API generic structure is applicable to different types of solutions.\nVMware Cloud Provider Lifecycle Manager needs access to a repository (mounted NFS or locally) which contains OVA files, upgrade packages, etc.\nThe Below diagram represents the high-level architecture of VMware Cloud Provider Lifecycle Manager\nWorkflow Execution Process Of VMware Cloud Provider Lifecycle Manager #  Once a request is triggered by VMware Cloud Provider Lifecycle Manager’s REST API or GUI, then it will execute the corresponding task defining a list of actions. The task will be executed asynchronously. Each task will be associated with an ID which can be used to query the state of the task.\nDatacenter\nTo enable VMware Cloud Provider Lifecycle Manager to manage products, first you must register a data center component. The data center components are instances or services available in the data center that VMware Cloud Provider Lifecycle Manager does not manage. You can register vCenter Server, NSX-T, and vRealize Operations Manager as data center components.\nEnvironment\nProducts are deployed as a part of Lifecycle Manager environment. Each environment can have multiple products and user needs to provide a unique Environment ID during deployment, for identification purpose. VMware Cloud Provider doesn’t allow environments with duplicate Environment ID as it is referenced during retrieval, deletion of environment and product management operations like upgrades, node management, etc.\nTo deploy a product, the target vCenter to deploy in, has to be specified. This should refer to a vCenter that is registered as a datacenter component.\nProduct\nThe products follow a generic definition pattern that defines basic common product fields and requires product-specific details to be specified as properties. Each product will be associated with a unique product ID and the same will be used to retrieve the details related to the products.\nWorkflow Execution\nThe below diagram represents the product deployment process using VMware Cloud Provider Lifecyclle Manager.\n"},{"id":30,"href":"/docs/developer-ready-cloud/logical-design/","title":"Cloud Infrastructure Logical Design","section":"Developer Ready Cloud","content":"Cloud Infrastructure Logical Design #  "},{"id":31,"href":"/docs/networking-security/logical-design/","title":"Cloud Infrastructure Logical Design","section":"Networking and Security","content":"Cloud Infrastructure Logical Design #  "},{"id":32,"href":"/docs/sovereign-cloud/logical-design/","title":"Cloud Infrastructure Logical Design","section":"Sovereign Cloud","content":"Cloud Infrastructure Logical Design #  "},{"id":33,"href":"/docs/cloud-infrastructure/metering/","title":"Cloud Infrastructure Metering","section":"Cloud Infrastructure","content":"Cloud Infrastructure Metering #  vCloud Usage Meter is a virtual appliance for tracking the usage of the VMware products part of the VMware Cloud Provider Program that are deployed on-prem and payed based on pay-as-you-grow model.\nThe Usage Meter appliance is installed on-prem through vSphere and connects to the metered products through their IPs and the users who are able to connect to them. After the successful connection to the metered product is established, the collection of usage data starts.\nThe data is collected every 1 hour for most VMware products and used by vCloud Usage Insight. The latter is a cloud service that aggregates the usage data and generated reports out of it. The aggregated data appears during the first few days of the following month in the VMware Commerce Portal (VCP). This data is used for the generation of the VCP Monthly Billing Order (MBO).\nHere is a glimpse of how Usage Meter and Usage Insight work together:\nvCloud Usage Meter Deployement #  vCloud Usage Meter is deployed on-prem as a virtual appliance and tracks the usage of the VMware products that it meters.\nOne of the ways to deploy the appliance is to use the VMware Cloud Provider Lifecycle Manager.\nSee the following information on how to deploy vCloud Usage Meter by using the API calls of the VMware Cloud Provider Lifecycle Manager.\nAnother way to deploy the appliance is by installing its ova file through vSphere. See the process here.\nvCloud Usage Meter Security and Privacy Guidelines #  vCloud Usage Meter collects usage data from the metered products in a transparent and secure way. It anonymizes data such as vSAN cluster name, VM name, hostname, target vCenter, etc. The anonymization is conducted prior to transmitting to VMware using SHA1 to create a one-way hash. From the hash, VMware cannot obtain the original value.\nMoreover, vCloud Usage Meter does not collect any PII data. Providers can see at any time what data their Usage Meter collects by downloading the usage data locally.\nThe full list of data collected by vCloud Usage Meter per supported VMware product can be found in the Usage Meter Data Privacy and Sharing Guidelines whitepaper.\nvCloud Usage Meter is also FIPS-compliant which testifies to its high level of security and data privacy.\nHow to start metering your VCPP products with Usage Meter #  To start metering the VMware products that you use, you need a signed VCPP contract with VMware and a deployed Usage Meter appliance. The latter must be registered with your VCPP license (Rental or Sovereing Cloud) before you can start metering the usage of your VMware products.\nThen, you must add the details of each product like IP address or hostname, and the credentials of the user who is able to connect to it.\nThe process of adding a VMware product for metering is explained in details in the following page.\nHow does the metering work #  The following information helps you understand how the metering of product usage data works.\nIt also provides insight into how the reported usage data is calculated and appears in the vCloud Usage Insight reports.\nThe metering information goes into the following categories.\nMetering Cloud Infrastructure Products #    vCenter Server - The vCenter Server usage is calculated by the average capped billed vRAM per a managed VM. The vCenter Server usage is reported as part of the Flex Core bundle.\n  VMware Cloud Foundation - The usage of VCF is calculated as the time-based average of host CPU core count, aggregated by different VCF editions except for the SDDC Manager license edition. The SDDC Manager license edition is metered as an average Capped Billed vRAM GB per VM. The VCF editon that is reported is the one selected when the VCF is added to the Usage Meter web application.\n  vSAN - The vSAN usage is calculated as a monthly average of an hourly count of used capacity (datastore space used). The vSAN license edition is determined by the vSAN features used by the vCenter VMs.\n  NSX- V - The NSX-V usage is calculated as an average capped billed vRAM GB per VM using NSX-V features if bundled or a monthly average of an hourly count of non-unique VMs serviced for the NSX-V Enterprise edition only. The edition is determined by the NSX- V features used by the vCenter VMs.\n  NSX-T - The NSX-T usage is calculated by the average capped billed vRAM in GB per VM using NSX-T features. The reported license edition is determined by the NSX-T features used by the vCenter VMs.\n  Cloud Director - The Cloud Director usage is calculated by the number of VMs under management.\n  Metering Other Solutions #    Cloud Director Availability - Usage is calculated based on the number of protected VMs.\n  Tanzu - Usage is calculated based on the vRAM or CPU cores used by the Tanzu-related VMs.\n  SRM - Metered based on the number of protected VMs.\n  vRealize Operations - Usage is metered either based on the average capped billed vRAM used by the VMs monitored by vRealize Operations when the latter is used as a Flex Add-on product, or the hourly count of non-uniques VMs under monitoring throughout the month when vROPs is reported as a standalone product.\n  vRealize Network Insight - Usage is metered either based on the average capped billed vRAM used by the VMs monitored by vRealize Operations when the latter is used as a Flex Add-on product, or the hourly count of non-uniques VMs under monitoring throughout the month when vROPs is reported as a standalone product.\n  vRealize Automation - Usage is calculated based on the monthly average of an hourly count of non-unique VMs in the month.\n  Metering Other Products #    Horizon - Usage is calculated as a maximum number of desktop VMs under management for VDI or maximum number of sessions under management for RDSH.\n  Horizon DaaS - Usage is calculated based on the maximum number of concurrent connections to Horizon Connection Server per license edition.\n  "},{"id":34,"href":"/docs/cloud-infrastructure/network-design/","title":"Cloud Infrastructure Network Design","section":"Cloud Infrastructure","content":"Cloud Infrastructure Network Design #  Network Design of Management Cluster for VMware Cloud Foundation #  The following picture shows the network design for all the components in the Cloud Infrastructure and how they are managed using VMware Cloud Provider Lifecyclle Manager\nReg.Mgmt and X.Reg.Mgmt\n  These are overlay Segments\n  Existing Reg. Mgmt is used for a secondary interface for VCD cells, vSAN FS, Usage meter, vRealize Operations\nManager Tenant App and VMware Cloud provider Lifecycle Manager\n  Cross region X.Reg.Mgmt is utilized for RabbitMQ nodes and load balancer.\n  VCD DMZ\n  VCD DMZ network has been added to separate the internet traffic. It is routed via a separate Tier-1 gateway and connected to existing Tier-0.\n  VCD Cells have the primary (eth0) interface connected to this network with NSX-T load balancer in its own Tier-1 gateway.\n  VMware Cloud Provider Lifecycle Manager Firewall Ports #  The below table provides a list of ports used by VMware Cloud Provider Lifecycle Manager for product and integration communication.\n   Port Protocol Direction Target Description     9443 TCP Inbound / Outbound Management network Port used for VMware Cloud Provider Lifecycle Manager REST API.   22 TCP Inbound / Outbound Management network SSH connection to the VMware Cloud Provider Lifecycle Manager machine to configure and set up deployment binaries.   22 TCP Outbound Deployed products (VCD, RMQ, vROPS TA, UM) SSH used to configure deployed products.   53 TCP/UDP Inbound / Outbound DNS Server DNS will be used to resolve IPs and hostnames and validate corresponding records for requested deployments.\nThe DNS server provided in the payload will be used for validation purposes.   123 UDP Outbound NTP server Configure NTP server to ensure time is in sync.   443 TCP Outbound vCenter (Mgmt and resource)\nNSX Manager\nVCD (cells and load balancer)\nvROPS\nvROPS Tenant App\nUsage Meter HTTPS traffic to access and configure deployed products as well as validate infrastructure components.   5671 * TCP, UDP Outbound RabbitMQ AMQP port used for RabbitMQ AMQP service. This port can be customized; thus, the corresponding port must be accessible.   15671 * TCP Outbound RabbitMQ Management Interface Management port used for RabbitMQ Management Interface. This port can be customized; thus, the corresponding port must be accessible.    ICMP Inbound / Outbound VCD cells\nVCD cells\nvROPS Tenant App\nUsage Meter\nRabbitMQ Ping is performed to check if deployed machines are running or existing prior to deployment.    "},{"id":35,"href":"/docs/developer-ready-cloud/network-design/","title":"Cloud Infrastructure Network Design","section":"Developer Ready Cloud","content":"Cloud Infrastructure Network Design #  "},{"id":36,"href":"/docs/networking-security/network-design/","title":"Cloud Infrastructure Network Design","section":"Networking and Security","content":"Cloud Infrastructure Network Design #  "},{"id":37,"href":"/docs/sovereign-cloud/network-design/","title":"Cloud Infrastructure Network Design","section":"Sovereign Cloud","content":"Cloud Infrastructure Network Design #  "},{"id":38,"href":"/docs/cloud-infrastructure/operations/","title":"Cloud Infrastructure Operations","section":"Cloud Infrastructure","content":"Cloud Infrastructure Operations #  After you complete the implementation of the Cloud Infrastructure, you perform common operations on the environment, such as \u0026hellip;\nFor operational guidance on the components that are deployed automatically in VMware Cloud Foundation or complement the basic VMware Cloud Foundation configuration, see the VMware Cloud Foundation Operations and Administration Guide in the VMware Cloud Foundation documentation.\nPersonas in Cloud Infrastructure #  Personas describe types of system users, aligned with real people and their functions within the organization. You build a persona set based on your organization\u0026rsquo;s requirements for role-based access control.[Read more]\nOperational Verification of Cloud Infrastructure #  After you add a {VVS Product/Suite} instance in your VMware Cloud Foundation environment during the implementation of the Cloud Infrastructure validated solution, verify that the newly-implemented and reconfigured components are operational and functioning within expected parameters.[Read more]\nCertificate Management for Cloud Infrastructure #  The security of your environment depends on the validity and trust of the SDDC component certificates. After you deploy and configure the standalone {VVS Product/Suite} instance to your VMware Cloud Foundation environment, you replace the component certificate if the certificate is expiring or compromised, or some of the certificate attributes, such as the host or organization name, must be changed.[Read more]\nPassword Management for Cloud Infrastructure #  Manage the account passwords of the components in your VMware Cloud Foundation environment according to the design objectives and design guidance of Cloud Infrastructure validated solution.[Read more]\nShutdown and Startup of Cloud Infrastructure #  In certain cases, for example, during hardware or power maintenance of the data center, you must shut down the standalone {VVS Product/Suite} instance in a VMware Cloud Foundation environment in a way that prevents data loss and appliance malfunction, and start it up restoring component integration after the maintenance operation is over.[Read more]\nMetering of Cloud Infrastructure #  After implementing Cloud Infrastructure you must take steps to ensure that proper usage metering of the new {VVS Product/Suite} begins.[Read more]\n"},{"id":39,"href":"/docs/cloud-infrastructure/pwd-management/","title":"Cloud Infrastructure Password Management","section":"Cloud Infrastructure","content":"Cloud Infrastructure Password Management #  "},{"id":40,"href":"/docs/cloud-infrastructure/personas/","title":"Cloud Infrastructure Personas","section":"Cloud Infrastructure","content":"Cloud Infrastructure Personas #  "},{"id":41,"href":"/docs/cloud-infrastructure/planning/","title":"Cloud Infrastructure Planning and Preparation","section":"Cloud Infrastructure","content":"Cloud Infrastructure Planning and Preparation #  Before you start implementing the components of the Cloud Infrastructure solution, you must set up an environment that has a specific compute, storage, and network configuration, and that provides external services to the components of the solution.\nUse the VMware Cloud Foundation Planning and Preparation Workbook to capture environment specific input values that are required during the implementation.\nCarefully review the VMware Cloud Foundation Planning and Preparation Workbook before implementation to avoid costly rework and delays. Capture input values that are specific to your environment and verify that the components that are required by this solution are available.\nThe VMware Cloud Foundation Planning and Preparation Workbook contains inputs for each implementation and configuration procedure. Reference your values from the VMware Cloud Foundation Planning and Preparation Workbook to complete UI or PowerShell procedures.\n#External Services You use services that are external to VMware Cloud Foundation when implementing the solution-name solution.\n   External Service Description     Active Directory (AD) Active Directory (AD) is used to provide authentication and authorization to the VMware Cloud Foundation infrastructure.\nThis includes dedicated Domain Users with least privilege access to act as service accounts for component connectivity.   Domain Name Services (DNS) Domain Name Services is used to ensure components are resolvable by FQDN and by IP address.   Network Time Protocol (NTP) Network Time Protocol is used to synchronize time consistently across components.   Certificate Authority (CA) Certificate Authority is used to provide signed certificates for user facing interfaces.    "},{"id":42,"href":"/docs/cloud-infrastructure/shutdown-startup/","title":"Cloud Infrastructure Shutdown and Startup","section":"Cloud Infrastructure","content":"Cloud Infrastructure Shutdown and Startup #  "},{"id":43,"href":"/docs/cloud-infrastructure/verification/","title":"Cloud Infrastructure Verification","section":"Cloud Infrastructure","content":"Cloud Infrastructure Verification #  "},{"id":44,"href":"/docs/dr-migration/deploy-vcda-appliances/","title":"Deployment of the VMware Cloud Director Availability Appliances","section":"DR and Migration","content":"Deployment of the VMware Cloud Director Availability Appliances #  Deployment Steps #  The deployment of the VMware Cloud Director Availability appliances in the vCenter Server is done by following these steps:\n  In the vCenter UI click on Deploy OVF Template\u0026hellip;\n  Select the VMware Cloud Director Availability OVF template.\n  Name the virtual machine.\n  Select a destination compute resource.\n  Review the virtual machine details.\n  Read and accept the license agreement.\n  Select the appliance that you are going to deploy.\n   Pick the storage for the disk files.\n  Specify the network that the appliance will be connected to.\n  Enter the deployment properties such as root password, NTP server, IP address, gateway, DNS, etc.\n  Validate that all the details are correctly entered on the summary screen, and deploy the virtual machine.\n  Note: You need to repeat these steps to deploy each of the appliances - Cloud Replication Management, Cloud Replicator(s) and Cloud Tunnel. The Combined appliances is not supported for Production.\nAfter the deployment of the appliances, you need to run the initial setup wizard. It is designed to guide you through the essential steps to configure all the appliances at the same time. Read more\n"},{"id":45,"href":"/docs/developer-ready-cloud/cert-management/","title":"Developer Ready Cloud Certificate Management","section":"Developer Ready Cloud","content":"Developer Ready Cloud Certificate Management #  "},{"id":46,"href":"/docs/developer-ready-cloud/design/","title":"Developer Ready Cloud Design","section":"Developer Ready Cloud","content":"Developer Ready Cloud Design #  The {VVS for CP Title} validated solution has objectives to deliver prescriptive content about the solution so that it is fast to deploy and is suitable for use in production environments.\n   Objective Description     Main objective Provide {VVS for CP function} for VMware Cloud Foundation infrastructure components. {optionally add: through services in the VVS}   VMware Cloud Foundation architecture support vSAN ReadyNodesConsolidatedStandardSingle VMware Cloud Foundation instanceMultiple VMware Cloud Foundation instances with NSX FederationSingle or multiple VMware Cloud Foundation instances with multiple availability zonesVxRail NodesStandardSingle VMware Cloud Foundation instanceMultiple VMware Cloud Foundation instances with NSX FederationSingle or multiple VMware Cloud Foundation instances with multiple availability zones   Workload domain type support Management Workload domainVI Workload domain   Scope of guidance Detailed design for solution components.Deployment and initial configuration of intelligent logging and analytics components for management and VI workload domains.Operational guidance for solution components, such as operational verification, password management, and certificate management.Solution interoperability with solution components, such as monitoring and life cycle.   Scope of implementation Deployment and configuration of solution components:Component 1Component 2Configuration of \u0026hellip;Component 1Component 2   Cloud type Public Cloud   Number of VMware Cloud Foundation instances 1   Load Balancing \u0026mdash;   Availability 99%   Authentication, authorization, and access control Use of Microsoft Active Directory over LDAP as the identity provider.Use of security groups and roles for least-privilege access control.Use of service accounts and least-privilege access control for solution integration. The configuration of Microsoft Active Directory Federation Services as the external identity provider is not included in this solution.   Certificate signing Certificates are signed by a certificate authority (CA) that consists of a root and intermediate certificate authority layers.    "},{"id":47,"href":"/docs/developer-ready-cloud/detailed-design/","title":"Developer Ready Cloud Detailed Design","section":"Developer Ready Cloud","content":"Developer Ready Cloud Detailed Design #  The {VVS for CP Title} validated solution uses {VVS Product} deployed on top of а VMware Cloud Foundation VI workload domain to \u0026hellip;\nLogical Design for {VVS for CP Title} #  The logical design consists of multiple elements that enable you to deploy and manage infrastructure used to {VVS Product Purpose}. [Read more]\nDeployment Specification for {VVS for CP Title} #  When {VVS Product} is enabled on \u0026hellip; [Read more]\nNetwork Design for {VVS for CP Title} #  {VVS Product} requires multiple networks. This section discusses networking design not covered in the NSX-T Data Center detailed design. [Read more]\nLifecycle Management for {VVS for CP Title} #  Lifecycle management design details the decisions for lifecycle management of an instance of {VVS Product}. [Read more]\nInformation Security and Access for {VVS for CP Title} #  You design authentication access, controls, and certificate management for {VVS Product} according to industry standards and the requirements of your organization. [Read more]\n"},{"id":48,"href":"/docs/developer-ready-cloud/metering/","title":"Developer Ready Cloud Metering","section":"Developer Ready Cloud","content":"Developer Ready Cloud Metering #  How to start metering your VCPP products with Usage Meter #  The following information helps you understand how Usage Meter detects and meters the usage of the listed VMware products and their features.\nIt also provides insight into how the reported usage data is calculated and appears in the Usage Insight reports.\nMetering Developer Ready Cloud Products #  Tanzu\n"},{"id":49,"href":"/docs/developer-ready-cloud/pwd-management/","title":"Developer Ready Cloud Password Management","section":"Developer Ready Cloud","content":"Developer Ready Cloud Password Management #  "},{"id":50,"href":"/docs/developer-ready-cloud/personas/","title":"Developer Ready Cloud Personas","section":"Developer Ready Cloud","content":"Developer Ready Cloud Personas #  "},{"id":51,"href":"/docs/developer-ready-cloud/shutdown-startup/","title":"Developer Ready Cloud Shutdown and Startup","section":"Developer Ready Cloud","content":"Developer Ready Cloud Shutdown and Startup #  "},{"id":52,"href":"/docs/developer-ready-cloud/verification/","title":"Developer Ready Cloud Verification","section":"Developer Ready Cloud","content":"Developer Ready Cloud Verification #  "},{"id":53,"href":"/docs/dr-migration/backup-restore/","title":"DR and Migration Backup and Restore","section":"DR and Migration","content":"DR and Migration Backup and Restore #  You can generate a new backup for each VMware Cloud Director Availability appliances in their own UI or do it directly from the Cloud Replication Manager appliance, where backups for all appliances will be generated.\nThe backup archive contains the following information from each appliance in the cloud site:\n Configuration files Public certificate Keystore Database dump  The backup does not contain:\n The appliance root user password. Any previous backup archives. Any support bundles. The NTP time server configuration. Enable SSH state. The network configuration provided in the OVF wizard during appliance deployment. Static routes configured on appliances with multiple network interface cards (NICs).  The backups are encrypted and password protected. They can be downloaded from the VMware Cloud Director Availability UI or API and stored outside of the VMware Cloud Director Availability appliances.\nGenerate a Backup Archive #  Follow these steps from the Cloud Replication Manager appliance to back up all appliances:\n Log in to the VMware Cloud Director Availability UI at https://Appliance-IP-Address/ui/admin. Navigate to the Backup Archives menu. Click GENERATE NEW. The backup window pops-up. There you need to enter a password and click the GENERATE button.  Shortly, the backup archive will be ready and can be downloaded by clicking the download button.  Note: If you perform backups per appliance, you can follow the same steps in the UI of each VMware Cloud Director Availability appliance.\nRestore a Backup #  VMware Cloud Director Availability support in-place restore of backups. It also does not require powering off of the appliance before the in-place restore.\nRestoring always requires an appliance with exactly the same version as the remaining cloud appliances in the site and with exactly the same version as the downloaded backup archive.\nUnlike the backup generation, the restore operation has to be performed on each appliance through its UI.\nNote: If you need to restore all the appliances, this is the correct order:\n Tunnel service Replicator service(s) Cloud service  These are the steps to perform a restore operation:\n Extract the backup archive. As a result, you will have a .enc file for each registered appliance. Since you might have multiple replicators, the file name of each one ends with its IP address. Log in to the VMware Cloud Director Availability UI at https://Appliance-IP-Address/ui/admin. Navigate to the Backup Archives menu. Click RESTORE. Select the correct .enc file for the component that is being restored, enter the password specified during the backup archive creation, and click RESTORE. If you have selected a wrong backup for another component, you will see the The appliance role does not match the one in the backup archive. error message.  When the process is completed, you will be able to access the VMware Cloud Director Availability appliance that you have just restored.  Generate a Backup through the API #  As an addition to the UI backup generation, there is an option for the administrator to generate one directly through the API, which is a convenient option for automating the backup process.\nTo generate and download the archive for each appliance through the API, you will need to perform the following steps:\n Open a terminal and execute this command:  curl 'https://Appliance-IP-Address:8046/sessions' -i -X POST \\ -H 'Content-Type: application/json' \\ -H 'Accept: application/vnd.vmware.h4-v4.1+json;charset=UTF-8' \\ -d '{ \u0026quot;type\u0026quot; : \u0026quot;localUser\u0026quot;, \u0026quot;localUser\u0026quot; : \u0026quot;root\u0026quot;, \u0026quot;localPassword\u0026quot; : \u0026quot;root_password\u0026quot; }' Please note this is for local user authentication. For more authentication options, please refer to the API programming guide.\nIf the command is executed successfully, in the output you will find a parameter called X-VCAV-Auth. For example:  Copy its value as this is the authentication token that will be used in the next steps.\nTo generate a new backup, execute the following command:  curl 'https://Appliance-IP-Address:8046/backups' -i -X POST \\ -H 'Content-Type: application/json' \\ -H 'Accept: application/vnd.vmware.h4-v4.1+json;charset=UTF-8' \\ -H 'X-VCAV-Auth: \u0026lt;\u0026lt;token\u0026gt;\u0026gt;' \\ -d '{ \u0026quot;password\u0026quot; : \u0026quot;\u0026lt;\u0026lt;password\u0026gt;\u0026gt;\u0026quot; }' \u0026lt;\u0026lt;token\u0026raquo; should be the value collected in the previous step and \u0026lt;\u0026lt;password\u0026raquo; is the password that you would like to define for the backup archive.\nThis is the expected result.\nTo download the archive, you need to execute:  curl 'https://Appliance-IP-Address:8046/backups/\u0026lt;\u0026lt;backup_id\u0026gt;\u0026gt;' -i -X GET \\ -H 'Accept: application/vnd.vmware.h4-v4.1+octet-stream;charset=UTF-8' \\ -H 'X-VCAV-Auth: \u0026lt;\u0026lt;token\u0026gt;\u0026gt;' --output \u0026lt;\u0026lt;destination/file.tar.bz2\u0026gt;\u0026gt; The \u0026lt;\u0026lt;backup_id\u0026raquo; is the ID parameter (the first one) in the response of the previous step, \u0026lt;\u0026lt;token\u0026raquo; is the value collected in step 1 results and \u0026lt;\u0026lt;destination/file.tar.bz2\u0026raquo; is the destination file.\nIf you would like to download another backup archive, you can list all available archives with the following:\ncurl 'https://Appliance-IP-Address:8046/backups' -i -X GET \\ -H 'Accept: application/vnd.vmware.h4-v4.1+json;charset=UTF-8' \\ -H 'X-VCAV-Auth: \u0026lt;\u0026lt;token\u0026gt;\u0026gt;' \u0026lt;\u0026lt;token\u0026raquo; is the value collected in step 1 results.\nIn case of a problem with the certificates, you can use -k as a curl parameter like this:\ncurl -k ‘https://Appliance-IP-Address:8046/backups’ … "},{"id":54,"href":"/docs/dr-migration/cert-management/","title":"DR and Migration Certificate Management","section":"DR and Migration","content":"DR and Migration Certificate Management #  The SSL certificates are essential for establishing a trusted connection between the different VMware Cloud Director Availability appliances and their proper service.\nEach of them comes with their unique self-signed SSL certificate during the deployment. But still, these certificates need to be replaced when they expire, or if the providers prefer to use CA-signed ones to make sure there will be no browser warnings, for example. Below you can find the necessary steps to replace the Cloud Service, Manager Service, Replicator Service, and the Tunnel Service certificates with CA-signed ones. Usual scenario #  It is sufficient for most providers to use a CA-signed certificate for the Cloud Service only and self-signed certificates for all other services. This CA-signed certificate has to be generated for the public endpoint of VMware Cloud Director Availability. Prerequisites for the CA-signed certificate #    PKCS#12 (.pfx) certificate and the private key should use the same password\n  PKCS#12 file should contain only one entry - the private key and its corresponding certificate and, optionally, the certificate trust chain\n  RSA key size should be 2048-bit or larger\n  The certificate should not use insecure hash algorithms like SHA1 or MD5\n  Useful commands #  Command 1: Generate a new private key and Certificate Signing Request:\n openssl req -out CSR.csr -new -newkey rsa:2048 -nodes -keyout privateKey.key\nCommand 2: Convert .crt to .pem\n openssl x509 -inform der -in certificate.cer -out certificate.pem\nCommand 3: Prepare a PKCS#12 (.pfx) from a .pem (in case your CA didn\u0026rsquo;t provide it to you)\n openssl pkcs12 -export -out certificate.pfx -inkey privateKey.key -in certificate.crt -certfile CACert.crt\nSteps #    Login through SSH with the root user to the VMware Cloud Director Availability Cloud Service host.\n   Generate a new private key and Certificate Signing Request using the following command:\n   openssl req -out CSR.csr -new -newkey rsa:2048 -nodes -keyout privateKey.key\nFill in the necessary data similar to this example   Once the CSR is generated, you need to transfer it to the CA for signing.\n  If the received CA-signed certificate is not in PKCS#12 format (.pfx), please use the following command to prepare it:\n   openssl pkcs12 -export -out certificate.pfx -inkey privateKey.key -in certificate.crt -certfile CACert.crt\n(where privateKey.key is the private key used for the CSR and CACert.crt is the CA certificate)\n Load the certificate to the Cloud Service using:\n  VMware Cloud Director Availability UI:     Navigate to the VMware Cloud Director Availability Cloud Service URL (https://Appliance-IP-Address/ui/admin.)    Log in as root.    Select Settings from the left pane called Configuration.      Under Appliance Settings, you will find Certificate.      Click Import.    Fill in the Export Password (specified while creating the .pfx).      Click Apply.     VMware Cloud Director Availability API through command-line:     Transfer the .pfx file to the VMware Cloud Director Availability Cloud Service host.    Log in as root through SSH to the VMware Cloud Director Availability Cloud Service host.    Log in as root to the VMware Cloud Director Availability API through the command-line using:    c4 loginroot 'password'\n    Upload the new certificate using:    c4 upload_certificate /path/to/cert/cert.pfx 'Export password'\n     The VMware Cloud Director Availability Cloud Service will be restarted after the certificate change.\n  You will no longer see any warnings in the browser.\n  Affected services #  To see what other services are affected by the change and fix, you can open System Health under Monitoring in the left pane.\nYou can see that the connectivity to the Tunnel Service is showing failure.\nTo fix it, you need to perform the steps in Procedure 1.\nProcedure 1: #    Click on Settings under Configuration.\n  Find Tunnel Service address in Service Endpoints.\n  Click Edit.\n  Enter the root password.\n   Click Apply.\n  Accept the certificate request.\n  Go back to System Health and check that the connectivity to the Tunnel Service is okay.\n  Affected paired sites #  Such a certificate change impacts both cloud and on-premises sites that are paired to this Cloud Service. In order to restore the regular operation, you will need to re-pair all connected sites.\nOn-premises #  To re-pair with an on-premises site, your tenant needs to:\n  Open the VMware Cloud Director Availability on-premises appliance URL.\n  Log in as root.\n  Click on Settings in the left pane.   Find Pairing under Site Details.\n  Click Repair.\n   Enter all information in the wizard and accept the certificate request.\n  Finish the wizard.\n  Cloud #  To re-pair with a cloud site, the remote cloud site admin needs to:\n  Open the VMware Cloud Director Availability UI of the remote site.\n  Log in as root.\n  Click Peer Sites under Configuration in the left pane.\n  Select the cloud site with the changed certificate (marked with an error).   Click Repair.\n  Click Update and accept the certificate request.\n  A message indicates there are actions to be performed on the other site.  Once these steps are performed, you need to do the same at the local site. Other appliances #  If you plan to replace all self-signed certificates with CA-signed ones, you can follow the steps described for the Cloud Service. The only difference is in the affected services as follows:\n  When changing the SSL certificate of a Manager Service, the trust between all Replicator Service instances is invalidated. All cloud and on-premises replicators become offline. The cloud replicators need to be repaired manually while the on-premises ones will restore their operation automatically within 30 minutes without repairing them manually. However, it may have a temporary impact over the active replications.\n  When changing the SSL certificate of a Replicator Service, it leads to a paring problem with Manager Service. You need to re-pair to the Manager Service on the local site and re-establish the trust between all cloud sites.\n  When changing the SSL certificate of a Tunnel Service, you need to re-establish the connectivity between it and the Cloud Service. To do so, you can perform Procedure 1. For about 30 minutes, you might see a Generic error occurred during TLS handshake message, but you do not need to perform any actions to fix it. The reason is that the certificate replacement restarts the service, which breaks the sessions with the remote cloud or on-premises replicator. The session initiation happens every 30 minutes, which means that all remote sites should auto-recover pairing in no longer than 30 min.\n  When changing the VMware Cloud Director SSL certificate, you need to re-establish the trust connection from the VMware Cloud Director Availability Cloud Service UI.\n  When changing the Lookup Service SSL certificate, all VMware Cloud Director Availability appliances need to trust the Lookup Service certificate once again.\n  Backup and restore #  One of the features in VMware Cloud Director Availability, which enables backing-up all appliances, is very useful when planning to perform changes to any of the services.\nConsidering that replacing the certificates impacts the operation of VMware Cloud Director Availability, we always recommend generating a backup before proceeding with any of the steps for updating the SSL certificates. You can see how in this blog post.\n"},{"id":55,"href":"/docs/dr-migration/deployment-spec/","title":"DR and Migration Deployment Specification","section":"DR and Migration","content":"DR and Migration Deployment Specification #  The deployment specification covers the design decisions regarding the design and sizing of the VMware Cloud Director Availability appliances.\nDeployment Model #  You consider the deployment model according to the design objectives and scale of your DR and migration services.\nA VMware Cloud Director Availability instance is required in each VMware Cloud Foundation instance that is intended to be utilized for the DR and migration services offered to tenants. You deploy the VMware Cloud Director Availability Cloud Replication Management and Cloud Tunnel appliances in the management domain and the Cloud Replicator(s) in the Workload domain(s).\nDesign Decisions on Site Recovery Manager​ Deployment #  Sizing Compute and Storage Resources for VMware Cloud Director Availability #  VMware Cloud Director Availability offers different deployment options based on the estimated number of replications that manages. Scale-out is made possible by deploying additional Cloud Replicator appliances.\nVMware Cloud Director Availability Appliances Sizing #     Appliance Type Description and Services Hardware Requirements     Cloud Replication Management Appliance A dedicated appliance, that runs the following VMware Cloud Director Availability services: * Manager Service * Cloud Service with embedded VMware Cloud Director Availability Tenant Portal - 2 vCPUs - 4 GB RAM\n- 10 GB Storage   Cloud Replicator Appliance A dedicated appliance for the Replicator Service that handles the replication traffic for a site. For large-scale environments, you can deploy more than one Cloud Replicator Appliance per cloud site. - 4 vCPUs - 6 GB RAM - 10 GB Storage   Cloud Tunnel Appliance A dedicated appliance for the Tunnel Service. - 2 vCPUs - 2 GB RAM\n- 10 GB Storage    VMware Cloud Director Availability Recommended Deployment #  The VMware Cloud Director Availability recommended deployment consists of the following components.\n   Appliance name Number of appliances     VMware Cloud Director Availability Cloud Replication Management 1   VMware Cloud Director Availability Cloud Replicator 2   VMware Cloud Director Availability Cloud Tunnel 1    One VMware Cloud Director Availability Cloud Replicator appliance supports up to 1000 active replications. This number can be lower due to several factors such as VM size, RPO settings, retention rules, etc.\nScalability #  To scale-out VMware Cloud Director Availability, you can deploy an additional Cloud Replicator every time the active replication numbers are close to the maximums.\nFor optimal performance, deploy the Cloud Replicators on different hosts if possible.\nReplication Technology and Flow #  VMware Cloud Director Availability uses Host Based Replication (HBR) technology as a data mover. An HBR Server runs in the VMware Cloud Director Availability Cloud Replicator and communicates with the source VM vSCSI IO Filter via one of the vmkernel interfaces of the source host. When VM is configured for replication this IO Filter is enabled and configured with the IP address and port of the listening HBR server plus several other replication settings like RPO time, quiescing, compression, and encryption.\nThe VM IO stream to the underlying datastore is handled by the vSCSI interface where the IO Filter works too.\nWhen a VM is configured for replication the IO Filter tracks the addresses of the blocks that are changed. A few moments before the RPO timer expires the IO Filter starts to read the content of the changed blocks and sends them to the HBR server that is afterward responsible for delivering the replication data to the recovery site.\nBoth the IO Filter and HBR server ensure when the RPO timer expires and gets reset that the content from all dirty blocks is replicated. When this process is completed on time we have an RPO violation-free replication and the IO Filter starts new dirty block tracking. If this process cannot be completed on time we see an RPO violation.\n"},{"id":56,"href":"/docs/dr-migration/design/","title":"DR and Migration Design","section":"DR and Migration","content":"DR and Migration Design #  The DR and Migration validated solution has objectives to deliver prescriptive content about the solution so that it is fast to deploy and is suitable for use in production environments.\n   Objective Description     Main objective Enable DR and migration services for the VMware Cloud Director Organizations on VMware Cloud Foundation.    VMware Cloud Foundation architecture support vSAN ReadyNodes\nStandard\nSingle VMware Cloud Foundation instance\nVxRail Nodes\nStandard\nSingle VMware Cloud Foundation instance   Workload domain type support Management Workload domain\nVI Workload domain   Scope of guidance Detailed design for solution components.\nDeployment and initial configuration of intelligent logging and analytics components for management and VI workload domains.\nOperational guidance for solution components, such as operational verification, password management, and certificate management.   Scope of implementation Deployment and configuration of solution components:\nVMware Cloud Director Availability Cloud Replication Management appliance\nVMware Cloud Director Availability Cloud Replicator appliance\nVMware Cloud Director Availability Cloud Tunnel appliance   Cloud type Private Cloud   Number of VMware Cloud Foundation instances 1   Load Balancing \u0026mdash;   Availability 99%   Authentication, authorization, and access control Use of VMware Cloud Director security groups and roles for least-privilege access control.\nUse of service accounts and least-privilege access control for solution integration.   Certificate signing Certificate for the Cloud service of VMware Cloud Director Availability Cloud Replication Manager Appliance is signed by a certificate authority (CA) that consists of a root and intermediate certificate authority layers. The certificates for all the other appliances can be self-signed.    "},{"id":57,"href":"/docs/dr-migration/detailed-design/","title":"DR and Migration Detailed Design","section":"DR and Migration","content":"DR and Migration Detailed Design #  The DR and Migration validated solution uses VMware Cloud Director Availability deployed on top of а VMware Cloud Foundation Management and VI workload domains.\nLogical Design for DR and Migration #  The logical design consists of multiple elements that enable you to deploy and manage infrastructure used for DR and Migration. [Read more]\nDeployment Specification for VMware Cloud Director Availability #  The deployment specification covers the design decisions regarding the design and sizing of the VMware Cloud Director Availability appliances. [Read more]\nNetwork Design for DR and Migration #  This section discusses networking design related to the optimized operation of VMware Cloud Director Availability and not covered in the NSX-T Data Center detailed design. [Read more]\nLifecycle Management for DR and Migration #  Lifecycle management design details the decisions for lifecycle management of VMware Cloud Director Availability. [Read more]\nInformation Security and Access for DR and Migration #  You design authentication access, controls, and certificate management for VMware Cloud Director Availability according to industry standards and the requirements of your organization. [Read more]\n"},{"id":58,"href":"/docs/dr-migration/implementation/","title":"DR and Migration Implementation","section":"DR and Migration","content":"DR and Migration Implementation #  Implementing DR and Migration validated solution includes configuring VMware Cloud Director Availability.\nTo implement and configure VMware Cloud Director Availability, you can use the user interface of each component in the solution.\nThis guidance provides a prescriptive path for deploying VMware Cloud Director Availability in a management and/or VI workload domain.\nPrerequisites #  Here is a high-level list of the requirements to deploy VMware Cloud Director Availability. For more details, please refer to the official documentation.\n  DNS and NTP server\n  SSO Lookup Service Address\n  SSO admin credentials. If not available, then a user with the following privileges:\n   \u0026quot;Cryptographer.ManageKeys\u0026quot;, \u0026quot;Cryptographer.RegisterHost\u0026quot;, \u0026quot;Datastore.Config\u0026quot;, \u0026quot;Extension.Register\u0026quot;, \u0026quot;Extension.Unregister\u0026quot;, \u0026quot;Extension.Update\u0026quot;, \u0026quot;Global.DisableMethods\u0026quot;, \u0026quot;Global.EnableMethods\u0026quot;, \u0026quot;Host.Config.Connection\u0026quot;, \u0026quot;Host.Hbr.HbrManagement\u0026quot;, \u0026quot;VirtualMachine.Inventory.Register\u0026quot;, \u0026quot;VirtualMachine.Inventory.Unregister\u0026quot;, \u0026quot;VirtualMachine.Interact.PowerOff\u0026quot;, \u0026quot;VirtualMachine.Interact.PowerOn\u0026quot;, \u0026quot;VirtualMachine.State.CreateSnapshot\u0026quot;, \u0026quot;VirtualMachine.State.RemoveSnapshot\u0026quot;, \u0026quot;VirtualMachine.Hbr.ConfigureReplication\u0026quot;, \u0026quot;VirtualMachine.Hbr.ReplicaManagement\u0026quot;, \u0026quot;VirtualMachine.Hbr.MonitorReplication\u0026quot;  Routing and Firewall Ports in place\n  Compatible versions of vCenter and VMware Cloud Director – open the VMware Product Interoperability Matrices\n  The ESXi hosts in all paired on-premises sites and in all paired cloud sites must run one of the following vSphere product editions that include the vSphere Replication feature:\n   vSphere Essentials Plus vSphere Standard vSphere Enterprise vSphere Enterprise Plus vSphere Desktop  Proceedure #    Deploy the VMware Cloud Director Availability appliances\nAll the steps required for deploying the three VMWare Cloud Director Availability appliances. Read more\n  Configure the VMware Cloud Director Availability appliances\nWalk through the steps of the initial setup wizard of VMware Cloud Director Availability. Read more\n  Configure multiple network interfaces\nAll the instructions if needed to configure multiple network adapters on each of the VMware Cloud Director Availability appliances. Read more\n  Attach Usage Meter to the VMware Cloud Director Availability Replication Management appliance\nHow to add the VMware Cloud Director Availability to Usage meter. Read more\n  "},{"id":59,"href":"/docs/dr-migration/info-sec-access/","title":"DR and Migration Information Security and Access","section":"DR and Migration","content":"DR and Migration Information Security and Access #  Identity Management Design #  Each VMware Cloud Director Availability appliance has just a single system administrator user (root). Its password is configured during the appliance deployment and must be changed during the initial setup wizard or at the first login to this appliance.\nAdditionally, a VMware Cloud Director service account with system administrator privileges needs to be created for the VMware Cloud Director Availability registration to the VMware Cloud Director instance. As an alternative, an existing system administrator account (administrator, root, etc.) can be used.\nAs part of this registration process, the Setup DRaaS and Migration and Availability plug-in is installed in VMware Cloud Director.\nCertificate Management Design #  Replace the default self-signed certificate of the Cloud service of VMware Cloud Director Availability Replication Management with a CA-signed certificate to provide secure access and communication for VMware Cloud Director Availability.\nAs the rest of the appliances are not publicly exposed, they do not need a CA-signed certificate. They can operate with their initially self-signed certificates until they expire or with newly generated self-signed certificates.\n"},{"id":60,"href":"/docs/dr-migration/lifecycle-mgmt/","title":"DR and Migration Lifecycle Management","section":"DR and Migration","content":"DR and Migration Lifecycle Management #  The lifecycle management of VMware Cloud Director Availability is provided using the native tools in each of the appliances. All deployment, patching, and upgrade operations are performed manually by the system administrator without or with minimal native automation.\nMost of the operations (deployment, upgrades) can be performed through the graphical user interface of VMware Cloud Director Availability while some of them are also available through the command-line.\nBackup and Restore #  Before performing any lifecyle operations, you need to backup the VMware Cloud Director Availability appliances. This way you will prevent extended loss of service in case of a potential problem caused by these operations.\nThis is how to generate a backup and then restore it. [Read more]\n"},{"id":61,"href":"/docs/dr-migration/logical-design/","title":"DR and Migration Logical Design","section":"DR and Migration","content":"DR and Migration Logical Design #  The DR and Migration solution is comprised of the following VMware Cloud Director Availability components:\nCloud Replication Management Appliance #  The Cloud Replication Management appliance is responsible for the communication with VMware Cloud Director. Based on this communication, it discovers resources (OrgVCD, storage policies, datastores, networks, etc.) managed by VMware Cloud Director and used by the tenants. This information is required for discovering vApps/VMs that can be replicated/migrated or suitable destination locations for incoming replications/migrations.\nIt also provides the VMware Cloud Director Availability UI and API interfaces. Another role of this appliance is to communicate with all the local and remote Replicators and receive data regarding each protected/migrated workload. Two VMware Cloud Director Availability services cover these functionalities in Cloud Replication Management appliance – the cloud.service and the manager.service.\nCloud Service #  This service understands the VMware Cloud Director constructs – OrgVCD, vApps, networks managed by VMware Cloud Director, storage policies, etc. To achieve this VMware Cloud Director Availability Cloud Management appliance communicates with the VMware Cloud Director API through the VMware Cloud Director LB. The Cloud Replication Management appliance does not communicate with the VMware Cloud Director consoleproxy cells/interfaces. Based on this, VMware Cloud Director Availability can:\n discover VMware Cloud Director managed vApps/VMs and protect/migrate them to another DR-enabled cloud or on-premises vCenter discover a suitable destination for incoming replications/migrations  The cloud service manages pairings with other DR-enabled clouds, policies, SLA profiles, and their assignment to VMware Cloud Director organizations. It provides information about the replication and system tasks. Also, it reports the replication compute resources consumption per tenant and per PVDC, the storage consumption per datastore, plus many other high- and low-level details.\nThe cloud service management interface is available on https://vcda_manager_fqdn:443/admin. It is possible to log in with the local OS root account, an SSO account if the appliance has registration in an SSO domain, or with a VMware Cloud Director System Administrator account if the initial configuration is already completed.\nManager Service #  The manager service manages the registrations of local and remote replicators. During the pairing process, remote replicators are registered in the Cloud Replication Management appliance. For each replication, it chooses one replicator from the source site and one from the destination site. The destination replicator is responsible for discovering the appropriate resources to create the replica disks at the destination and write data. Replicators send information to the Cloud Replication Management appliance about their operation – statuses, amount of data replicated, operation start time, time to complete, etc.\nThe manager service is also used to manage replicators. It can trigger the rebalancing of replications across all replicators or put a replicator in maintenance mode, which leads to assigning each of its replications to another one. This is useful when the current replicators need to be offloaded by adding a new replicator in the solution.\nThe manager service management interface is available at https://vcda_manager_fqdn:8441. It is possible to log in with the local OS root account and an SSO account if the appliance is already registered in Lookup Service.\nCloud Replicator #  Cloud Replicator is responsible for moving the replication data around - to and from the ESXi hosts and the cloud. For outgoing replications/migrations, it communicates with the VMKernel interface of the ESXi host, captures and encrypts replication data, optionally compresses it, and sends it to the remote replicator, which can be another Cloud Replicator or on-premises Replicator. For incoming replications/migrations the Cloud Replicator receives replication data from a Replicator (cloud or on-premises), decompresses and decrypts this data, and sends it to the ESXi to be written on a datastore. Cloud Replicator is the only component that can scale out as the number of protections/migrations increases.\nCloud Tunnel #  The Cloud Tunnel appliance is the single-entry point to the VMware Cloud Director Availability instance in the cloud. Its role is to handle and forward the incoming management and replication traffic. It is the only VMware Cloud Director Availability appliance that needs a dedicated Internet-accessible endpoint.\nLogical Design For Product Deployment #  The logical design provides a high-level overview of the solution design.\nBased on the standard architecture, most of the components will be deployed in the management domain except for Cloud Replicator(s) that will be deployed in the VI Workload Domain(s).\n"},{"id":62,"href":"/docs/dr-migration/metering/","title":"DR and Migration Metering","section":"DR and Migration","content":"DR and Migration Metering #  How to start metering your DR and Migration products with Usage Meter #  The following information helps you understand how Usage Meter detects and meters the usage of the listed VMware products and their features.\nIt also provides insight into how the reported usage data is calculated and appears in the Usage Insight reports.\nMetering DR and Migration Products #  Cloud Director Availability\n"},{"id":63,"href":"/docs/dr-migration/network-design/","title":"DR and Migration Network Design","section":"DR and Migration","content":"DR and Migration Network Design #  Inside data centers, while the cloud providers typically use links with 10 Gbps or more between the components, the routing of replication data traffic might still benefit from optimizing. The way the Cloud Tunnel Appliance and the Cloud Replicator Appliance instances connect in the local cloud site is important. This connectivity can be routed or switched. Routed connectivity is easier for deployment and configuration. However, the routers might bottleneck replications. The intensive replication traffic might impact the operations of the routers, causing issues for other types of traffic.\nTo bypass the routers and optimize the replication data traffic, use multiple network interfaces for the cloud appliances and connect the Cloud Replicator Appliance instances with the Cloud Tunnel Appliance at a common Layer 2 port group. By using such optimization, only the connectivity with the Cloud Replication Management Appliance and with the management infrastructure remains over routed networks. However, the management traffic is negligible compared to the replication data traffic.\nThe following network diagram shows this topology.\nNetwork Ports #  This is the list of ports used by VMware Cloud Director Availability.\n   Source Destination Port Number Protocol Description     VMware Cloud Director Availability Replicator ESXi Hosts 902 TCP and UDP Used by the VMware Cloud Director Availability Replicator service for replication traffic to the destination ESXi hosts.   VMware Cloud Director Availability Replicator VMware Platform Services Controller® 443 TCP Used for single sign-on and Lookup Service communication.   VMware Cloud Director Availability Replicator vCenter Server 443 TCP Used by the local VMware Cloud Director Availability vApp Replication Manager service or the VMware Cloud Director Availability Replicator service for communication with the local vCenter Server.   VMware Cloud Director Availability Replicator VMware Cloud Director Availability vApp Replication Manager 8044 TCP Used for vCloud Availability vApp Replication Manager management from the vCloud Availability Replicator.   VMware Cloud Director Availability Replicator VMware Cloud Director Availability Tunnel 8048 TCP Used for VMware Cloud Director Availability vApp Replication Manager management from the VMware Cloud Director Availability Replicator.   VMware Cloud Director Availability vApp Replication Manager VMware Platform Services Controller® 443 TCP Used for single sign-on and Lookup Service communication.   VMware Cloud Director Availability vApp Replication Manager VMware Cloud Director service 443 TCP Used for VMware Cloud Director Director management from the VMware Cloud Director Availability vApp Replication Manager.    VMware Cloud Director Availability vApp Replication Manager VMware Cloud Director Availability Replicator 8043 TCP Used for VMware Cloud Director Availability Replicator management from the VMware Cloud Director Availability vApp Replication Manager.    VMware Cloud Director Availability vApp Replication Manager VMware Cloud Director Availability Tunnel 8047, 8048 TCP Used for VMware Cloud Director Availability Tunnel management from the VMware Cloud Director Availability vApp Replication Manager.    VMware Cloud Director Availability Tunnel VMware Cloud Director Availability Replicator 8043, 44045 TCP Used for VMware Cloud Director Availability Replicator management from the VMware Cloud Director Availability Tunnel.    VMware Cloud Director Availability Tunnel VMware Cloud Director Availability vApp Replication Manager 8044, 8046 TCP Used for VMware Cloud Director Availability vApp Replication Manager service management from the VMware Cloud Director Availability Tunnel appliance.    VMware Cloud Director Availability Tunnel VMware Platform Services Controller® 443 TCP Used for VMware Platform Services Controller® communication management from the VMware Cloud Director Availability vApp Replication Manager and VMware Cloud Director Availability Replicator.    ESXi Hosts VMware Cloud Director Availability Replicator 31031, 44045, 44046 TCP Used by the ESXi hosts for replication traffic to the destination VMware Cloud Director Availability Replicator service.    Firewall VMware Cloud Director Availability Tunnel 8048 TCP Used for redirecting external traffic management to the VMware Cloud Director Availability Tunnel service.     "},{"id":64,"href":"/docs/dr-migration/operations/","title":"DR and Migration Operations","section":"DR and Migration","content":"DR and Migration Operations #  After you complete the implementation of VMware Cloud Director Availability, you can perform common operations on the environment related to maintaining the proper functionality of the DR and Migration services.\nFor operational guidance on the components that are deployed automatically in VMware Cloud Foundation or complement the basic VMware Cloud Foundation configuration, see the VMware Cloud Foundation Operations and Administration Guide in the VMware Cloud Foundation documentation.\nPersonas in DR and Migration #  Personas describe types of system users, aligned with real people and their functions within the organization. You build a persona set based on your organization\u0026rsquo;s requirements for role-based access control.[Read more]\nOperational Verification of DR and Migration #  After you add a VMware Cloud Director Availability instance in your VMware Cloud Foundation environment during the implementation of the DR and Migration validated solution, verify that the newly-implemented and reconfigured components are operational and functioning within expected parameters.[Read more]\nCertificate Management for DR and Migration #  The security of your environment depends on the validity and trust of the SDDC component certificates. After you deploy and configure the standalone VMware Cloud Director Availability instance to your VMware Cloud Foundation environment, you replace the component certificate if the certificate is expiring or compromised, or some of the certificate attributes, such as the host or organization name, must be changed.[Read more]\nPassword Management for DR and Migration #  Manage the account passwords of the components in your VMware Cloud Foundation environment according to the design objectives and design guidance of DR and Migration validated solution.[Read more]\nShutdown and Startup of DR and Migration #  In certain cases, for example, during hardware or power maintenance of the data center, you must shut down the standalone VMware Cloud Director Availability instance in a VMware Cloud Foundation environment in a way that prevents data loss and appliance malfunction, and start it up restoring component integration after the maintenance operation is over.[Read more]\nMetering of DR and Migration #  After implementing DR and Migration you must take steps to ensure that proper usage metering of the new VMware Cloud Director Availability replications begins.[Read more]\n"},{"id":65,"href":"/docs/dr-migration/pwd-management/","title":"DR and Migration Password Management","section":"DR and Migration","content":"DR and Migration Password Management #  VMware Cloud Director Availability doesn\u0026rsquo;t have its users and permissions system but utilizes the organization structure and authentication mechanisms of VMware Cloud Director.\nAs a result, there is only one local user for each appliance - the system administrator user (root).\nVMware Cloud Director Availability uses the root user account for access to both the virtual appliance console and the management interface. The initial deployment of each VMware Cloud Director Availability appliance sets up this account. The OVF Deployment wizard requires an initial password for the root user account, with an initial requirement being over three characters long. After the initial deployment, VMware Cloud Director Availability forces changing this initial password on the first login by using the root user, with the following requirements for the persistent root user account password.\n The password must be over eight characters. The password must contain digits, upper and lower case letters, and non-alphabetic characters. The password cannot match any previous password. The password must contain more than four new characters compared to the previous password.  Change the root user password #  For security reasons, you can change the root users passwords of the VMware Cloud Director Availability appliances. Please note that each appliance has its own root user, and changing the password of one appliance will NOT affect the rest.\nProcedure #   Log in to the management interface of the VMware Cloud Director Availability appliance.  In a Web browser, go to https://Appliance-IP-Address/ui/admin. Select Appliance login enter the root user credentials. Click Login.   In the left pane under Configuration, click Settings. Under Appliance settings, next to Root password click Change. In the VMware Cloud Director Availability Appliance Password window, change the root user password.  In the Current Password text box, you must enter the current password of the root user. In the New Password text box, enter the new password for the root user. It must comply with the VMware Cloud Director Availability password policy. In the Confirm Password text box, enter the same new password. To confirm the password change, click Apply.    Note: VMware Cloud Director Availability does not store the root user password for services communications and operations. No further actions are required after any of the VMware Cloud Director Availability appliances root users passwords changes:\n The root user password is used only for administrative logins to the appliance. Changing the root user password of the Cloud Replication Management Appliance in a cloud site does not affect the paired cloud sites and does not affect the paired on-premises sites. The Replicator Service instances paired with the Cloud Service continue operating normally after changing the root users passwords of the Cloud Replicator Appliance instances and the Cloud Replication Management Appliance. The Cloud Service only uses the Cloud Tunnel Appliance root user password to enable the Tunnel Service for the first time. Changing the root user password of the On-Premises to Cloud Director Replication Appliance does not affect the pairing with the cloud site.  "},{"id":66,"href":"/docs/dr-migration/personas/","title":"DR and Migration Personas","section":"DR and Migration","content":"DR and Migration Personas #  In the VMware Cloud Director Availability terminology, there are two types of personas:\n Service providers manage VMware Cloud Director Availability objects and the local VMware Cloud Director Availability appliances after authenticating as VMware Cloud Director System Administrator users. By default, the System Administrator role has all VMware Cloud Director rights. Users belonging to that role can manage any local and monitor any remote VMware Cloud Director Availability inventory object. To manage VMware Cloud Director Availability objects in the remote site, authenticate as a System Administrator to the remote site. Tenant users perform disaster recovery operations and manage local VMware Cloud Director Availability objects after authenticating as VMware Cloud Director Organization Administrator users. These users can perform disaster recovery operations in the local site, can manage any local VMware Cloud Director Availability object, and can monitor any remote VMware Cloud Director Availability object that belongs to the VMware Cloud Director organization. To manage remote VMware Cloud Director Availability objects, authenticate as an Organization Administrator user to the remote site.  "},{"id":67,"href":"/docs/dr-migration/planning/","title":"DR and Migration Planning and Preparation","section":"DR and Migration","content":"DR and Migration Planning and Preparation #  Before you start implementing the components of the DR and Migration solution, you must set up an environment that has a specific compute, storage, and network configuration, and that provides external services to the components of the solution.\nUse the VMware Cloud Foundation Planning and Preparation Workbook to capture environment specific input values that are required during the implementation.\nCarefully review the VMware Cloud Foundation Planning and Preparation Workbook before implementation to avoid costly rework and delays. Capture input values that are specific to your environment and verify that the components that are required by this solution are available.\nThe VMware Cloud Foundation Planning and Preparation Workbook contains inputs for each implementation and configuration procedure. Reference your values from the VMware Cloud Foundation Planning and Preparation Workbook to complete UI or PowerShell procedures.\nExternal Services #  You use services that are external to VMware Cloud Foundation when implementing the solution-name solution.\n   External Service Description     Active Directory (AD) Active Directory (AD) is used to provide authentication and authorization to the VMware Cloud Foundation infrastructure.\nThis includes dedicated Domain Users with least privilege access to act as service accounts for component connectivity.   Domain Name Services (DNS) Domain Name Services is used to ensure components are resolvable by FQDN and by IP address.   Network Time Protocol (NTP) Network Time Protocol is used to synchronize time consistently across components.   Certificate Authority (CA) Certificate Authority is used to provide signed certificates for user facing interfaces.    Important Considerations #  A typical good practice is to separate the management and resource vCenters/clusters. The number of hosts in resource vCenters/clusters is significantly higher than the number in the management cluster. A recommendation is to deploy Replicators on resource hosts and not in the management cluster so more Replicators can be deployed and a DRS rule can be created to keep the Replicator VMs on different hosts for better load distribution. Also, the replication traffic path from the Replicator appliances to the replication network on the resource hosts will be enhanced. The hosts can use the management vmkernel interface to communicate with the Replicator. Another option is to have a dedicated vmkernel interface for replication purposes only. Using the management vmkernel simplifies the configuration but significantly reduces the control options available to the administrator and can lead to a risk for routing uncompressed replication traffic, which is highly non-desired. The general recommendation is to use a dedicated vmkernel for the replication traffic. In this case, the administrator will have better control over the infrastructure. Using NIOC, the administrator will be able to set shares for different types of vmkernel traffic. It enables carrying the replication traffic over dedicated uplinks.\nNote: If any other VMware HBR-based replication products (vSphere Replication, VMware Site Recovery Manager or VMware HCX) are used in this cloud, configuring a dedicated vmkernel interface marked with “vSphere Replication” and “vSphere NFC Replication” will lead to all of these products try to use it. This means the network connectivity between their appliances and the replication vmkernel interfaces will be required to enable all of these products to operate successfully. For more information, please consult with respective product documentation.\n"},{"id":68,"href":"/docs/dr-migration/shutdown-startup/","title":"DR and Migration Shutdown and Startup","section":"DR and Migration","content":"DR and Migration Shutdown and Startup #  Start/Stop/Status #  To start, restart, stop or see the status of each of the VMware Cloud Director Availability appliances, you need to establish an SSH session to the respective appliance and run the following command:\nsystemctl {start|restart|stop|status} \u0026lt;Service_System_Unit\u0026gt; The different services and their system units can be found in the table below.\n   Service Name System Unit     VMware Cloud on AWS Data Engine Service h4dm   Replicator Service replicator   Manager Service manager   Cloud Service cloud   Tunnel Service tunnel   vSphere Replication Server hbrsrv   Lightweight Delta Protocol Service lwdproxy   PostgreSQL database server h4postgresql    Restart through the UI #  As part of the troubleshooting, you can restart all VMware Cloud Director Availability services in the appliance from the System health page.\nNote: After restarting each service, wait a couple of minutes for the service to become operational and display its service management interface again.\nProcedure #   Log in to the management interface of each VMware Cloud Director Availability appliance.  In a Web browser, go to https://Appliance-IP-Address/ui/admin. Select Appliance login or SSO login and enter the root or the single sign-on user credentials. Click Login.   Restart all of the appliance services.  In the left pane, click System Health. In the System health page, click Restart service. In the Restart service window, to confirm the restart operation click Restart.    "},{"id":69,"href":"/docs/dr-migration/verification/","title":"DR and Migration Verification","section":"DR and Migration","content":"DR and Migration Verification #  The VMware Cloud Director Availability System Health page indicates the overall status of the service and appliances. It is highly recommended to verify the status after the initial setup or any maintenance operations such as an upgrade, certificate changes, password changes or other.\nService status #  Verify the connectivity statuses in the local cloud site to the following infrastructure services.\n Connectivity to the vCenter Server Lookup service. Connectivity to the database of VMware Cloud Director Availability. Connectivity to VMware Cloud Director. Connectivity to the local Tunnel Service. Connectivity to the NTP server.  Tunnel connectivity #  The following three sections are available for verifying the statuses of the connections from the local Tunnel Service to the following destinations.\n Local components connectivity to all the remaining VMware Cloud Director Availability services on the cloud appliances in the local cloud site. Remote cloud sites connectivity to the remote Tunnel Service instances in all paired remote cloud sites with the local cloud site. On-Prem Incoming connectivity to all paired On-Premises to Cloud Director Replication Appliance instances with the local cloud site.  Successful connectivity shows a green check icon OK. Alternatively, a red exclamation icon shows for connections that the Tunnel Service cannot establish. Restoring such connections automatically updates their connectivity status to green check icons OK.\nExample #  Below you can see an example from the System Health page.\n"},{"id":70,"href":"/docs/cloud-infrastructure/horizon-daas-metering/","title":"Horizon DaaS Metering and Reporting","section":"Cloud Infrastructure","content":"Horizon DaaS Metering and Reporting #  Product Detection #  For setting up VMware Horizon DaaS usage collection, for every Horizon DaaS deployment (each unique Horizon DaaS Service Provider implementation), the provider needs to register it in the Usage Meter 4.5.0.1 web application.\nTo set up the Horizon Desktop as a Service usage collection, the provider selects Horizon Desktop as Service in the Usage Meter web application, adds a new entry, and then enters the Horizon DaaS appliance IP address or hostname, port, username, password, and active directory domain. Validation of the user credentials is performed, and if correct, the data collection starts. The Usage Meter collector connects to the Horizon DaaS Service Provider appliance and collects license data. Usage metrics are collected every 6 hours.\nMetering #  For every reporting period, Usage Meter collects the maximum number of Desktop VMs under management for VDI and the maximum number of sessions under management for RDSH.\nReporting #  Sample Monthly Usage Report for Horizon Desktop as a Service\n   Product Hostname Version VC UUID Unit of Measure Units to be Reported     VMware Horizon DaaS Bundle - VDI Edition    Maximum Number of Desktop VMs under management for VDI 10   VMware Horizon DaaS Bundle - RDSH Edition    Maximum Number of Sessions under management for RDSH 80    "},{"id":71,"href":"/docs/cloud-infrastructure/horizon-metering/","title":"Horizon Metering and Reporting","section":"Cloud Infrastructure","content":"Horizon Metering and Reporting #  Product Detection #  Horizon is added for metering in Usage Meter 4.5.0.1. The provider needs to enter the endpoint IP address or hostname, user and password, and the domain to which Horizon belongs. After the product certificate is accepted in the Usage Meter web application and the connection to Horizon is successful, the data collection starts.\nMetering #  Usage Meter 4.5.0.1 collects data for the number of concurrent connections from the Horizon Connection Server and the license with which the concurrent connections are associated. Usage Meter 4.5.0.1 collects data every 1 hour and sends it to vCloud Usage Insight. Usage Meter stores in-memory the last received number of concurrent connections. It compares the latest collected data with the in-memory data and pushes the value to vCloud Usage Insight if it has changed. The Horizon usage is calculated based on the maximum number of concurrent connections per license edition for the month. If Horizon is not licensed or not reachable, Usage Meter 4.5.0.1 will generate a warning message in the Usage Meter Notifications tab.\nReporting #  Horizon usage is reported per license edition. The following license editions are reported by Usage Meter 4.5.0.1:\n VMware Horizon Standard VMware Horizon Advanced VMware Horizon Enterprise VMware Horizon Apps Standard VMware Horizon Apps Advanced  Sample Monthly Usage Report for Horizon\n   Product Hostname Version VC UUID Unit of Measure Units to be Reported     VMware Horizon Standard    Concurrent Connection 15   VMware Horizon Enterprise    Concurrent Connection 20    "},{"id":72,"href":"/docs/cloud-infrastructure/solution-interop-lifecycle/","title":"Life Cycle Management for Cloud Infrastructure","section":"Cloud Infrastructure","content":"Life Cycle Management for Cloud Infrastructure #  After you implement the {VVS for CP Title} validated solution, life cycle management for the Cloud Infrastructure components is managed by VMware Cloud Provider Lifecycle Manager.\nFor information on the impact of performing life cycle management of the products in this validated solution on VMware Cloud Foundation and other validated solutions that might be deployed in your environment, see VMware Knowledge Base Article KBxxxxx. For information on the life cycle management design for the products included within this validated solution, see Life Cycle Management Design for Cloud Infrastructure.\nTo perform life cycle management of the products included within this validated solution, refer to the following documentation:\nFor VMware Cloud Provider Lifecycle Manager upgrade, see document link.\nAfter you upgrade VMware Cloud Provider Lifecycle Manager, you can upgrade \u0026hellip;.\nFor information on applying {Cloud Infrastructure components} patches and hot fixes, see document link.\n"},{"id":73,"href":"/docs/networking-security/vcd-lbaas-implementation/","title":"Load Balancing as a Service in VMware Cloud Director","section":"Networking and Security","content":"Load Balancing as a Service in VMware Cloud Director #  Introduction #  This document is intended for VCPP Cloud Providers who are interested in providing Load Balancing as a Service (LBaaS) in their multi-tenant environments managed by VMware Cloud Director (VCD).\nFrom VMware Cloud Director 10.2 and onwards, VMware Cloud Director provides load balancing services in NSX-T backed organization virtual data centers (VDCs) by leveraging the capabilities of VMware NSX Advanced Load Balancer (Avi).\nThe content below describes the deployment and configuration procedures and also clearly delineates the cloud provider actions from the actions of the tenant, addressing both self-service and managed service offerings that are possible.\nVMware NSX Advanced Load Balancer (Avi) provides multi-cloud load balancing, web application firewall and application analytics across on-premises data centers and any cloud. The software-defined platform delivers applications consistently across bare metal servers, virtual machines and containers to ensure a fast, scalable, and secure application experience.\nLBaaS Anatomy #  The NSX Advanced Load Balancer Platform (Avi) is architected on software-defined principles, decoupling the data and control planes. As a result, it centrally manages and dynamically provisions pools of application services, including load balancing, across multi cloud environments.\nArchitecturally, the Platform comprises three core elements:\n The Avi Controller - provides central control and management of the Avi Service Engines. It orchestrates policy-driven application services, monitors real-time application performance (leveraging data provided by the Avi Service Engines), and provides for predictive auto-scaling of load balancing and other application services. Furthermore, it is capable of delivering per-tenant or per-application load balancing — increasingly in demand in multi cloud contexts — and also facilitates troubleshooting with traffic analytics. The Avi Service Engines (SEs) - distributed software that runs on bare metal servers, virtual machines, and containers. They implement application services across on-premises datacenters, colocation datacenters, and public clouds. They also collect data relating to application performance, security, and clients. As distributed software, Avi Service Engines are capable of horizontal auto-scaling within minutes while functioning as service proxies for micro services. The Avi Console - provides web-based administration and monitoring. It is a web server running on the controller and offers a UI for configuration of application services, delivers visualization of network configurations and virtual IPs (VIPs), and displays application health scores and transaction round-trip times. It’s also where customers can view performance, security, and client insights, as well as where they can view service interactions.  VMware Cloud Director Support #  Starting with version 10.2, VMware Cloud Director provides load-balancing services by using the capabilities of VMware NSX Advanced Load Balancer (Avi). VMware Cloud Director supports L4 and L7 load balancing that you can configure on an NSX-T Data Center edge gateway.\nAs a system administrator, you deploy the NSX Advanced Load Balancer controller cluster with the other management solutions in the management infrastructure.\nThe NSX Advanced Load Balancer Controller uses APIs to interface with NSX Manager and vCenter Server to discover the infrastructure. It also manages the lifecycle and network configuration of Service Engines (SE). The Avi Controller cluster uploads the SE OVA image to the vCenter Server content library and uses vCenter APIs to deploy the SE VMs.\nThis integration happens through an NSX-T Cloud configured in NSX ALB before being imported into VMware Cloud Director.\nLoad balancing services are associated with NSX-T edge gateways, which can be scoped to an organization VDC or a data center Group.\n​The system administrator has the flexibility to decide whether a service engine group is dedicated to a single edge gateway or shared between several edge gateways.\nTenant users have full self-service UI and API load balancing capabilities in VMware Cloud Director.\nA service engine node is a VM with up to 10 network interfaces (NICs). The first NIC is always used for the management and control traffic. The other nine are used to connect to the NSX-T edge gateway (tier-1 gateway) using a service network logical segment. The service networks are created by VMware Cloud Director when you enable the load balancing service on an edge gateway with the DHCP service to provide IP addresses for the attached SEs.\nBy default, the IP address used is 10.255.255.0/25 subnet. The system administrator can change the IP address if it coincides with the existing organization\u0026rsquo;s VDC networks.\nService Engines run each service interface in a different VRF. As a result, IP conflicts or cross-tenant communication does not occur. Avi automatically picks a service engine to instantiate the load balancing service when the tenant configures a load balancing pool and virtual service.\nWhen an SE is assigned, Avi configures a static route (/32) on the organization VDC edge gateway pointing the virtual service VIP (virtual IP) to the service engine IP address from the tenant\u0026rsquo;s load balancing service network.\nProvider and Tenant Responsibilities #  As a system administrator, you deploy an Avi Controller Cluster, complete the initial configuration and the association with NSX-T and VMware Cloud Director. Once the integration is ready, you deploy and enable load balancing on an NSX-T edge gateway and assign it a service engine group.\nAn organization administrator creates load balancer server pools and virtual services.\nDeployment \u0026amp; Configuration #  Requirements #  Please find the full list of requirements in the planning and preparation page.\nDeploying the Avi Controller Cluster #  To ensure complete system redundancy, the Avi Controller must be highly available. Three Avi Controller VMs will form a highly available control plane for the NSX Advanced Load Balancer.   Download the Controller OVA from my.vmware.com portal. Follow this KB article to download the Controller OVA image. Log into the vCenter server through a vSphere Client and deploy a first Avi Controller: Follow the Deploy OVA Template wizard instructions:  Choose a port group for Destination Network in Network Mapping. This port group is the management network for the Controller and will be used for all management communication (e.g., Avi Controller communication with vCenter). Specify the management IP address and default gateway (only static IP addresses should be used in a production environment). The \u0026lsquo;Sysadmin login authentication\u0026rsquo; key is used to specify an SSH public key and is NOT required.   Repeat the last steps to create two additional Avi Controllers to be used to form a three-node Controller cluster which will form the control plane for the NSX Advanced Load Balancer. Create an anti-affinity \u0026lsquo;VM/Host\u0026rsquo; rule to make sure Controller VMs are placed on separate hosts. Power on Controller VMs.  Just like any other infrastructure management system, CPU and memory should be 100% reserved on Avi controllers.  Avi Controller Cluster Initial Setup #  This section shows the steps to perform initial configuration of the Avi Controller using its deployment wizard. You can change or customize settings following initial deployment using the Avi Controller’s web interface.\nConfigure NSX Advanced Load Balancer Controller cluster to provide a highly available control plane for the NSX Advanced Load Balancer.\n Initialize the first NSX Advanced Load Balancer Controller VM  In a web browser, navigate to the first controller IP or FQDN. Note: While the system is booting up, a 503 status code or a page with following message will appear: \u0026ldquo;Controller is not yet ready. Please try again after a couple of minutes\u0026rdquo;. Wait for about 5 to 10 minutes and refresh the page.   Once the NSX Advanced Load Balancer welcome screen appears, create an admin account. Complete the remaining steps by configuring all required parameters (DNS, NTP, SMTP, etc.). Select No Orchestrator in the Orchestrator Integration page. Leave the Tenant Settings configured by default.   Configure an NSX Advanced Load Balancer Controller cluster  Navigate to Administration \u0026gt; Controller and select Edit. Specify the Name and the Controller Cluster IP. Add the details for each of the three NSX Advanced Load Balancer Controller nodes.  Click on Save. It will take a few minutes for the services to restart and the Controller cluster to be up. In a web browser, log in to the Controller cluster VIP. Navigate to Administration \u0026gt; Controller and ensure all the Controllers show State as Active which represents a healthy Controller cluster. Setup licensing in Administration \u0026gt; Settings \u0026gt; Licensing. Basic or Enterprise licenses are set at the controller cluster level. You cannot mix both licenses in a single Avi Controller cluster instance.   Finish the Controller Cluster configuration (alerting, backup, etc.). Note: the full configuration of the Avi Controllers general settings is outside the scope of this document.    VMware Cloud Director integration with NSX Advanced Load Balancer fails if the default self-signed certificate is used.\nBy default, the Controller cluster Portal will be setup with a self-signed certificate which does not have a valid SAN (Subject Alternative Name) and makes the integration with VMware Cloud Director impossible. VMware Cloud Director will reject any URL that does not match the values present in the certificate, which is to conform with industry standard security guidelines and our platform criteria.\n Setup of Avi Controller cluster Portal certificate is outside the scope of this document.\nAdditional resources:\n Deploying an Avi Controller Cluster Avi SSL/TLS Certificates  NSX-T Cloud #  The point of integration in Avi, with any infrastructure, is named a cloud. For NSX-T environment, an NSX-T cloud has to be configured.\nAn NSX-T cloud is defined by an NSX-T manager and a transport zone. If an NSX-T manager has multiple transport zones, each will map to a new NSX-T cloud. To manage load balancing for multiple NSX-T environments each NSX-T manager will map to a new NSX-T cloud.\nNSX-T cloud general considerations:\n An NSX-T cloud has a one-to-one relationship with a network pool backed by an NSX-T transport zone. DHCP checkbox: the Service Engines are expected to get an IP via DHCP on the management subnet  To create an NSX-T cloud, log in in to the Avi Controller and:\n Navigate to Infrastructure \u0026gt; Clouds. Click on Create and select NSX-T Cloud.  Following the general parameters, the NSX-T section allows to configure the future service engines network configuration:\n The transport zone must match the overlay transport zone configured in the network pool in VMware Cloud Director. The NSX-T cloud requires two types of network configurations:  Management Network: the tier-1 logical router and overlay segment to be used for management connectivity of the service engine VMs has to be selected. The first vNic of each service engines will be connected to that management network (which must be created upfront, with DHCP enabled). Data Network: although not required for the VMware Cloud Director integration, it is required to set a dummy data network to avoid having the NSX-T cloud object in a degraded state.    VMware Cloud Director will automatically complete the data network tier-1 logical routers and segments when load balancing is enabled on tier-1 acting as NSX-T edge gateways.   Each NSX-T cloud can have one or more vCenters associated to it. vCenter objects must be configured on Avi for all the vCenter compute managers added to the NSX-T that has ESXi hosts that belong to the transport zone configured in the NSX-T cloud.  Additional resources:\n Multiple vCenters with NSX-T Cloud  Service Engine Groups #  A service engine group is an isolation domain that also defines service engine node sizing (CPU, memory, storage), bandwidth restrictions, availability modes, and network access.\nResources in a service engine group can be used for different virtual services, depending on your tenant\u0026rsquo;s needs.\nTo create a service engine group, log in in to the Avi Controller and:\n Navigate to Infrastructure \u0026gt; Cloud Resources \u0026gt; Service Engine Group. Using the \u0026ldquo;Select Cloud\u0026rdquo; drop down menu, select the relevant NSX-T cloud. Click on Create.  The basic settings page allows to configure the high availability mode, the service engine capacity and limit settings, as well as other advanced parameters. The official Avi documentation can help to size appropriately the service engines in terms of CPU, memory and disk.\nService engines VMs may be automatically deployed on any host and storage that most closely matches the resources and reachability criteria for placement.\nStarting in Avi 20.1.3 and onwards, it is possible to tailor the service engine placement in terms of:\n vSphere folder vSphere hosts and cluster vSphere datastore  You may create multiple service engine groups depending on your tenants requirements for high availability, placement or performances.  Additional resources:\n Sizing Service Engines  VMware Cloud Director Service Admin Portal #  After the NSX Advanced Load Balancer deployment and configuration with the NSX-T infrastructure, the next step is to register the controller cluster with VMware Cloud Director.\nTo provide virtual service management capabilities to your tenants:\n Register your Avi Controller instances with your VMware Cloud Director instance. Register your NSX-T Cloud instances with VMware Cloud Director. Import all the relevant service engine groups to your VMware Cloud Director deployment.  Consumption #  Enabling Load Balancing #  Before an organization administrator can configure load balancing services, a system administrator must enable the load balancer on the NSX-T edge gateway and assign at least one service engine group to it.\n Navigate to the NSX-T edge gateway on which you want to enable load balancing. Under Load Balancer, click General Settings. Click Edit and enable the Load Balancer function for this particular edge. (optional) Enter a network CIDR for a service network subnet.  The service network is an internal construct; as such, it is not exposed to the tenant. Only change the default specification (192.168.255.1/25) if it overlaps with an existing organization VDC network.  Once load balancing is enabled, the next step is to manage the service engine group assignment on the edge gateway.\n Under Load Balancer, click Service Engine Groups. Select an available service engine group from the list. For shared service engine groups, the system administrator must set the maximum and reserved number of virtual services that can be placed on the edge gateway (within the capacity of the service engine group)  Design considerations:\n A system administrator can assign one or more service engine groups to an NSX-T Data Center edge gateway. All service engine groups that are assigned to a single edge gateway use the same service network.  Load Balancer Server Pool #  After a system administrator assigns a service engine group to an edge gateway, an organization administrator can create and configure virtual services that run in a specific service engine group.\nThe heart of a load balancer is its ability to effectively distribute traffic across healthy servers. A server pool is a group of one or more servers that you configure to run the same application and to provide high availability.\nIf persistence is enabled, only the first connection from a client is load balanced. While the persistence remains in effect, subsequent connections or requests from a client are directed to the same server.\n Under Load Balancer, click Pools, and then click Add. Configure the general settings for the load balancer pool.  Add members to the server pool.  Note: pool health status and pool member health status will remain Down until a virtual service is created and service engines are deployed.  Additional resources:\n Add a Load Balancer Server Pool  Virtual Service #  A virtual service listens for traffic to an IP address, processes client requests, and directs valid requests to a member of the load balancer server pool.\nA virtual service is a combination of an IP address and a port that uses a single network protocol. The virtual service is advertised to outside networks and is listening for client requests. When a client connects to the virtual service, the load balancer directs the request to a member of the configured load balancer server pool.\nTo secure SSL termination for a virtual service, you can use a certificate from the certificate library. For more information, see Import Certificates to the Certificates Library.\n Under Load Balancer, click Virtual Services, and then click Add. Configure the general settings for the load balancer pool. Enter a meaningful name and, optionally, a description, for the virtual service. To activate the virtual service upon creation, toggle on the Enabled option. Select a service engine group for the virtual service. Select a load balancer pool for the virtual service. Enter an IP address for the virtual service. Select the virtual service type.  The Virtual IP (VIP) can be any arbitrary IPv4 address. The VIP can be a routable external IP address allocated to the organization VDC edge gateway or any internal routed address:\n An external organization VDC edge gateway allocated IP address; no DNAT is required, but you cannot use this IP for NAT anymore due do the internal packet processing. An arbitrary internal IP (DNAT required). In that situation, the VIP must not coincide with any existing organization VDC networks or with the load balancer service network.  A static route will be automatically created on the Tier-1 from the VIP to the relevant service engine node IP.\n Additional resources:\n Create a Virtual Service  Health Monitoring #  VMware Cloud Director manages the health of the following load balancing components:\n NSX-T Cloud Virtual services Server pools  VMware Cloud Director provides basic monitoring and metrics about the virtual services and pools to both providers and tenant administrators.\nProviders can see the basic usage metrics for each service engine groups deployments (number of applications, usage, and running SE engines).\nTenants can see some basic metrics about each virtual service (up or down and traffic). Analytics is only available if the controller are imported with Enterprise License.\nAdvanced Features Consumption #  Although some advanced features are not exposed in VMware Cloud Director, they can be provided as a managed service. This includes (but is not limited to) Web Application Firewall (WAF) or custom Health Monitors.\nAvi Intelligent Web Application Firewall #  Web application firewalls (WAFs) are intended to protect businesses from web app attacks and proactively prevent threats. Traditional web application security solutions do not provide visibility and security insights that administrators can use to create an effective application security posture. Enterprises need real-time visibility into application traffic, user experience, security and threat landscape, and application performance to identify and protect against the most sophisticated attacks.\nAvi leverages software-defined architecture and its strategic location on the network to gain real-time application insights. The built-in WAF solution provides application security and networking teams with an elastic and analytics-driven solution that scales and simplifies policy customization and administration through central management.\nAvi intelligent WAF (iWAF) plays an integral role in a defense-in-depth strategy that does comprehensive threat analysis, mitigates risk, provides zero-day protection against unpublished exploits and optimizes application security.\nAs of today, Avi iWAF capabilities are not exposed in VMware Cloud Director for self-service configuration and consumption. However, a system administrator can assign WAF policies to existing virtual services.\nAdditional resources:\n Avi Intelligent Web Application Firewall  Custom Health Monitor #  Avi validates if the backend servers are functioning efficiently by sending active health monitors on a periodic basis. Avi Vantage also tests if they can accommodate additional workloads before load balancing a client to a server. Health monitors originate from the service engines assigned to the application\u0026rsquo;s virtual service. The health monitors are attached to the pool for the virtual service.\nA pool may have multiple actively concurrent health monitors (such as Ping, TCP, and HTTP), as well as a passive monitor. All active health monitors must be successful for the server to be marked up.\nWhen configuring a server pool from the tenant portal, a tenant administrator can choose between 5 health monitors: HTTP, HTTPS, TCP, UDP and PING. However, a system administrator can create and customize advanced health monitors from the Avi UI, and assign them to existing server pool.\nOnce the additional health monitor is associated with the server pool, it will appear in the tenant portal: a tenant administrator can remove it but not add it in self-service.\nResources #   NSX Advanced Load Balancer Integration with NSX-T NSX-T Support in NSX Advanced Load Balancer  "},{"id":74,"href":"/docs/networking-security/vcd-lbaas-design/","title":"Load Balancing as a Service in VMware Cloud Director Design","section":"Networking and Security","content":"(this page is here as a placeholder)\nClouds are containers for the environment that NSX Advanced Load Balancer is installed. During the initial setup of the Avi Networks platform, a default cloud named Default-Cloud is created. The first controller is deployed in Default-Cloud. You can add clouds containing SEs and virtual services. The network adapter 1 of the service engine VM is reserved for management connectivity and the remaining nine data interfaces (network adapter 2 to 10) for the service engine VM to the VIP or data segment.\nAvi controller deployed and managed by provider SEs are outside of tenant domains Service Engine Groups can be dedicated or shared. It is a provider decision on how to manage this.\nDedicated: If a tenant wants to pay to have dedicated LB compute (for throughput reasons) Shared: Normal model for providers to leverage multiple edges and potentially multiple tenants on the same compute resources\nNote: the shared VS dedicated is more about how the provider wants to manage how the tenants uses which SEGs As we must follow Basic licensing, Service Engine Groups configuration need to be configured in Legacy HA (Active/Standby) Mode This impact the number of Virtual Services per Service Engine Group\nDesign considerations\n NSX Advanced Load Balancer supports load balancing only in an NSX-T Data Center transport zone of type overlay.  The network adapter 1 of the Service Engine VM is reserved for management connectivity. You can connect only one of the remaining nine data interfaces (network adapter 2-10) of the Service Engine VM to the VIP or data segment. The other interfaces must be left disconnected. The service engines are deployed in one arm mode. The same interface is used for the client and backend server traffic. The SE routes to backend servers through the Tier 1 router. The SEs on a dedicated logical segment: • Allow to manage the IP address assignment separately for SE interfaces. • In the current version, this segment must be created on NSX-T Data Center before adding it to the cloud configuration on NSX Advanced Load Balancer. Only logical segments connected to the tier-1 router are supported. The cloud automation for NSX-T Data Center integration does not support placing SEs on logical segments directly connected to tier-0 routers.\nThe Controller cluster VMs can be deployed adjacent to the NSX Manager for NSX-T Data Center, connected to the management port group: • Dedicated tier-1 gateway and logical segment for the SE management. • Management IP address of the SEs must be reachable from controller. • Tier-0 must advertise the learned routes to the external router using BGP.\nVCD will prevent you to use more that one Avi NSX-T Cloud per VCD Geneve network pool. But you can have (in theory) multiple Geneve TZs on the same vSphere cluster, but that means separate physical NICS for each TZ Avi: You can\u0026rsquo;t share a transport zone, so you need a different pVDC when you have different Avi controllers with different transport zone \u0026gt; because VCD check the TZ match the NP during import\nIDEAS / PLACEHOLDER #   have a link to what\u0026rsquo;s next (design, prep or implementation)\n  show design options for where to host/connect the controllers vs the SEs  https://vmware-wwcp.screenstepslive.com/m/100574/l/1333937-nsx-advance-load-balancer https://avinetworks.com/docs/20.1/nsx-t-design-guide/#nsx-t-cloud-configuration-model\n"},{"id":75,"href":"/docs/cloud-infrastructure/solution-interop-lb/","title":"Logging for Cloud Infrastructure","section":"Cloud Infrastructure","content":"Logging for Cloud Infrastructure #  After you implement the {VVS for CP Title} validated solution, you can load balance the components that are newly added to your VMware Cloud Foundation environment.\nFor validated load balancing solutions, see Advanced Load Balancing Validated Solutions.[link]\nIntegration with NSX Advanced Load Balancer #  If your environment is running vRealize Log Insight, you can connect vRealize Log Insight to the {VVS for CP Title} components.\nDesign Decisions on Logging of {VVS for CP Title}\n   Decision ID Design Decision Design Justification Design Implications     VVS-COMP1-001 Decision comment Justification comments Implication comments   VVS-COMP1-002 Decision comment Justification comments Implication comments   VVS-COMP1-002 Decision comment Justification comments Implication comments    Prerequisites #  Verify that NSX Advanced Load Balancer is deployed and operational in a logical environment enabled for VMware Cloud Foundation.\nProceedure #   Step 1 Title - may link to sub document Description of step with [Read more link] or just describe the process if short Step 2 Title - may link to sub document Description of step with [Read more link] or just describe the process if short Step 3 Title - may link to sub document Description of step with [Read more link] or just describe the process if short  "},{"id":76,"href":"/docs/cloud-infrastructure/solution-interop-logging/","title":"Logging for Cloud Infrastructure","section":"Cloud Infrastructure","content":"Logging for Cloud Infrastructure #  After you implement the {VVS for CP Title} validated solution, monitor the components that are newly added to or reconfigured in your VMware Cloud Foundation environment.\nFor validated monitoring solutions, see VMware Cloud Foundation Validated Solutions.[link]\nIntegration with vRealize Log Insight #  If your environment is running vRealize Log Insight, you can connect vRealize Log Insight to the {VVS for CP Title} components.\nDesign Decisions on Logging of {VVS for CP Title}\n   Decision ID Design Decision Design Justification Design Implications     VVS-COMP1-001 Decision comment Justification comments Implication comments   VVS-COMP1-002 Decision comment Justification comments Implication comments   VVS-COMP1-002 Decision comment Justification comments Implication comments    Prerequisites #  Verify that vRealize Operations is deployed and operational in a logical environment enabled for VMware Cloud Foundation mode using the corresponding vRealize Suite Lifecycle Manager instance.\nProceedure #   Step 1 Title - may link to sub document Description of step with [Read more link] or just describe the process if short Step 2 Title - may link to sub document Description of step with [Read more link] or just describe the process if short Step 3 Title - may link to sub document Description of step with [Read more link] or just describe the process if short  "},{"id":77,"href":"/docs/cloud-infrastructure/solution-interop-monitor/","title":"Monitoring and Alerting for Cloud Infrastructure","section":"Cloud Infrastructure","content":"Monitoring and Alerting for Cloud Infrastructure #  After you implement the {VVS for CP Title} validated solution, monitor the components that are newly added to or reconfigured in your VMware Cloud Foundation environment.\nFor validated monitoring solutions, see VMware Cloud Foundation Validated Solutions.[link]\nIntegration with vRealize Operations Manager #  If your environment is running vRealize Operations Manager, you can connect vRealize Operations Manager to the {VVS for CP Title} components.\nDesign Decisions on Monitoring of {VVS for CP Title}\n   Decision ID Design Decision Design Justification Design Implications     VVS-COMP1-001 Decision comment Justification comments Implication comments   VVS-COMP1-002 Decision comment Justification comments Implication comments   VVS-COMP1-002 Decision comment Justification comments Implication comments    Prerequisites #  Verify that vRealize Operations is deployed and operational in a logical environment enabled for VMware Cloud Foundation mode using the corresponding vRealize Suite Lifecycle Manager instance.\nProceedure #   Step 1 Title - may link to sub document Description of step with [Read more link] or just describe the process if short Step 2 Title - may link to sub document Description of step with [Read more link] or just describe the process if short Step 3 Title - may link to sub document Description of step with [Read more link] or just describe the process if short  "},{"id":78,"href":"/docs/networking-security/cert-management/","title":"Networking and Security Certificate Management","section":"Networking and Security","content":"Networking and Security Certificate Management #  "},{"id":79,"href":"/docs/networking-security/design/","title":"Networking and Security Design","section":"Networking and Security","content":"Networking and Security Design #  The {VVS for CP Title} validated solution has objectives to deliver prescriptive content about the solution so that it is fast to deploy and is suitable for use in production environments.\n   Objective Description     Main objective Provide {VVS for CP function} for VMware Cloud Foundation infrastructure components. {optionally add: through services in the VVS}   VMware Cloud Foundation architecture support vSAN ReadyNodesConsolidatedStandardSingle VMware Cloud Foundation instanceMultiple VMware Cloud Foundation instances with NSX FederationSingle or multiple VMware Cloud Foundation instances with multiple availability zonesVxRail NodesStandardSingle VMware Cloud Foundation instanceMultiple VMware Cloud Foundation instances with NSX FederationSingle or multiple VMware Cloud Foundation instances with multiple availability zones   Workload domain type support Management Workload domainVI Workload domain   Scope of guidance Detailed design for solution components.Deployment and initial configuration of intelligent logging and analytics components for management and VI workload domains.Operational guidance for solution components, such as operational verification, password management, and certificate management.Solution interoperability with solution components, such as monitoring and life cycle.   Scope of implementation Deployment and configuration of solution components:Component 1Component 2Configuration of \u0026hellip;Component 1Component 2   Cloud type Public Cloud   Number of VMware Cloud Foundation instances 1   Load Balancing \u0026mdash;   Availability 99%   Authentication, authorization, and access control Use of Microsoft Active Directory over LDAP as the identity provider.Use of security groups and roles for least-privilege access control.Use of service accounts and least-privilege access control for solution integration. The configuration of Microsoft Active Directory Federation Services as the external identity provider is not included in this solution.   Certificate signing Certificates are signed by a certificate authority (CA) that consists of a root and intermediate certificate authority layers.    "},{"id":80,"href":"/docs/networking-security/detailed-design/","title":"Networking and Security Detailed Design","section":"Networking and Security","content":"Networking and Security Detailed Design #  The {VVS for CP Title} validated solution uses {VVS Product} deployed on top of а VMware Cloud Foundation VI workload domain to \u0026hellip;\nLogical Design for {VVS for CP Title} #  The logical design consists of multiple elements that enable you to deploy and manage infrastructure used to {VVS Product Purpose}. [Read more]\nDeployment Specification for {VVS for CP Title} #  When {VVS Product} is enabled on \u0026hellip; [Read more]\nNetwork Design for {VVS for CP Title} #  {VVS Product} requires multiple networks. This section discusses networking design not covered in the NSX-T Data Center detailed design. [Read more]\nLifecycle Management for {VVS for CP Title} #  Lifecycle management design details the decisions for lifecycle management of an instance of {VVS Product}. [Read more]\nInformation Security and Access for {VVS for CP Title} #  You design authentication access, controls, and certificate management for {VVS Product} according to industry standards and the requirements of your organization. [Read more]\n"},{"id":81,"href":"/docs/networking-security/implementation/","title":"Networking and Security Implementation","section":"Networking and Security","content":"Networking and Security Implementation #  Implementing {VVS for CP Title} validated solution includes configuring \u0026hellip; and enabling \u0026hellip;\nTo implement and configure {VVS for CP services}, two alternative methods exist. You can use the user interface of each component in the solution or you can use PowerShell cmdlets. You can directly reuse the PowerShell commands by replacing the provided sample values with values from your VMware Cloud Foundation Planning and Preparation Workbook.\nThis guidance provides a prescriptive path for deploying {VVS for CP solution} using \u0026hellip;, and sample {VVS for CP services} in a {management|VI workload} domain. For more information on other deployment options and configurations, read the {VVS for CP Products} Configuration and Management guide. See the {VVS for CP Products} documentation for more details.\nPrerequisites #   Verify that your environment is configured according to Before You Apply This Guidance and the Developer Ready Infrastructure tab of the VMware Cloud Foundation Planning and Preparation Workbook. If you want to use the included Microsoft PowerShell cmdlets to perform implementation and configuration procedures, verify that your system fulfils the following prerequisites.  Verify that your system has Microsoft PowerShell 5.1 installed. See Microsoft PowerShell. Install the PowerValidatedSolutions PowerShell module together with the supporting modules from the PowerShell Gallery by running the following commands. Install-Module -Name VMware.PowerCLI -MinimumVersion 12.4.1 Install-Module -Name VMware.vSphere.SsoAdmin -MinimumVersion 1.3.7 Install-Module -Name ImportExcel -MinimumVersion 7.1.1 Install-Module -Name PowerVCF -MinimumVersion 2.2.0 Install-Module -Name PowerValidatedSolutions -MinimumVersion 1.7.0  Import the PowerValidatedSolutions and the PowerCLI PowerShell modules by running the following commands. Import-Module -Name VMware.PowerCLI -MinimumVersion 12.4.1 Import-Module -Name PowerValidatedSolutions -MinimumVersion 1.7.0     Proceedure #    [Configure Product 1](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  [Configure Product 2](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  [Deploy and Configure Product 3](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  [Deploy and Configure Product 4](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  Configuring VMware Cloud Director service for Load Balancing as a Service #  See the instructions below on how to deploy and configure VMware NSX Advanced Load Balancer in combination with VMware Cloud Director to provide Load Balancing as a Service capabitilies for end users.\n Load Balancing as a Service in VMware Cloud Director  "},{"id":82,"href":"/docs/networking-security/metering/","title":"Networking and Security Metering","section":"Networking and Security","content":"Networking and Security Metering #  How to start metering your VCPP products with Usage Meter #  The following information helps you understand how Usage Meter detects and meters the usage of the listed VMware products and their features.\nIt also provides insight into how the reported usage data is calculated and appears in the Usage Insight reports.\nMetering Networking and Security Products #  vCenter Server\nVMware Cloud Foundation\nvSAN\nNSX\nCloud Director\nMetering Other Solutions #  Cloud Director Availability\nTanzu\nSRM\nvRealize Operations\nvRealize Network Insight\nvRealize Automation\nMetering Other Products #  Horizon\nHorizon DaaS\n"},{"id":83,"href":"/docs/networking-security/operations/","title":"Networking and Security Operations","section":"Networking and Security","content":"Networking and Security Operations #  After you complete the implementation of the Networking and Security, you perform common operations on the environment, such as \u0026hellip;\nFor operational guidance on the components that are deployed automatically in VMware Cloud Foundation or complement the basic VMware Cloud Foundation configuration, see the VMware Cloud Foundation Operations and Administration Guide in the VMware Cloud Foundation documentation.\nPersonas in Networking and Security #  Personas describe types of system users, aligned with real people and their functions within the organization. You build a persona set based on your organization\u0026rsquo;s requirements for role-based access control.[Read more]\nOperational Verification of Networking and Security #  After you add a {VVS Product/Suite} instance in your VMware Cloud Foundation environment during the implementation of the Networking and Security validated solution, verify that the newly-implemented and reconfigured components are operational and functioning within expected parameters.[Read more]\nCertificate Management for Networking and Security #  The security of your environment depends on the validity and trust of the SDDC component certificates. After you deploy and configure the standalone {VVS Product/Suite} instance to your VMware Cloud Foundation environment, you replace the component certificate if the certificate is expiring or compromised, or some of the certificate attributes, such as the host or organization name, must be changed.[Read more]\nPassword Management for Networking and Security #  Manage the account passwords of the components in your VMware Cloud Foundation environment according to the design objectives and design guidance of Networking and Security validated solution.[Read more]\nShutdown and Startup of Networking and Security #  In certain cases, for example, during hardware or power maintenance of the data center, you must shut down the standalone {VVS Product/Suite} instance in a VMware Cloud Foundation environment in a way that prevents data loss and appliance malfunction, and start it up restoring component integration after the maintenance operation is over.[Read more]\nMetering of Networking and Security #  After implementing Networking and Security you must take steps to ensure that proper usage metering of the new {VVS Product/Suite} begins.[Read more]\n"},{"id":84,"href":"/docs/networking-security/pwd-management/","title":"Networking and Security Password Management","section":"Networking and Security","content":"Networking and Security Password Management #  "},{"id":85,"href":"/docs/networking-security/personas/","title":"Networking and Security Personas","section":"Networking and Security","content":"Networking and Security Personas #  "},{"id":86,"href":"/docs/networking-security/planning/","title":"Networking and Security Planning and Preparation","section":"Networking and Security","content":"Networking and Security Planning and Preparation #  Before you start implementing the components of the Networking and Security solution, you must set up an environment that has a specific compute, storage, and network configuration, and that provides external services to the components of the solution.\nUse the VMware Cloud Foundation Planning and Preparation Workbook to capture environment specific input values that are required during the implementation.\nCarefully review the VMware Cloud Foundation Planning and Preparation Workbook before implementation to avoid costly rework and delays. Capture input values that are specific to your environment and verify that the components that are required by this solution are available.\nThe VMware Cloud Foundation Planning and Preparation Workbook contains inputs for each implementation and configuration procedure. Reference your values from the VMware Cloud Foundation Planning and Preparation Workbook to complete UI or PowerShell procedures.\n#External Services You use services that are external to VMware Cloud Foundation when implementing the solution-name solution.\n   External Service Description     Active Directory (AD) Active Directory (AD) is used to provide authentication and authorization to the VMware Cloud Foundation infrastructure.\nThis includes dedicated Domain Users with least privilege access to act as service accounts for component connectivity.   Domain Name Services (DNS) Domain Name Services is used to ensure components are resolvable by FQDN and by IP address.   Network Time Protocol (NTP) Network Time Protocol is used to synchronize time consistently across components.   Certificate Authority (CA) Certificate Authority is used to provide signed certificates for user facing interfaces.    Before any solution inplementation, you must set up an environment that has a specific compute, storage, and network configuration and that provides external services to the components of the solution. Please find below a list of resources that can help you to plan accordingly for networking and security services in VMware Cloud Director:\n Planning and preparation for LBaaS in VMware Cloud Director  "},{"id":87,"href":"/docs/networking-security/shutdown-startup/","title":"Networking and Security Shutdown and Startup","section":"Networking and Security","content":"Networking and Security Shutdown and Startup #  "},{"id":88,"href":"/docs/networking-security/verification/","title":"Networking and Security Verification","section":"Networking and Security","content":"Networking and Security Verification #  "},{"id":89,"href":"/docs/cloud-infrastructure/nsx-metering/","title":"NSX Metering and Reporting","section":"Cloud Infrastructure","content":"NSX Metering and Reporting #  Usage Meter 4.5.0.1 can detect specific NSX features available to Virtual Machines, which determines the NSX edition billed to a VM.\nUsage Meter 4.5.0.1 tracks NSX usage by Virtual Machine based on the networking services available to the Virtual Machine.\nConfiguration #  The Usage Meter administrator must configure the NSX Manager endpoint and credentials using the Usage Meter web application. There is one NSX Manager for each vCenter server instance utilizing NSX.\nAll virtual machines deployed to an NSX prepared host are candidates for NSX usage. The administrator needs to consider partitioning tenant VMs onto networks depending on their NSX usage. To avoid NSX metering for Virtual Machines that are not utilizing NSX, consider deploying the VMs to a vCenter cluster that is not prepared for NSX. The figure below shows two different vCenter clusters within the same vCenter domain. Virtual machines that are not utilizing NSX should be deployed to the cluster that is not prepared for NSX.\nFeature Detection #  The fact that a virtual machine can potentially access a service through the network will result in the VM being metered for the service. A VM will be considered as using NSX for metering purposes if:\n The virtual machine is connected to a network (backed by any type of switch) with access to an NSX edge. The virtual machine is connected to an NSX logical switch or distributed switch on an NSX prepared host. The virtual machine is referenced by a non-default distributed firewall rule, including groups/policies.  Note: The default DFW rule is the ‘Allow’ action.\n The virtual machine is connected to a network (backed by any type of switch) with access to a distributed logical router. If a virtual machine is connected to an Edge service through the network, the VM will be metered for the service.  Usage Meter examines the switches, routers, and gateways managed by the NSX Manager, and creates a graph of connected networks. It then determines the VMs that are connected to each switch. VMs are metered for NSX usage based on their ability to reach a gateway or router through the network. Usage Meter does not examine individual Virtual Machines, network traffic, or routing tables to determine actual usage.\nUsage Meter examines the list of NSX features available to a Virtual Machine and selects the minimum license needed to enable the features. Each VM is metered based on the NSX edition and the VMs vRAM configuration. The following table lists the NSX components examined by Usage Meter to determine available NSX-V features.\nNote: NSXFint is a column that appears in the Virtual Machine History report for VMs that are using NSX. NSXFint has an integer value and represents the NSX features used by a metered VM. The NSXFint value per NSX-v feature is shown in the table below. The NSXFInt value for each metered VM will be the integer value of the NSX feature or the integer sum of all NSX features used by that VM.\nFor example, a VM using the NSX Edge load balancing and Distributed firewalling features will have the following value in the NSXFInt column = 2+64=66.\nNote: Each NSX-v feature has a unique NSXFint value. However, the following NSX-v features are all reported as integer 1 and are essentially undistinguished: Distributed switching and routing, NSX Edge Firewall, NAT, Integration with vRealize, and OpenStack, VPN (IPSEC and SSL). These features are Base features, and if a VM uses a couple of them, then Usage Meter will only meter them as a single Base feature used by that VM. As a result, the sum of these NSX-v features will have an NSXFint value equal to 1.\nFor example, if a VM uses Distributed switching and routing and NSX Edge Firewall, this VM will only have a value of NSXFint=1.\nTo find the features used by a VM, subtract from the NSXFint value the highest possible value equal to or less than the NSXFint value, and continue the subtraction until NSXFint =0.\nFor example, let’s have a VM that has NSXFint = 9.\n We will check in the table below which NSX feature has a value equal to or less than 9 and subtract it from NSXFint. In this case, the highest number close to NSXFint =9 is 8, corresponding to Dynamic Routing with ECMP (Active-Active). The result of the subtraction is NSXFint - 8= 9-8=1. We will check again in the table what NSX feature has a value equal to 1. This feature is a Base feature and could be any of the following features: Distributed switching and routing, NAT, VPN (IPSEC \u0026amp; SSL), NSX Edge Firewall, Integration with vRealize and OpenStack. When we also subtract it from NSXFint, the NSXFint value will equal 0. In conclusion, NSXFint =9 is NSXFint=8+1, corresponding to ECMP dynamic routing and a Base feature.     NSX-V Feature NSX Feature String NSX-V Edition Flex NSXFint VMs declared as using this feature Provided By     Distributed switching and routing, NAT, VPN (IPSEC \u0026amp; SSL), NSX Edge firewall, Integration with vRealize and OpenStack BASE Base 1 All VMs that are connected to a Logical Switch. All VMs on all networks serviced by the edge. ESXi Hosts prepared Edge gateway   NSX Edge load balancing DLB Base 2 All VMs on all networks serviced by the edge. Edge gateway   Dynamic routing with ECMP ECMP Base 4 All VMs on all networks serviced by the edge. Edge gateway   Dynamic Routing with ECMP (Active-Active) DYNRT Base 8 All VMs on all networks serviced by the edge. Edge gateway   Software L2 bridging to physical environment SWL2 Base 16 All VMs on all networks serviced by the edge. SW L2 bridging to a physical environment   Distributed firewalling DFW Professional 64 All VMs referenced in the Source rule or Target rule sections of a firewall rule. Default Firewall rules excluded. Hosts prepared   Remote Gateway (also known as L2VPN) RemoteGW Professional 128 All VMs on all networks serviced by the edge. Edge gateway   Multi-Site NSX Optimizations Universal Advanced 256 All VMs on the ULS serviced by the edge. ULS, UDFW   Integration with HW VTEPs HWVTEP Advanced 512 All VMs on the LS bridged with HW VTEP. Integration with HW VTEPs   Service insertion (3rd party integration) DFW3 Advanced 1024 Same as Distributed Firewalling. Distributed firewalling   Active Directory Integrated firewall DFW_AD Advanced 2048 Same as Distributed Firewalling. Distributed firewalling   Context Aware firewall with Layer 7 DFWL7 Advanced 4096 All VMs on all networks serviced by the edge. Edge gateway   Server activity monitoring SAM Advanced 65536 Same as Distributed Firewalling. Distributed firewalling             The following table lists the combinations of NSX features available to a Virtual Machine and the resulting NSX edition that will be metered.\n   Is the host prepared for NSX-V? Is the VM connected to Logical Switch? At least one non-default rule is applicable to a VM Is NSX Edge available to a VM? NSX Edition metered Scenario in Diagram below     No n/a n/a No none    No No n/a Yes at least* Base Edition    Yes No No No none 1   Yes No No Yes at least* Base Edition+ 5   Yes No Yes No Advanced Edition    Yes No Yes Yes at least* Advanced Edition    Yes Yes No No Base Edition 1   Yes Yes No Yes at least* Base Edition 2, 3, 6   Yes Yes Yes No Advanced Edition    Yes Yes Yes Yes at least* Advanced Edition     *Depending upon the edge services configured. NSX-V Scenario Samples #  Scenario One: Minimum NSX configurations\nA virtual machine VM1 is deployed to a vSphere host on an NSX enabled cluster. The virtual machine is not connected to a switch. The VM is automatically connected to the NSX Distributed Firewall.\nMetering By default, the VM is connected to a distributed Firewall. VM1 will not be metered for NSX usage unless the default distributed firewall rules have been modified to reference the VM. If the DFW is in use using non-default rules, then the VM will be metered for NSX Advanced Edition.\nA virtual machine VM1 is deployed to a host on an NSX enabled cluster. The VM is connected to a switch. The VM is automatically connected to the NSX Distributed Firewall. The administrator has not modified the default DFW rules.\nMetering VM1 will be billed for NSX (Base Edition) since it is connected to a distributed switch.\nScenario Two: Base Edition Example\nTwo virtual machines VM1 and VM2 are connected to different VXLAN backed networks with routing through a Distributed Logical Router. Both virtual machines have access to a remote network through an Edge Gateway ESG, running a Firewall service. Neither of the VMs are referenced by non-default DFW rules.\nMetering VM1 and VM2 are both metered for NSX Base edition since both distributed switching and routing, and edge firewall are base edition features. **Scenario Three:**Active / Active Gateway\nDynamic routing with ECMP (Active-active) Edge\nMetering VM1, VM2, and VM3 are billed as NSX Base since ECMP is a Base feature, and all VMs have potential access to the edge. This scenario illustrates the feature selection based on the most advanced feature reachable by a Virtual Machine through the network.\nScenario Four: NSX Partitioned by Tenant\nTwo different Tenants A and B, each with their own network and ESG. No shared Switch, DLR or ESG.\nMetering VM1 is metered for NSX usage based on the services running on the ESG1 accessible to VM1. VM2 is metered for NSX usage based on the services running on the ESG2 accessible to VM2.\n Scenario Five: ESG on vSphere Distributed Switch (Not a logical Switch)\nVM1 on an NSX prepared Cluster and attached to vSphere Distributed Switch, not a Logical Switch. ESG running a load balancer service attached to the same vSphere Distributed Switch. VMs are using only default DFW rules.\nMetering VM1 is metered for NSX (Base Edition) since Edge Load balancing is a Base feature and is accessible to the VM through the distributed switch.\nScenario Six: NSX Cross vCenter shared ESG\nAn NSX Edge Gateway, ESG shared between vCenter Domains using a Universal Logical Switch. Both virtual machines are using only default DFW rules.\nMetering VM1 and VM2 are both billed as NSX Enterprise since the ESG connects to a Universal Logical Switch, and all VMs have access to the ESG.\nNSX Reporting #  NSX usage can be included in reports as a license edition line item or as a standalone line item. Usage reporting is based on editions unless standalone reporting is requested. NSX-V Q\u0026amp;A\nQ1: What are the minimum configurations that Usage Meter will detect as NSX usage?\n A VM connected to a Logical Switch will be detected as an NSX BASE edition. This is the case even when no distributed logical routers or NSX edges are created. A VM with a vNIC referenced in a distributed firewall rule (non-default) will cause the VM to be detected as NSX Advance, even if the VM is not connected to a logical switch, distributed logical router, or edge.  Q2: Are the Virtual Machines that implement NSX functionality (for example, NSX Controller VMs and Edge Gateways) billed for NSX usage?\n Yes, NSX management VMs are billed for NSX Base usage. The only VM excluded from metering is the Usage Meter appliance.  Q3: An NSX Edge Gateway can be installed on a vCenter cluster that is not prepared for NSX. In this case, is the NSX Edge and the Virtual Machines utilizing the edge billed for NSX usage?\n Installation of an edge gateway on unprepared servers is supported only when the Edge is running the L2VPN Client. It is assumed that the client hosting the gateway will not be metered by Usage Meter.  Q4: Does Usage Meter infer the content of a distributed firewall rule? For example, if two rules cancel out one another.\n No, Usage Meter does not examine the relationships between firewall rules. Usage Meter will meter the VM for DFW usage if any of the DFW rules in a policy reference the vNIC either directly or through a security group (static or dynamic).  Q5: If a VM is connected to multiple networks, what rate is metered at?\n The VM is metered at the rate of the network with the highest level of service features.  Q6: If a VM is listed in the NSX Firewall exclusion list, does Usage Meter bill for Firewall usage?\n No, Usage Meter does not bill DFW usage for VMs in the NSX firewall exclusion list.  Q7: On an Edge configured as a Remote Gateway (also known as L2VPN), what VM’s are metered for NSX Usage?\n L2VPN can be configured as \u0026ldquo;Server\u0026rdquo; and \u0026ldquo;Client\u0026rdquo;. In both cases, all VM\u0026rsquo;s with access to the Edge are metered by Usage Meter.  Q8: How does Usage Meter detect if NSX Cross vCenter is configured?\n Usage Meter detects the Universal logical switch configured on a local edge.  Q9: Does Usage Meter detect and bill for NSX vShield Endpoint (guest introspection to support anti-malware) solutions?\n Yes, Usage Meter detects vShield Endpoint as a base NSX feature.  Q10: An NSX Edge can be deployed to an ESX Server that is not prepared for NSX. Can the edge be connected to a logical switch?\n No, it is not possible to create a Logical Switch on a server that is not prepared for NSX.  Q11: Are Virtual Machines connected to a vNetwork Standard Switch (vSwitch) or vNetwork Distributed Switch (dvSwitch) metered for NSX Usage?\n Yes, all switch types that are serviced by an NSX Edge are metered. Logical switches will be metered even if there is no NSX Edge servicing it.  NSX-T Features #  Usage Meter 4.5.0.1 inspects the topology of the virtual NSX network, obtaining lists of all known:\n Virtual machines Virtual Network Interfaces Logical ports Logical switches (aka \u0026ldquo;segments\u0026rdquo;) Logical routers (aka \u0026ldquo;gateways\u0026rdquo;)  Usage Meter reports usage for each VM, based on the feature and license editions described in the table below. Note: NSXFint is a column that appears in the Virtual Machine History report and represents the sum of the integer code of the NSX features used by a VM. Each NSX- T feature has a unique NSXFint value. In the table below, you can find the NSXFInt value for each NSX-T feature metered by Usage Meter. The value of the NSXFInt column in the Virtual Machine History report for each metered VM will be the sum of all NSX-T features used by that VM. For example, a VM using the Layer 2 VPN (aka \u0026ldquo;Remote Gateway\u0026rdquo;) and 3rd party service insertion features will have the following value in the NSXFInt column = 128+1024=1152. To find the features used by a VM, subtract from the NSXFint value, the highest possible value equal to or less than the NSXFint value, and continue the subtraction until NSXFint =0. For example, let’s have a VM that has NSXFint value = 3.\n We will check in the table below which NSX feature has a value equal to or less than 3 and subtract it from NSXFint. In this case, the highest number close to NSXFint =3 is 2, corresponding to Edge load balancing. The result of the subtraction is NSXFint - 2= 3-2=1. We will check again in the table what NSX feature has a value equal to 1. This feature is Distributed switching and routing. When we also subtract it from NSXFint, the NSXFint value will equal 0. In conclusion, NSXFint =3 is NSXFint=2+1, corresponding to Edge load balancing and Distributed switching and routing.     NSX Feature NSX Feature String NSX Edition Flex NSXFint VMs declared as using this feature     Distributed switching and routing BASE Base 1 All VMs connected to any NSX-T logical switch have this feature.   Edge Load Balancing DLB Base 2 A VM is metered as using this feature if it is connected (via switches and routers) to a router that has the load balancing service enabled.   Dynamic Routing with ECMP ECMP Base 4 Any VM connected (via switches and tier-1 routers) to a tier-0 router that is ECMP-enabled, will be metered as using this feature.   SW L2 Bridging to physical environment SWL2 Base 16 Any logical ports with attachment type \u0026ldquo;BRIDGEENDPOINT\u0026rdquo; use this feature, and all VMs that are connected to a logical switch that has such a port, will be metered as using this feature.   Network Address Translation NAT Base 32 All VMs connected to logical switches connected directly or indirectly to a router that has NAT rules are metered using this feature.   Distributed Firewall DFW Prof 64 Any VM that is referenced directly or indirectly in the sources or destinations of an enabled Distributed Firewall rule, will be metered for this feature, unless the appliedTos property of the rule indicates that the rule is not applied to that VM.   Layer 2 VPN (aka \u0026ldquo;Remote Gateway\u0026rdquo;) L2VPN Prof 128 Any segment/logical switch with a logical port connected to an L2VPN session uses this feature, and VMs attached to that logical switch will be metered as using this feature.   3rd party service insertion DFW3 Adv 1024 Any VM that is referenced directly or indirectly in the sources or destinations of an enabled service insertion rule will be metered for this feature, unless the appliedTos property of the rule indicates that the rule is not applied to that VM.   Identity firewall (aka \u0026ldquo;Integration with Active Directory\u0026rdquo;) DFW_AD Adv 2048 Any VM metered for DFW because of an Active Directory-enabled firewall rule will also be metered for this feature.   Context-aware Firewall with Layer 7 DFWL7 Adv 4096 Any VM metered for DFW will also be metered for this feature if the firewall rule that references the VM has a non-empty context profiles list.   Virtual Private Network using IPSEC IPSEC Base 8192 Any VM that is connected (via logical switches and routers) to a logical router that has IPsec service and IPsec sessions enabled is metered as using this feature.   Edge Firewall (aka Gateway firewall) GFW Base 16384 Any VM connected (via switches and routers) to a router that has one or more specified gateway firewall rules, will be metered as using this feature. The difference between distributed and gateway firewall rules is that distributed firewall sections (groups of rules) have an enforced_on attribute set to \u0026ldquo;VIF\u0026rdquo;, and gateway firewall sections have the enforced_on attribute set to LOGICALROUTER.   IPv6 Layer 3 forwarding IPV6STATIC Base 32768 If an NSX-T manager node has api/v1/global-configs/RoutingGlobalConfig configured to support IPv6 Layer 3 forwarding, then all the VMs which have a network managed by NSX-T manager node are metered with this feature.   URL Filtering (as part of a firewall) URL Adv 131072 Any VM metered for the DFWL7 feature will also be metered for this URL feature if it is referenced by a firewall rule with a context profile that specifies a domain name.   Container networking NCP Adv 262144 VMs are metered as using this feature if their VIF is connected to a logical port that has a tag with a scope of ncp/cluster.   NSX Federation FED Ent Plus 524288 This feature is detected if Global Manager is installed and there is at least 1 Local Manager connected to the Global Manager. This is a global configuration. If this feature is enabled, all the hosts under the Local Manager are said to be using Federation.   Kubernetes VM in vSphere PKS cluster PKS Adv 2097152 If a VM would be metered for the NCP feature and if its ncp/cluster tag specifies a cluster name and if the named cluster has a type of \u0026ldquo;Kubernetes\u0026rdquo;, and an infrastructure type of \u0026ldquo;vSphere\u0026rdquo;, then the VM is metered as using this PKS feature instead of the NCP feature.   Multi vCenter Network and Security MVC Adv 4194304 If an NSX-T manager is connected to more than one vCenter compute manager, then all the VMs that the NSX-T manager knows about will be metered with this feature.   IPv6 Layer 3 forwarding and bgp configured on corresponding Tier-0 router IPV6DYN Adv 8388608 If an NSX-T manager node has api/v1/global-configs/RoutingGlobalConfig configured to support IPv6 Layer 3 forwarding and bgp, is configured on the corresponding Tier-0 router, then all the VMs which are connected to Tier-0 router gateway are metered with this feature.   Tier-0 router configured as VRF VRF Prof 16777216 If an NSX-T manager node has a Tier-0 router configured as VRF, then all the VMs connected to Tier-0 router gateway on which this VRF instance is configured will be metered with this feature.   NSX intelligence appliance NSXINT Ent+ 33554432 If an NSX-T manager node has an NSX intelligence appliance configured, then all the VMs which have their network managed by NSX-T manager node are metered with this feature.   Tier-0 router configured with EVPN EVPN Ent+ 67108864 If an NSX-T manager node has a Tier-0 router configured with EVPN, then all the VMs connected to those Tier-0 router gateway will be metered with this feature.   NSX Distributed IDS IDS_STANDALONEHOST Adv 2147483648 This feature is enabled on a per host basis. When it is enabled, all the VMs connected to that host are counted.   Integration with Distributed Firewall IDFW Adv 4294967296 This is a global feature. When it is enabled, all the hosts/VMs under the NSX Manager are counted.    NSX-T Scenario Sample #  Only metering of eVPN inline mode and non-telco use case is supported. The eVPN server mode is not covered. In this scenario, non-telco eVPN inline mode uses VRF on T0, getting mapped to MP-eBGP via RD/RT combination and VMs belonging to VRF on south-side/downlink of T0 will be behind T1.\n "},{"id":90,"href":"/docs/networking-security/vcd-lbaas-planning-and-preparation/","title":"Planning and Preparation for Load Balancing as a Service in VMware Cloud Director","section":"Networking and Security","content":"Planning and Preparation for Load Balancing as a Service in VMware Cloud Director #  Introduction #  Before you start implementing the Load Balancing as a Service in VMware Cloud Director solution, you must set up an environment that has a specific compute, storage, and network configuration and that provides external services to the components of the solution.\nRequirements #  Software #  To implement load balancing as a service with VMware Cloud Director, your software versions must meet the requirements specified in the VMware Product Interoperability Matrix.\nResources #  Before you deploy NSX Advanced Load Balancer, you must provide sufficient compute and storage resources to meet the footprint requirements of the Controller cluster and the Service Engines.\n Avi Controller Sizing Sizing Service Engines  Networking #  This load balancing as a service solution is based on several management virtual appliances that require to be deployed in a management infrastructure. Latency requirements are critical to guarantee proper functioning and performance:\n Latency among Avi controllers – Less than 10 ms Latency between any Avi SE to any Avi Controller – Less than 75 ms recommended Latency between Avi Controller and NSX-T Manager – Less than 10 ms recommended  Best practice is to co-locate in the same port group/management infrastructure as NSX-T   Latency between Avi Controller and VMware Cloud Director – Best practice is to have have VCD cells in the same management infrastructure as NSX-T manager and Avi Controller  The Avi Controller and service engines use several ports for management and control communication: Protocol Ports Used by Avi Vantage for Management Communication.\nThe firewall should allow traffic for these ports.\nPreparation #  The solution comprises of the Avi Controller which uses APIs to interface with the NSX-T manager and vCenter to discover the infrastructure. It also manages the lifecycle and network configuration of the service engines.\nThe NSX-T Cloud is the object that permits the integration with the NSX-T manager and the vCenter server(s).\nThe user accounts configured on the Avi Controller require the following roles and permissions for the integration to work successfully:\n Roles and Permissions for vCenter user Roles and Permissions for NSX-T user  vSphere #  When using an NSX-T Cloud, the Avi Controller uploads the service engine image to the content library on the vCenter server and uses this to create new virtual machine every time a new service engine is required. The content library must be created on vCenter before configuring the NSX-T cloud.\nNSX-T #  The first network adapter of the service engine VM is reserved for management connectivity, and the remaining 9 data interfaces (network adapter 2 to 10) for the service engine VM to the VIP or data segment.\nThe Avi SE management interface can be connected to an overlay (recommend) or a VLAN logical segment. When connected to an overlay segment, it also needs a tier-1 gateway to provide external connectivity to be able to reach the Avi controller management IP. It is recommended to have a dedicated tier-1 gateway and segment for Avi service engine management.\nIf VLAN-backed logical segments are used instead of overlay transport zone for the management network in the NSX-T Cloud, refer to this page: NSX-T VLAN Logical Segment.  Regardless of the solution (overlay or VLAN segment for the SE management network), the NSX-T topology must be created upfront the NSX-T Cloud configuration. In the case of overlay segment for the SE management network:\n Create a tier-1 gateway that will be used to connect the SE management network. Create 2 overlay segments: one for the management network, and one as a dummy data network segment. Enable DHCP Server at the tier-1 gateway level and configure DHCP on the management segment.  More details here: Configuring Management Networking for SE.\nNext Steps #  One the environment is ready, you can proceed with the VMware NSX Advanced Load Balancer deployment and configuration in combination with VMware Cloud Director to provide Load Balancing as a Service: Load Balancing as a Service in VMware Cloud Director.\n"},{"id":91,"href":"/docs/cloud-infrastructure/rabbit-design/","title":"RabbitMQ Design","section":"Cloud Infrastructure","content":"RabbitMQ Design #  Detailed design information for RabbitMQ goes here.\n Deployment model Design decisions Sizing Others  "},{"id":92,"href":"/docs/dr-migration/setup-vcda/","title":"Setting Up VMware Cloud Director Availability","section":"DR and Migration","content":"Setting Up VMware Cloud Director Availability #  Port mapping #  The communication between the different appliances occurs at the following ports as shown on the diagram.\nRequirements #  Here is a high-level list of the requirements to deploy VMware Cloud Director Availability. For more details, please refer to the official documentation.\n  DNS and NTP server\n  SSO Lookup Service Address\n  Routing and Firewall Ports in place\n  Compatible versions of vCenter and VMware Cloud Director – open the VMware Product Interoperability Matrices\n  VMware Cloud Director Availability initial configuration #  The deployment of the VMware Cloud Director Availability appliances in the vCenter Server is done by following these steps:\n  Select the OVF template.\n  Name the virtual machine.\n  Select a destination compute resource.\n  Review the virtual machine details.\n  Read and accept the license agreement.\n  Select the appliance that we are going to deploy.\n  Pick the storage for the disk files.\n  Specify the network.\n  Enter the deployment properties such as root password, NTP server, IP address, gateway, DNS, and more.\n  Validate that all the details are correctly entered on the summary screen, and deploy the virtual machine.\n  After the deployment of the appliances, you need to run the initial setup wizard. It is designed to guide you through the essential steps to configure all the appliances at the same time, no matter if it is a combined or a distributed environment (only the distributed setup is recommended for production).\nFor example, you can define the Lookup service, attach a Cloud Replicator Appliance or a Cloud Tunnel Appliance, and even change the root password for of all appliances, without any necessity to log in to each of them and change it in their UI.\nA detailed look at the initial setup wizard #  YouTube video showing the exact steps\nAfter you successfully deploy the OVA templates for all the appliances, the next step is to run the initial setup wizard.\nFirst, you need to login to the appliance by opening your browser and entering the following URL: https://\u0026lt;Cloud-Replication-Management-Appliance-URL\u0026gt;/ui/admin.\nYou will see the login screen of the VMware Cloud Director Availability Cloud Service admin UI. There, you have to enter the password defined during the deployment process.\nSince it is the first login to the system, you will be prompted to change the password.\nAfter you enter a new password that matches the password policy (it should be at least 8 symbols and contain at least one uppercase, lowercase, number, and special character), you will see the welcome screen (Picture 3).\nAfter reading and complying with the information on the welcome screen, proceed with the configuration of the Cloud Director Availability, by clicking Run Initial Setup Wizard. Note that all the steps are mandatory, and you cannot skip any of them.\nThe first thing to do is to enter your license key.\nNext, you need to give your site a name and provide the Service Endpoint address. In case you are not sure about the address at the moment of setup, you can leave it empty and fill it later in the VMware Cloud Director Availability portal (Configuration menu).\nOn the next screen, you have to fill in your VMware Cloud Director Endpoint address and an administrator’s credentials. Note that you only need to type the Endpoint URL, and the wizard will automatically add the https:// prefix and /api suffix.\nBy clicking Next, you are prompted to reject or accept the VMware Cloud Director certificate. To proceed further, you need to accept it.\nAfter accepting the certificate, you will be asked for your consent to participate in the VMware\u0026rsquo;s Customer Experience Improvement Program (\u0026ldquo;CEIP\u0026rdquo;). By default, it is checked, but you can uncheck it and proceed with the wizard.\nThe penultimate step is to connect your Cloud Replicator Appliance(s) (if you have more than one). An important note - on this step, you enter the Lookup Service Address. It is used for all your replicators and the tunnel.\nAfter entering all the Lookup Service Address, Replicator Service Address, and root password, you need to click TEST CONNECTION to verify the connectivity and connect to the Cloud Replicator Appliance. Similarly, to the VMware Cloud Director Service Endpoint, you only need to put the IP/URL, and the port, prefix, and suffix are added automatically. You need to perform the same set of actions for all the Cloud Replicator Appliances you want to attach.\nRight after clicking the TEST CONNECTION button, you will be prompted to reject or accept the Cloud Replicator Appliance certificate. To proceed, accept the certificate.\nIf you haven\u0026rsquo;t logged in the Cloud Replicator Appliance UI so far, you will see a message that the root password has expired. You can directly set a new root password from the wizard. The password policy is the same as for the Cloud Replication Management Appliance. If you change the password before running the wizard, you will proceed directly to the last step without being asked to change the root password.\nYou also need to provide the SSO administrator credentials.\nThe ADD A REPLICATOR SERVICE INSTANCE button will let you connect additional Replicator Services if wanted.\nIf all the details are entered correctly, you will be prompted to reject or accept the Lookup Service certificate. To proceed, accept the certificate.\nThe very last step of the setup process is to connect to the Cloud Tunnel Appliance. You don\u0026rsquo;t need to define the Lookup Service Address again as the wizard uses the one set on the previous step. You only need to enter the API URL and the root password. Note that the prefix and port are added automatically.\nSimilarly, to the previous step where we connected to the Cloud Replicator Appliance(s), if you haven\u0026rsquo;t changed the root password yet, you could do it after clicking the CHECK PASSWORD button. Note that if you have already changed the password, the UI will direct you to the next action.\nBy clicking Next, you will be prompted to reject or accept the Cloud Tunnel Appliance certificate. To go through, you need to accept it.\nThe last stage of the wizard is a summary that will show you some of the details you entered. Use the Finish button to close the initial setup wizard and start using your newly configured VMware Cloud Director Availability.\nOn the picture below, you can see how the home screen looks like after performing a successful configuration.\n"},{"id":93,"href":"/docs/dr-migration/vcda-vmc-on-aws-sddc/","title":"Setting Up VMware Cloud Director Availability at a VMC on AWS SDDC","section":"DR and Migration","content":"Setting Up VMware Cloud Director Availability at a VMC on AWS SDDC #  Prerequisites #  To be able to successfully deploy and run VMware Cloud Director Availability in your VMC on AWS environment, you will need to make sure the following requirements are met:\n Have a properly deployed Software-Defined Data Center (SDDC). Have a VMware Cloud Director deployed at VMC on AWS (Cloud Director service) that is linked to the SDDC. Have defined at least one Organization, OrgVDC with Hardware Version (Default is Hardware Version 14 – vCenter 6.7.0) higher than one you have in the vCenter you would like to use as a source location Have defined at least one tenant admin user. (Recommended) Have a dedicated routed network for the VMware Cloud Director Availability appliances. (You can still use any existing routed network). Obtain its CIDR from Networking \u0026amp; Security \u0026gt; Network \u0026gt; Segments.  Obtain the proper Source NAT Public IP of your SDDC from Networking \u0026amp; Security \u0026gt; Overview.  Obtain the proper DNS Service IP of your SDDC from Networking \u0026amp; Security \u0026gt; System \u0026gt; DNS.  Create a Trusted IPs group from Network \u0026amp; Security \u0026gt; Inventory \u0026gt; Group \u0026gt; Compute Groups where you will add your public IP address so you can access the VMware Cloud Director Availability portal. Then in this group you will need to add all your tenant IP addresses so they can connect their on-premises appliances to your VMware Cloud Director Availability cloud.  Create a Compute Gateway Firewall Rule with the following settings to allow access from your trusted IPs to the environment:  Create a new Resource Pool for the VMware Cloud Director Availability Appliances under the Compute-Resource Pool.  Deployment #  Below you can find the necessary configuration steps for the separate appliances case and NOT for the combined appliance.\nPlease repeat the mentioned steps for each of the appliances – Cloud Replication Management appliance, Cloud Replicator appliance and Cloud Tunnel appliance.\n  Log in to the vCenter UI from your VMC console.\n  Deploy the OVA template in the Resource pool created in Requirement #8 in the Prerequisites section.\n  The deployment steps are similar to the typical VMware Cloud Director Availability Deployment. There are only a few considerations to be taken:\n On Step 7 – Select Storage: Select Workload Datastore   On Step 8 – Select networks: Select the dedicated network for VMware Cloud Director Availability from Requirement #4 in the Prerequisites section.    On Step 9 – Customize template:\n In the Address field provide an address in the dedicated network for VMware Cloud Director Availability from Requirement #4 in the Prerequisites section. In the DNS servers field provide the DNS Service IP address from Requirement #6 in the Prerequisites section.      After you have successfully deployed the 3 appliances, you should see something similar to:\n  Additional SDDC configuration #  To be able to successfully pair any on-premises instance to the VMware Cloud Director Availability cloud instance hosted at VMC on AWS, you need to perform some additional steps and prepare your SDDC network settings.\nPlease follow the procedures in their exact order as they are listed in this document.\nAdd Inventory Services #  You need to define 2 Services that will be later used in the Firewall settings. One is for the Cloud Management Portal and the other one is for the Cloud Tunnel endpoint.\nFollow these steps to get your services defined:\n Navigate to your SDDC Network \u0026amp; Security \u0026gt; Inventory \u0026gt; Services. To add the Management Portal service, click on ADD SERVICE. Give the service a name.  Click on Set Service Entries. Enter a name for the entry, select the Service Type to be TCP and the Destination Port to be 8046.  Click Apply and then Save. To add the Tunnel endpoint service, click on ADD SERVICE. Give the service a name.  Click on Set Service Entries. Enter a name for the entry, select the Service Type to be TCP and the Destination Port to be 8048.  Your services are ready.  Request Public IPs #  You will need to request 2 new Public IP addresses – one for the Cloud Management Portal and one for the Cloud Tunnel. To request them, please follow the steps below:\n Navigate to your SDDC Network \u0026amp; Security \u0026gt; System \u0026gt; Public IPs. Click on REQUEST NEW IP. Put a meaningful note for your Cloud Management Portal IP. Click Save. Click on REQUEST NEW IP. Put a meaningful note for your Cloud Tunnel IP. Click Save. Your 2 new Public IPs are ready.  Create a Compute Group #  You need to create a Compute Group that will be later used in the Firewall configuration. To create a Compute Group, please follow the steps below:\n Navigate to your SDDC Network \u0026amp; Security \u0026gt; Inventory \u0026gt; Groups \u0026gt; Compute Groups. Click on ADD GROUP. Give the Compute Group a meaningful name.  Click on Set Members and select the IP Addresses tab. Enter the network details from Requirement #4 in the Prerequisites section.  Click on Apply and then Save. The Compute Group is now ready.  Create Management Groups #  For enabling your Cloud Replicator to perform its replication jobs with ESXi, you need to create 2 Management Groups that will be later used in the Management Gateway Firewall configuration. To create them, please follow these steps:\n Navigate to your SDDC Network \u0026amp; Security \u0026gt; Inventory \u0026gt; Groups \u0026gt; Management Groups. Click on ADD GROUP. Give the first Management Group a meaningful name.  Click on Set Members. Enter the private IP that you will set to the Cloud Replicator.  Click on Apply and then Save. Click on ADD GROUP. Give the second Management Group a meaningful name.  Click on Set Members. Enter the Public IP that you collected in Requirement #5 in the Prerequisites section.  Click on Apply and then Save. Your Management Groups are created.  Configure the Compute Gateway Firewall #  You need to do some configurations to the Compute Gateway Firewall in order to allow the inbound traffic to the Cloud Tunnel and also the outbound traffic from your VMware Cloud Director Availability appliances.\nThese are the necessary steps:\n Navigate to your SDDC Network \u0026amp; Security \u0026gt; Security \u0026gt; Gateway Firewall \u0026gt; Compute Gateway. Click on ADD RULE. Give the Appliances Outbound Rule a meaningful name. Select the Compute Group that you created in section Create a Compute Group in the Sources column. Leave everything else with its default value. Make sure the Rule is enabled. Click on ADD RULE. Give the Cloud Tunnel Inbound Rule a meaningful name. Select the Cloud Tunnel Endpoint service that you created in Add Inventory Services section. Leave everything else with its default value. Make sure the Rule is enabled. Click on Publish. The Firewall Rules are ready.  Configure the Management Gateway Firewall #  To enable the internal communication between the different VMware Cloud Director Availability components and the ESXi and vCenter, you need to configure 2 Compute Gateway Firewall rules. To create them, please follow these steps:\n Navigate to your SDDC Network \u0026amp; Security \u0026gt; Security \u0026gt; Gateway Firewall \u0026gt; Management Gateway. Click on ADD RULE. Give the ESXi Provisioning Rule a meaningful name. Select as follows:  Sources – the Cloud Replicator Private IP Management Group that you defined in the Create Management Groups section. Destinations – ESXi. Services – Provisioning and Remote Console (TCP 902).   Click on ADD RULE. Give the Appliances Inbound rule a meaningful name. Select as follows:  Sources – the Management Group that has the Public IP as a member that you defined in the Create Management Groups section. Destinations – vCenter. Services – HTTPS.   Click on Publish. The Firewall Rules are defined.  Add NAT rules #  NAT rules are necessary to forward the incoming traffic to the correct appliances. You need to add 2 NAT rules – one for the Cloud Management Portal and one for the incoming Cloud Tunnel traffic.\nThe Cloud Management Portal rule can be removed after the initial configuration is done as the Portal is accessible through the VMware Cloud Director Availability Plug-in in Cloud Director service.\nThe steps to add NAT rules are:\n Navigate to your SDDC Network \u0026amp; Security \u0026gt; Network \u0026gt; NAT. Click on ADD NAT RULE. Give the Cloud Management Portal Rule a meaningful name. The rule settings should be as follows:  Public IP – the Public IP that you requested for the Cloud Management Portal in the Request Public IPs section. Service – the Cloud Management Service that you defined in the Add Inventory Services section. Public Port – 8046. Internal IP – the Cloud Management Replicator Appliance internal IP address. Internal Port – 8046. Firewall – Match Internal Address. Click Save.   Click on ADD NAT RULE. Give the Cloud Tunnel Inbound Rule a meaningful name. The rule settings should be as follows:  Public IP – the Public IP that you requested for the Cloud Tunnel in the Request Public IPs section. Service – the Cloud Tunnel Service that you defined in the Add Inventory Services section. Public Port – 443. Internal IP – the Cloud Management Replicator Appliance internal IP address. Internal Port – 8048. Firewall – Match Internal Address. Click Save.   The NAT rules are created.  Initial setup #   Make sure your external IP address is in the Trusted IP list that was defined in Requirement #7 in the Prerequisites section. Navigate to (https://\u0026lt;Cloud_Management_Portal_Public_IP\u0026gt;:8046/admin). Log in as root and change the password when prompted. Click on Run the initial setup wizard. Provide the VMware Cloud Director Availability license. Give the site a meaningful name and check only the VMC data engine to be activated.  Provide the Cloud Director service public URL in the following format – (https://CDs_URL/api). Enter a System Administrator or CDS Provider Admin user and its password. For example, vcdaadmin@sytem. Any other user types except Local users are currently not supported.  Provide the VMC Lookup Service URL which is the vCenter public URL. Use this format – (https://vCenter_URL:443/) lookupservice/sdk. Enter the internal IP address of the Replicator (for example, (https://172.26.46.202:8043)) and its root password. You might be prompted to change the root password, if you haven’t done so yet. Enter cloudadmin@vmc.local as SSO user name and provide its password.  Enter the Cloud Tunnel Appliance internal IP address and its root password. You might be prompted to change the root password, if you haven’t done so yet.  Finalize the wizard.  Pairing with another Cloud #  To enable migrations from private clouds running VMware Cloud Director, you need to upgrade and pair the existing instance of VMware Cloud Director Availability operating in this private cloud.\nOnce its version is 4.2, you will need to change the Data Engine similarly to what you did in the VMware Cloud Director Availability provider instance running in Cloud Director service (step 3 from the Additional Configuration in the Provider setup section).\nTo continue supporting the existing replications, it should have both options selected – Classic and VMC.\nIn cases where you perform a fresh installation of VMware Cloud Director Availability 4.2, you can select both data engines to be enabled during the Initial Config Wizard.\n"},{"id":94,"href":"/docs/cloud-infrastructure/solution-interop/","title":"Solution Interoperability of Cloud Infrastructure","section":"Cloud Infrastructure","content":"Solution Interoperability of Cloud Infrastructure #  Integrate the {VVS for CP Title} validated solution with components added to your VMware Cloud Foundation environment by other validated solutions for operations management and business continuity. You can use such validated solutions for logging, backup and restore, disaster recovery, and life cycle management with certain considerations.\nThis validated solution includes guidance only for implementing intelligent operations management. Performing all deployments and configurations for operations management and business continuity are out of scope. Such guidance is part of other validated solutions. However, this solution provides either design or implementation guidance to enable the integration with such solutions.\nMonitoring and Alerting for {VVS for CP Title} #  After you implement the {VVS for CP Title} validated solution, configure both monitoring and alerting for the vRealize Automation components in the VMware Cloud Foundation environment.[Read more]\nLogging for {VVS for CP Title} #  After you implement the {VVS for CP Title} validated solution, by using VMware or third-party components, collect log data in a central place from the components that are newly-added to or re-configured in your VMware Cloud Foundation environment.[Read more]\nAdvanced Load Balancing for {VVS for CP Title} #  After you implement the {VVS for CP Title} validated solution, by using VMware or third-party components, enable load balancing of the components that are newly-added to your VMware Cloud Foundation environment.[Read more]\nLife Cycle Management of {VVS for CP Title} #  After you implement the {VVS for CP Title} validated solution, by using VMware or third-party components, enable upgrade and patching of the components that are newly-added to your VMware Cloud Foundation environment. [Read more]\n"},{"id":95,"href":"/docs/sovereign-cloud/cert-management/","title":"Sovereign Cloud Certificate Management","section":"Sovereign Cloud","content":"Sovereign Cloud Certificate Management #  "},{"id":96,"href":"/docs/sovereign-cloud/design/","title":"Sovereign Cloud Design","section":"Sovereign Cloud","content":"Sovereign Cloud Design #  The Sovereign Cloud validated solution has objectives to deliver prescriptive content about the solution so that it is fast to deploy and is suitable for use in production environments.\n   Objective Description     Main objective Provide VMware Validated Solution for Soveriegn Cloud evnvironments.   Network security profile support Segration between security domainsMultiple Availability ZonesResident Domain security profileManagement plane traffic policy creationFirewall exception rules for external servicesSovereign Domain security profileTraffic policy creationFirewall exception rules for inbound and outbound traffic   Encryption support KMS ProvisioningVM EncryptionStorage EncryptionReplication of encrypted objects   Scope of guidance Detailed design for solution components.Deployment and initial configuration of solution.Operational guidance for solution components   Scope of implementation Deployment and configuration of solution components:Component 1Component 2Configuration of \u0026hellip;Component 1Component 2   Cloud type Sovereign Cloud   Number of VMware Cloud Foundation instances 1   Load Balancing NSX Advanced Load Balancer (AVI)   Availability 99.999%   Authentication, authorization, and access control Use of Microsoft Active Directory over LDAP as the identity provider.Use of security groups and roles for least-privilege access control.Use of service accounts and least-privilege access control for solution integration. The configuration of Microsoft Active Directory Federation Services as the external identity provider is not included in this solution.   Certificate signing Certificates are signed by a certificate authority (CA) that consists of a root and intermediate certificate authority layers.    "},{"id":97,"href":"/docs/sovereign-cloud/detailed-design/","title":"Sovereign Cloud Detailed Design","section":"Sovereign Cloud","content":"Sovereign Cloud Detailed Design #  The {VVS for CP Title} validated solution uses {VVS Product} deployed on top of а VMware Cloud Foundation VI workload domain to \u0026hellip;\nLogical Design for {VVS for CP Title} #  The logical design consists of multiple elements that enable you to deploy and manage infrastructure used to {VVS Product Purpose}. [Read more]\nDeployment Specification for {VVS for CP Title} #  When {VVS Product} is enabled on \u0026hellip; [Read more]\nNetwork Design for {VVS for CP Title} #  {VVS Product} requires multiple networks. This section discusses networking design not covered in the NSX-T Data Center detailed design. [Read more]\nLifecycle Management for {VVS for CP Title} #  Lifecycle management design details the decisions for lifecycle management of an instance of {VVS Product}. [Read more]\nInformation Security and Access for {VVS for CP Title} #  You design authentication access, controls, and certificate management for {VVS Product} according to industry standards and the requirements of your organization. [Read more]\n"},{"id":98,"href":"/docs/sovereign-cloud/implementation/","title":"Sovereign Cloud Implementation","section":"Sovereign Cloud","content":"Sovereign Cloud Implementation #  Implementing {VVS for CP Title} validated solution includes configuring \u0026hellip; and enabling \u0026hellip;\nTo implement and configure {VVS for CP services}, two alternative methods exist. You can use the user interface of each component in the solution or you can use PowerShell cmdlets. You can directly reuse the PowerShell commands by replacing the provided sample values with values from your VMware Cloud Foundation Planning and Preparation Workbook.\nThis guidance provides a prescriptive path for deploying {VVS for CP solution} using \u0026hellip;, and sample {VVS for CP services} in a {management|VI workload} domain. For more information on other deployment options and configurations, read the {VVS for CP Products} Configuration and Management guide. See the {VVS for CP Products} documentation for more details.\nPrerequisites #   Verify that your environment is configured according to Before You Apply This Guidance and the Developer Ready Infrastructure tab of the VMware Cloud Foundation Planning and Preparation Workbook. If you want to use the included Microsoft PowerShell cmdlets to perform implementation and configuration procedures, verify that your system fulfils the following prerequisites.  Verify that your system has Microsoft PowerShell 5.1 installed. See Microsoft PowerShell. Install the PowerValidatedSolutions PowerShell module together with the supporting modules from the PowerShell Gallery by running the following commands. Install-Module -Name VMware.PowerCLI -MinimumVersion 12.4.1 Install-Module -Name VMware.vSphere.SsoAdmin -MinimumVersion 1.3.7 Install-Module -Name ImportExcel -MinimumVersion 7.1.1 Install-Module -Name PowerVCF -MinimumVersion 2.2.0 Install-Module -Name PowerValidatedSolutions -MinimumVersion 1.7.0  Import the PowerValidatedSolutions and the PowerCLI PowerShell modules by running the following commands. Import-Module -Name VMware.PowerCLI -MinimumVersion 12.4.1 Import-Module -Name PowerValidatedSolutions -MinimumVersion 1.7.0     Proceedure #    [Configure Product 1](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  [Configure Product 2](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  [Deploy and Configure Product 3](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  [Deploy and Configure Product 4](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  "},{"id":99,"href":"/docs/sovereign-cloud/metering/","title":"Sovereign Cloud Metering","section":"Sovereign Cloud","content":"Sovereign Cloud Metering #  How to start metering your VCPP products with Usage Meter #  The following information helps you understand how Usage Meter detects and meters the usage of the listed VMware products and their features.\nIt also provides insight into how the reported usage data is calculated and appears in the Usage Insight reports.\nMetering Sovereign Cloud Products #  vCenter Server\nVMware Cloud Foundation\nvSAN\nNSX\nCloud Director\nMetering Other Solutions #  Cloud Director Availability\nTanzu\nSRM\nvRealize Operations\nvRealize Network Insight\nvRealize Automation\nMetering Other Products #  Horizon\nHorizon DaaS\n"},{"id":100,"href":"/docs/sovereign-cloud/operations/","title":"Sovereign Cloud Operations","section":"Sovereign Cloud","content":"Sovereign Cloud Operations #  After you complete the implementation of the Sovereign Cloud, you perform common operations on the environment, such as \u0026hellip;\nFor operational guidance on the components that are deployed automatically in VMware Cloud Foundation or complement the basic VMware Cloud Foundation configuration, see the VMware Cloud Foundation Operations and Administration Guide in the VMware Cloud Foundation documentation.\nPersonas in Sovereign Cloud #  Personas describe types of system users, aligned with real people and their functions within the organization. You build a persona set based on your organization\u0026rsquo;s requirements for role-based access control.[Read more]\nOperational Verification of Sovereign Cloud #  After you add a {VVS Product/Suite} instance in your VMware Cloud Foundation environment during the implementation of the Sovereign Cloud validated solution, verify that the newly-implemented and reconfigured components are operational and functioning within expected parameters.[Read more]\nCertificate Management for Sovereign Cloud #  The security of your environment depends on the validity and trust of the SDDC component certificates. After you deploy and configure the standalone {VVS Product/Suite} instance to your VMware Cloud Foundation environment, you replace the component certificate if the certificate is expiring or compromised, or some of the certificate attributes, such as the host or organization name, must be changed.[Read more]\nPassword Management for Sovereign Cloud #  Manage the account passwords of the components in your VMware Cloud Foundation environment according to the design objectives and design guidance of Sovereign Cloud validated solution.[Read more]\nShutdown and Startup of Sovereign Cloud #  In certain cases, for example, during hardware or power maintenance of the data center, you must shut down the standalone {VVS Product/Suite} instance in a VMware Cloud Foundation environment in a way that prevents data loss and appliance malfunction, and start it up restoring component integration after the maintenance operation is over.[Read more]\nMetering of Sovereign Cloud #  After implementing Sovereign Cloud you must take steps to ensure that proper usage metering of the new {VVS Product/Suite} begins.[Read more]\n"},{"id":101,"href":"/docs/sovereign-cloud/pwd-management/","title":"Sovereign Cloud Password Management","section":"Sovereign Cloud","content":"Sovereign Cloud Password Management #  "},{"id":102,"href":"/docs/sovereign-cloud/personas/","title":"Sovereign Cloud Personas","section":"Sovereign Cloud","content":"Sovereign Cloud Personas #  "},{"id":103,"href":"/docs/sovereign-cloud/planning/","title":"Sovereign Cloud Planning and Preparation","section":"Sovereign Cloud","content":"Sovereign Cloud Planning and Preparation #  Before you start implementing the components of the Sovereign Cloud solution, you must set up an environment that has a specific compute, storage, and network configuration, and that provides external services to the components of the solution.\nUsing the different VMware Validated Solution documenation sets will guide you in implementing a good foundation in order to configure a Sovereign Cloud solution. However, there are some design decisions and considerations that will directly impact the sovereign cloud solution. These will be called out in the Design Objectives, Detailed Design, and Design Decision sections of this guide.\nCarefully review the Sovereign Cloud Detailed Design and Implementation steps before deploying to avoid costly rework and delays. Capture input values that are specific to your environment and verify that the components that are required by this solution are available.\nReview all of the legal policies that pertain to the sovereignty of data and its transmission that are applicable to your country/jurisdiction. Capture the design decisions that these policies directly effect in the design decisions workbook for implementation. Determine the impact these design decisions will have on the implementation. You will want to develop a test plan to validate the functionality of the Sovereign Cloud environment after these policies have been implemented.\nExternal Services #  Services you use that are external to VMware Cloud Foundation when implementing the solution-name solution.\n   External Service Description     Active Directory (AD) Active Directory (AD) is used to provide authentication and authorization to the VMware Cloud Foundation infrastructure.\nThis includes dedicated Domain Users with least privilege access to act as service accounts for component connectivity.   Domain Name Services (DNS) Domain Name Services is used to ensure components are resolvable by FQDN and by IP address.   Network Time Protocol (NTP) Network Time Protocol is used to synchronize time consistently across components.   Certificate Authority (CA) Certificate Authority is used to provide signed certificates for user facing interfaces.   Authentication \u0026amp; Access Control    Application Filters    Data Filters    Auditing Services    Key Management Services (KMS)    Firewall Services     "},{"id":104,"href":"/docs/sovereign-cloud/shutdown-startup/","title":"Sovereign Cloud Shutdown and Startup","section":"Sovereign Cloud","content":"Sovereign Cloud Shutdown and Startup #  "},{"id":105,"href":"/docs/sovereign-cloud/verification/","title":"Sovereign Cloud Verification","section":"Sovereign Cloud","content":"Sovereign Cloud Verification #  "},{"id":106,"href":"/docs/cloud-infrastructure/srm-metering/","title":"SRM Metering and Reporting","section":"Cloud Infrastructure","content":"SRM Metering and Reporting #  VMware Site Recovery Manager (SRM) is a disaster recovery solution that provides automated orchestration and non-disruptive testing of centralized recovery plans for all virtualized applications. It allows service providers to offer reliable, automated protection for workloads hosted on their own cloud infrastructure and being replicated to another cloud destination (DR of the cloud) or workloads running on customer premises and being replicated to the cloud infrastructure (DR to the Cloud). Usage Meter 4.5.0.1 supports the metering of SRM Protected VMs. A protected VM is any virtual machine that is part of an SRM protection group, regardless of whether the VM is powered-on or off. A license is only required for the VM on the active site; no license is required at the failover site. The SRM collector is part of the vCenter collector on the Usage Meter 4.5.0.1 appliance. All collected SRM protected VM details will be in the vCenter collection archives. The collector collects data once a day, and it tracks only the protected VMs present in the protection group.\nNote: vCloud Usage Meter 4.5.0.1 only supports metering of protected VMs in READY state and not protected VMs in SHADOWING state.\nProduct Detection #  SRM is automatically detected in vCenter when the latter is added for metering in the Usage Meter 4.5.0.1 web application. The appliance checks if there is an SRM instance installed on the metered vCenter, and if there is, it receives information from the SRM server for the count of the protected VMs. The service providers do not need to provide site details for the SRM metering. They can deactivate the SRM metering from the UM 4.5.0.1 web application for any added vCenter. Usage Meter 4.5.0.1 detects and meters SRM versions from 8.2.1 to 8.5.\nMetering of SRM provides enhanced billing bi-directional support, for example, from protection to failover site and from failover to protection site. Usage Meter 4.5.0.1 supports the metering of multiple failover sites, for example, from site A to site B and from site A to site C. If any site part of a pair of sites is not added to a Usage Meter appliance, then no VM will be counted as a protected VM. Metering of active and failover sites with a single UM 4.5.0.1 appliance:\n   Setup Expected Monthly Usage Report Count     Both sites A and B are added to the same Usage Meter 4.5.0.1. Both vCenter and SRM are enabled. The Monthly Usage Report will contain 8 protected VMs. 5 protected VMs from site A. 3 protected VMs from site B. Note: In Usage Meter 3.6.1, billing on both sites is not possible.   Site A added to Usage Meter 4.5.0.1, Site B is not added to Usage Meter 4.5.0.1. The Monthly Usage Report will contain 5 protected VMs. 5 protected VMs from site A.   Both A and B sites are added to the same Usage Meter 4.5.0.1. However, site B is deactivated in the Usage Meter web application by deselecting the following checkbox: Meter VMs protected by all SRM\u0026rsquo;s associated with this VC in the Edit this vCenter/vCloud Foundation Server window. The Monthly Usage Report will contain 5 protected VMs. 5 protected VMs from site A. 0 protected VMs from site B. Note: Metering in this scenario is the same as with UM 3.6.1.   Both sites A and B are added to the same Usage Meter 4.5.0.1. However, site A and B are deactivated in the Usage Meter web application by deselecting the following checkbox: Meter VMs protected by all SRM\u0026rsquo;s associated with this VC in the Edit this vCenter/vCloud Foundation Server window. The Monthly Usage Report will contain 0 protected VMs. 0 protected VMs from site A. 0 protected VMs from site B. Note: In this scenario, there will be no billing for SRM, only vCenter-based VM usage part of the Monthly Usage Report.    Metering of active and failover sites with multiple Usage Meter 4.5.0.1 appliances registered in the same contract:\n   Setup Monthly Usage Report Number of Protected VMs     UM 1 and UM 2 both belong to the same contract. Site A is metered by UM 1; vCenter and SRM are both enabled. Site B is metered by UM 2; vCenter and SRM are both enabled. The Monthly Usage Report of UM 1 will contain 8 protected VMs. The Monthly Usage Report of UM 2 will contain 8 protected VMs. Per the contract, there will be 16 protected VMs.       \nWorkarounds for avoiding duplicate billing:\n \nMonthly Usage Report Number of Protected VMs     \nAvoiding duplicate SRM billing\nUM 1 and UM 2 both belong to the same contract.\nSite A is metered by UM 1; vCenter and SRM are both enabled.\nSite B is metered by UM 2; vCenter is enabled, while SRM is deactivated. Note: SRM metering can be enabled/deactivated in the Usage Meter 4.5.0.1 web application by clicking Edit for a selected vCenter/vCloud Foundation instance and then by selecting/deselecting the checkbox: Meter VMs protected by all SRM\u0026rsquo;s associated with this VC in the Edit this vCenter/vCloud Foundation Server window. \nThe Monthly Usage Report of UM 1 will contain 8 protected VMs.\nThe Monthly Usage Report of UM 2 will contain 0 protected VMs.\nPer the contract, there will be 8 protected VMs.\nNote: In the example with UM 2, there will be no SRM specific billing, but only vCenter-based VM usage information in the Monthly Usage Report of that appliance.\n   \nAvoiding duplicate SRM and vCenter billing\nUM 1 \u0026amp; UM 2 both belong to the same contract.\nSite A is metered by UM 1; vCenter and SRM are both enabled.\nSite B is metered by UM 2; vCenter is deactivated (by applying a demo license to all hosts), and SRM is also deactivated.\nNote: SRM metering can be deactivated in the Usage Meter 4.5.0.1 web application by clicking Edit for a selected vCenter/vCloud Foundation instance and then by deselecting the checkbox: Meter VMs protected by all SRM\u0026rsquo;s associated with this VC in the Edit this vCenter/vCloud Foundation Server window. \nThe Monthly Usage Report of UM 1 will contain 8 protected VMs.\nThe Monthly Usage Report of UM 2 will contain 0 protected VMs.\nPer contract, there will be 8 protected VMs.\nNote: In the scenario where both vCenter and SRM are deactivated, there will be no SRM specific billing and no vCenter-based VM usage in the Monthly Usage Report.\n    Sample Monthly Usage Report #  The following is an excerpt from the Usage Meter 4.5.0.1 Monthly Usage Report and contains an example of SRM-metered data.\n   Product Metric Units to be reported     VMware vCenter Site Recovery Manager Protected VMs 103    "},{"id":107,"href":"/docs/cloud-infrastructure/tanzu-metering/","title":"Tanzu Metering and Reporting","section":"Cloud Infrastructure","content":"Tanzu Metering and Reporting #  Configuration #  Tanzu is automatically detected if the Usage Meter administrator configures the endpoint and credentials for each vCenter to be metered using the Usage Meter web application. The Usage Meter administrator can choose to either meter Tanzu as a vRAM or CPU cores metric by selecting the respective option from the \u0026ldquo;If Tanzu is detected, choose the metric to report:\u0026rdquo; drop-down list. The Usage Meter administrator can switch between the vRAM metric and CPU cores metric any time during the metering period. The default metering metric is vRAM. Any of the following Tanzu editions can be selected in the Usage Meter web application as well.\n Tanzu Basic Tanzu Standard Tanzu Advanced  Note: Currently, Usage Insight will only report Tanzu-related usage as Basic in the monthly usage reports, irrespective of the selected Tanzu edition. In future vCloud Usage Insight releases, there will be a fine-grain mapping of the Tanzu-related usage and its correlating edition.\nNote: It is recommended that a single Usage Meter instance meters a single Tanzu edition. For datacenters using different Tanzu editions, there should be a separate Usage Meter installation for each used Tanzu edition. Metering\nOnly Tanzu Basic-related VMs are metered based on Tanzu Basic usage. The following type of VMs will be considered as Tanzu Basic-related VMs:\n Supervisor VM: These VMs are Kubernetes control plane VMs. Three Kubernetes control plane VMs in total are created on the hosts that are part of the Supervisor Cluster. The three-control plane VMs are load-balanced as each one of them has its own IP address. Additionally, a floating IP address is assigned to one of the VMs. vSphere DRS determines the exact placement of the control plane VMs on the ESXi hosts and migrates them when needed. vSphere DRS is also integrated with the Kubernetes Scheduler on the control plane VMs so that DRS determines the placement of vSphere Pods. When as a DevOps engineer, you schedule a vSphere Pod, the request goes through the regular Kubernetes workflow, then to DRS, which makes the final placement decision. POD VM: A vSphere Pod is a VM with a small footprint that runs one or more Linux containers. Each vSphere Pod is sized precisely for the workload that it accommodates and has explicit resource reservations for that workload. It allocates the exact amount of storage, memory, and CPU resources required for the workload to run. vSphere Pods are only supported with Supervisor Clusters configured with NSX-T Data Center as the networking stack. TKG VM: VMs running and managing Tanzu Kubernetes clusters. A Tanzu Kubernetes cluster is a full distribution of the open-source Kubernetes container orchestration platform that is built, signed, and supported by VMware. You can provision and operate Tanzu Kubernetes clusters on the Supervisor Cluster by using the Tanzu Kubernetes Grid Service. Both main nodes and worker nodes are metered in the Tanzu Kubernetes cluster.  Tanzu Basic supports both time-based average vRAM metering metric and CPU cores metering metric.\n vRAM metric (Time-based average vRAM usage): Average vRAM usage for all Tanzu Basic-related powered-on VMs. CPU cores metric (Time-based average of host CPU core count): Average host cores usage for all hosts with at least one powered-on Tanzu Basic-related VM. A host is metered for the period where there was at least one powered-on Tanzu Basic-related VM running on this host during the metering period. All cores of the host are metered for the duration.  For example, if there is at least one powered-on VM that is running on a host with 6 CPU cores for any of the 10 days in a 30-day period, this host will be billed with an average host CPU core count of 2, (6 * (1/3) = 2). If a host -whether it has been modified or added or placed into migration mode (i.e., host state changes) - has been running even a single VM, the host is metered for the duration where there is at least one powered-on Tanzu Basic-related VM.\nReporting #  Tanzu Basic Usage (if detected) is always reported as a standalone line item in the Monthly Usage Report.\nSample Monthly Usage Report #     Product Hostname Version VC UUID Units of Measure Units to be Reported     Tanzu Basic    Avg Capped Billed vRAM (GB) 20   Tanzu Basic    Avg Number of Cores 6    Note: The report above shows both the vRAM and CPU cores usage are detected by Usage Meter. This could mean that the Usage Meter administrator has registered a single Tanzu Basic enabled vCenter and switched between the vRAM metric and CPU core metric during the metering period. Multiple vCenters with different metering metrics registered to the Usage Meter cloud also produce two-line items in the report. If the same metric is selected during the entire metering period for all vCenters registered in the Usage Meter, only one-line item with the selected metric will be shown in the report.\nVirtual Machine History Report: #  The column \u0026ldquo;vmType\u0026rdquo; is included in the Virtual Machine History report indicating the types of VMs in the report:\n   vmType Translation     SUP Supervisor VM   POD POD VM   TKG VMs created by vSphere Tanzu Kubernetes Grid service   OTHERS VMs that are not categorized as SUP, POD or TKG    Note: Tanzu will not be shown in \u0026ldquo;associated products\u0026rdquo; on the vCenter registration and management page even if detected by Usage Meter.\n"},{"id":108,"href":"/docs/cloud-infrastructure/vcenter-metering/","title":"vCenter Metering and Reporting","section":"Cloud Infrastructure","content":"vCenter Server Metering and Reporting #  Usage Meter collects product usage information from all vCenter servers that are registered with Usage Meter.\nNote: Usage Meter does not traverse Enhanced Linked Mode, and it requires registering all vCenter servers, part of this mode, to meter their usage data.\nNote: VMware Cloud Provider Program partners should utilize VCPP licenses for all servers used in the service delivery path or administration control plane. VMware perpetual licenses, including OEM versions, can only be utilized to support internal IT operations that are not part of service delivery. In addition, VMware perpetual licenses may not be used to support the management or operations of an environment utilized to host unaffiliated third parties. Virtual machines running on hosts with perpetual or demo license keys are metered by Usage Meter but are not reported.\nConfiguration #  The Usage Meter administrator must configure the endpoint and credentials for each vCenter server to be metered using the Usage Meter web application.\nFeature Detection #  When metering vCenter, Usage Meter performs two types of usage collections: event-based and inventory collections.\nEvent history collections #  Usage meter subscribes to vCenter events to detect changes in a virtual machine and host state. Changes in a virtual machine state are delivered every hour to Usage Meter and recorded.\nNote: Usage Meter collects data from hosts and VMs in an active state. Even when there is a connectivity issue with a host, Usage Meter will still report metering data if the host VMs are in a powered-on state. This means that providers will be billed for VMs even when there are temporary interruptions in host connectivity. If providers want to be sure they are not being billed for VMs, they need to turn those VMs off.\nInventory collections #  Usage Meter queries vCenter servers every eight hours to collect full inventory information.\nvCenter Reporting #  The vCenter Server Standard edition is part of the Flex Core bundle and therefore reported as part of that bundle. vCenter usage is bundled by default and cannot be reported standalone. See an exaple below:\n"},{"id":109,"href":"/docs/dr-migration/vcda-initial-config/","title":"VMware Cloud Director Availability Appliances Initial Configuration","section":"DR and Migration","content":"VMware Cloud Director Availability Appliances Initial Configuration #    Login to the appliance at the following URL: https://\u0026lt;Cloud-Replication-Management-Appliance-URL\u0026gt;/admin.\n  Enter the password defined during the deployment process.\n  Since it is the first login to the system, you will be prompted to change the password.\n  Click Run Initial Setup Wizard. Note that all the steps are mandatory, and you cannot skip any of them.\n  Enter your license key.\n  Give the site a name and provide the Service Endpoint address (the public FQDN/IP address and port of the Cloud Tunnel, e.g. https://vcda-london.cloudhappens.local:443). In case you are not sure about the address at the moment of setup, you can leave it empty and fill it later in the VMware Cloud Director Availability portal under Configuration \u0026gt; Settings \u0026gt; Service Endpoint address. You need to select the Classic data engine.\n  Enter the VMware Cloud Director Endpoint address and a system administrator’s credentials. Note that you only need to type the Endpoint URL, and the wizard will automatically add the https:// prefix and /api suffix. Accept the thumbprint.  Connect all the deployed Cloud Replicator Appliance(s). Enter the Lookup Service Address and SSO admin credentials. Leave Use the above Lookup Service address for Manager, Cloud and Tunnel checked. Note that all the prefixes and ports are added automatically so you can enter just the address. Accept the thumbprints.  Note: If you haven\u0026rsquo;t logged in the Cloud Replicator Appliance UI so far, you will be prompted to change its root password.\nEnter the API URL and the root password. Note that the prefix and port are added automatically. Accept the thumbprint.  Note: If you haven\u0026rsquo;t logged in the Cloud Tunnel Appliance UI so far, you will be prompted to change its root password.\nReview the summary and finalize the wizard.  To make sure the configuration process completed successfully, you can check the status of the VMware Cloud Director Availability components and connectivity in the System Health menu.\n"},{"id":110,"href":"/docs/dr-migration/vcda-gcve-sddc/","title":"VMware Cloud Director Availability Certificate Management","section":"DR and Migration","content":"Setting Up VMware Cloud Director Availability at a GCVE SDDC #  User Permissions for Google Cloud VMware Engine #  The default vSphere administrative user that comes with Google Cloud VMware Engine is CloudOwner@gve.local. Despite its administrative rights, the CloudOwner user misses some privileges (like Host.Config.Connection, for example) for the VMware Cloud Director Availability Classic data engine to operate properly. Even the temporary elevation of the CloudOwner privileges (link) does not help to perform a successful replication.\nHowever, out-of-the-box Google Cloud VMware Engine creates 5 vSphere solution users with full administrative privileges. They are intended to be used by products like VMware Cloud Director, VMware SRM and also other VMware and non-VMware tools. By using one of the solution users during the VMware Cloud Director Availability configuration, the product can successfully create and maintain a healthy replication. A description of the solution user accounts and steps how to enable them is available here.\nNOTE: The password of the solution user expires 365 days after it was changed last. This means resetting it needs to be considered every year not to disrupt the service.\nGoogle Cloud VMware Engine Network Configuration #  In terms of internal networking and communication, Google Cloud VMware Engine is not as restrictive as VMC on AWS, for example. There is no need to define firewall rules for enabling the VMware Cloud Director Availability appliances to access the ESXi hosts, for example.\nStill these requirements need to be met:\n Have a network segment for the VMware Cloud Director Availability appliances to connect to. It can be an existing one or specially created for VMware Cloud Director Availability. Managing network segments is done directly through the VMware NSX-T Data Center UI deployed in Google Cloud VMware Engine. For further instructions, please refer to the VMware NSX-T Data Center user documentation. Request a new public IP and forward it to the VMware Cloud Director Availability Cloud Tunnel appliance internal IP address.  Define a firewall table that will allow incoming traffic to the Cloud Tunnel.  VMware Cloud Director Availability Deployment #  The VMware Cloud Director Availability appliances deployment is following the typical sequence of deployment steps that can be found in the documentation.\nThe only consideration to be made is during the Initial Setup Wizard when specifying the data engine (Classic or VMC). When the Classic data engine is selected, the solution user credentials need to be provided when connecting to the Lookup service. And when the VMC engine is selected, both CloudOwner and solution user can be used for connecting to the Lookup service.\n"},{"id":111,"href":"/docs/dr-migration/multi-nic-config/","title":"VMware Cloud Director Availability Multi-NIC Configuration","section":"DR and Migration","content":"VMware Cloud Director Availability Multi-NIC Configuration #  Overview #  Placing the VMware Cloud Director Availability appliances in different networks is something common for Service Providers. This leads to the need to use multiple network interfaces to support that scenario and guarantee the product will continue operating as per design.\nThere are a few main reasons that lead to this design:\n  Bypass a router\n  Port forwarding is not possible\n  Inability to route the replication traffic\n  Separation of the incoming replications to different isolated networks\n  Design #  You need to take two considerations before the implementation of VMware Cloud Director Availability appliances that will have multiple NICs:\n  Which interface will be used for the communication with the rest of the VMware Cloud Director Availability appliances?\n  How will the routing be organized - to which interface the default gateway will be configured and what static routes will be required?\n  The General recommendation (GR01) is to deploy the appliances with the interfaces that will be used for communicating with each other. When following this recommendation, the VMware Cloud Director Availability services will discover and set to use the first NIC (ens160) and its first IP address. The only additional change that might be required is to move the default gateway to a different NIC and configure one or more static routes on ens160.\nMoving the Default Gateway #  To perform the necessary steps, you have to connect to the appliance. The recommended way is to use DCUI because the configuration changes might lead to losing network connectivity.\n First, you need to unconfigure ens160. Example command:  /opt/vmware/h4/bin/net.py unconfigure-nic ens160\nThen configure only the IP address of ens160 without setting a default gateway on it. Example command:   /opt/vmware/h4/bin/net.py configure-nic --static -a 192.168.10.10/24 ens160\nConfigure the static route(s) for ens160. Example command:   /opt/vmware/h4/bin/net.py add-route ens160 destination_subnet gateway metric\nNote: You can use this command multiple times for setting more than one static route.\n(Optional) Configure the name servers. Example command:   /opt/vmware/h4/bin/net.py configure-dns --servers ns01_ip ns02_ip --search-domain domain1 domain2 \nOnce you finish the configuration and the appliance is accessible over the network, you can connect through SSH or use the UI.\nReconfigure the VMware Cloud Director Availability Appliances #  For cases where GR01 is not followed, some actions need to be taken so the VMware Cloud Director Availability appliances can use the IP address set to an interface different from ens160.\nCloud Tunnel #  It is essential to know that only one of the Cloud Tunnel interfaces can be used for communication with the rest of the VMware Cloud Director Availability appliances in the local site. For pairing purposes all the interfaces of the tunnel appliance can be used.\nTo reconfigure the Cloud Tunnel, you need to:\n  Set IP addresses to all interfaces and configure the static routes.\n  Log in as root through SSH to the Tunnel appliance.\n  Authenticate as root to the Tunnel service via CLI. Example command:\n   h4 -k tunloginroot 'r00t_Password'\nCheck the current service configuration. Example command:   h4 -k tunendpoints\nExpected output:\n{ \u0026quot;configured\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;192.168.1.2\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8047, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;192.168.1.2\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8047, \u0026quot;tunnelAddress\u0026quot;: \u0026quot;192.168.1.2\u0026quot;, \u0026quot;tunnelPort\u0026quot;: 8048, \u0026quot;tunnelPublicAddress\u0026quot;: \u0026quot;vcav01.ber.cloudprovider.pub\u0026quot;, \u0026quot;tunnelPublicPort\u0026quot;: 443 }, \u0026quot;effective\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;192.168.1.2\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8047, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;192.168.1.2\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8047, \u0026quot;tunnelAddress\u0026quot;: \u0026quot;192.168.1.2\u0026quot;, \u0026quot;tunnelPort\u0026quot;: 8048, \u0026quot;tunnelPublicAddress\u0026quot;: \u0026quot;vcav01.ber.cloudprovider.pub\u0026quot;, \u0026quot;tunnelPublicPort\u0026quot;: 443 } } The important parameter is tunnelAddress. The value of this parameter will be used to configure the other local VMware Cloud Director Availability appliances – Cloud Replication Manager and Cloud Replicator(s) - when they are prepared to communicate with the tunnel. This parameter can be set to a specific IP address or null. Setting it to null will lead to the service discovering the first IP address in the system and use it. In this example, the ens160 IP address is 192.168.1.2, and the ens192 IP address is 172.18.24.4.\nNext, we need to configure the Tunnel service to use the IP address of ens192. Example command:   h4 -k tunsetendpoints \u0026quot;192.168.1.2\u0026quot; \u0026quot;8047\u0026quot; \u0026quot;192.168.1.2\u0026quot; \u0026quot;8047\u0026quot; \u0026quot;172.18.24.4\u0026quot; \u0026quot;8048\u0026quot; \u0026quot;vcav01.ber.cloudprovider.pub\u0026quot; \u0026quot;443\u0026quot;\nExpected output:\n{ \u0026quot;configured\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;192.168.1.2\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8047, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;192.168.1.2\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8047, \u0026quot;tunnelAddress\u0026quot;: \u0026quot;172.18.24.4\u0026quot;, \u0026quot;tunnelPort\u0026quot;: 8048, \u0026quot;tunnelPublicAddress\u0026quot;: \u0026quot;vcav01.ber.cloudprovider.pub\u0026quot;, \u0026quot;tunnelPublicPort\u0026quot;: 443 }, \u0026quot;effective\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;192.168.1.2\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8047, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;192.168.1.2\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8047, \u0026quot;tunnelAddress\u0026quot;: \u0026quot;172.18.24.4\u0026quot;, \u0026quot;tunnelPort\u0026quot;: 8048, \u0026quot;tunnelPublicAddress\u0026quot;: \u0026quot;vcav01.ber.cloudprovider.pub\u0026quot;, \u0026quot;tunnelPublicPort\u0026quot;: 443 } } Note: Make sure the parameters are provided in the correct order.\nWith this, the Cloud Tunnel is properly configured to use a non-default IP address.\nOnce the tunnelAddress has its new value, please navigate to the VMware Cloud Director Availability Portal (\u0026lt;https://manager_appliance_IP_address/ui/admin) and re-enable the tunneling to propagate the change to all local components – Cloud Replication Manager and Cloud Replicator(s).\nCloud Replication Manager #  The Cloud Replication Manager runs two services (Cloud service and Manager service) that require reconfiguration as both need to use the same interface to communicate with the rest of the appliances. For communication with the VMware Cloud Director cells and vCenters, the services can use any interface.\nCloud service #    Set IP addresses to all interfaces and configure the static routes.\n  Log in as root through SSH to the Cloud Replication Manager appliance.\n  Authenticate as root to the Cloud service via CLI. Example command:\n  c4 loginroot 'r00t_Password'\nCheck the current service configuration. Example command:  c4 endpoints\nExpected output:\n{ \u0026quot;configured\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: null, \u0026quot;mgmtPort\u0026quot;: 8046, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-e2eecba4-8381-4799-a39a-0ec4eca105bb.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048, \u0026quot;apiAddress\u0026quot;: null, \u0026quot;apiPort\u0026quot;: 8443, \u0026quot;apiPublicAddress\u0026quot;: \u0026quot;vcav01.ber.cloudprovider.pub\u0026quot;, \u0026quot;apiPublicPort\u0026quot;: 443 }, \u0026quot;effective\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;192.168.2.81\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8046, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-e2eecba4-8381-4799-a39a-0ec4eca105bb.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048, \u0026quot;apiAddress\u0026quot;: \u0026quot;vcavm1.ber.cloudprovider.local\u0026quot;, \u0026quot;apiPort\u0026quot;: 8443, \u0026quot;apiPublicAddress\u0026quot;: \u0026quot;vcav01.ber.cloudprovider.pub\u0026quot;, \u0026quot;apiPublicPort\u0026quot;: 443 } } Note: Because the Cloud Replication Manager appliance is already prepared for tunneling, the mgmtPublicAddress parameter has this value tn-\u0026lt;\u0026lt;uuid\\.tnexus.io. It should NOT be changed in the next step but should be used as it is.\nThe parameter that has to be changed is mgmtAddress. In the Configured section it is set to null which means the service will try to discover an interface with a successfully configured IP address and bind itself to this address.\nIn this example, the ens160 IP address is 192.168.2.81, and the service currently uses this interface. The IP address of the ens192 interface is 172.17.31.81.\nWe will configure mgmtAddress to use ens192 with IP address 172.17.31.81. Example command:   c4 -k setendpoints \u0026quot;172.17.31.81\u0026quot; \u0026quot;8046\u0026quot; \u0026quot;tn-e2eecba4-8381-4799-a39a-0ec4eca105bb.tnexus.io\u0026quot; \u0026quot;8048\u0026quot; \u0026quot;vcavm1.ber.cloudprovider.local\u0026quot; \u0026quot;8443\u0026quot; \u0026quot;vcav01.ber.cloudprovider.pub\u0026quot; \u0026quot;443\u0026quot;\nExpected output:\n{ \u0026quot;configured\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;172.17.31.81\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8046, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-e2eecba4-8381-4799-a39a-0ec4eca105bb.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048, \u0026quot;apiAddress\u0026quot;: \u0026quot;vcavm1.ber.cloudprovider.local\u0026quot;, \u0026quot;apiPort\u0026quot;: 8443, \u0026quot;apiPublicAddress\u0026quot;: \u0026quot;vcav01.ber.cloudprovider.pub\u0026quot;, \u0026quot;apiPublicPort\u0026quot;: 443 }, \u0026quot;effective\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;172.17.31.81\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8046, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-e2eecba4-8381-4799-a39a-0ec4eca105bb.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048, \u0026quot;apiAddress\u0026quot;: \u0026quot;vcavm1.ber.cloudprovider.local\u0026quot;, \u0026quot;apiPort\u0026quot;: 8443, \u0026quot;apiPublicAddress\u0026quot;: \u0026quot;vcav01.ber.cloudprovider.pub\u0026quot;, \u0026quot;apiPublicPort\u0026quot;: 443 } } Restart the Cloud service. Example command:  systemctl restart manager\nNote: This operation won’t break any of the running replication tasks but will only reload the Cloud Replicator configuration and ensure all paired on-premises and remote cloud appliances receive the correct information for the replicator configuration in the local site.\nOnce you perform these steps, the Cloud service is configured, and you can proceed to the steps for the Manager service.\nManager service #    Log in as root through SSH to the Cloud Replication Manager appliance.\n  Authenticate as root to the Manager service via CLI. Example command:\n  h4 loginroot 'r00t_Password'\nCheck the current service configuration. Example command:  h4 endpoints\nExpected output:\n{ \u0026quot;configured\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: null, \u0026quot;mgmtPort\u0026quot;: 8044, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-853bd005-b905-4da1-bb75-e17996efb5df.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048 }, \u0026quot;effective\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;192.168.2.81\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8044, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-853bd005-b905-4da1-bb75-e17996efb5df.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048 } } Note: The mgmtAddress has null value. This is the parameter that will be changed in the next step.\nChange the mgmtAddress. Example command:  h4 setendpoints \u0026quot;172.17.31.81\u0026quot; \u0026quot;8044\u0026quot; \u0026quot;tn-853bd005-b905-4da1-bb75-e17996efb5df.tnexus.io\u0026quot; \u0026quot;8048\u0026quot;\nExpected output:\n{ \u0026quot;configured\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;172.17.31.81\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8044, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-853bd005-b905-4da1-bb75-e17996efb5df.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048 }, \u0026quot;effective\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;172.17.31.81\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8044, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-853bd005-b905-4da1-bb75-e17996efb5df.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048 } } With this, the configuration of the Replication Manager is completed.\nTo restore the regular operation of VMware Cloud Director Availability, you will need to:\n  Re-register all the Cloud Replicators via the Manager service UI (\u0026lt;https://manager_appliance_IP_address:8441)\n  Enable tunneling via the VMware Cloud Director Availability Portal (\u0026lt;https://manager_appliance_IP_address/ui/admin)\n  Cloud Replicator(s) #  The idea behind having multiple interfaces for the Cloud Replicator is to optimize replication traffic flow. When the Cloud Replicator has more than one NIC, one of the interfaces should be able to communicate with the rest of the VMware Cloud Director Availability appliances and the other one should be in the same Layer 2 broadcast domain as the ESXi vmkernel interface. The Cloud Replicator can\u0026rsquo;t use one interface to communicate with the Cloud Tunnel and another interface to communicate with the Cloud Replication Manager.\n  Set IP addresses to all interfaces and configure the static routes.\n  Log in as root through SSH to the Cloud Replicator appliance.\n  Authenticate as root to the Replicator service via CLI. Example command:\n  h4 rtrloginroot 'r00t_Password'\nCheck the current service configuration. Example command:  h4 rtrendpoints\nExpected output:\n{ \u0026quot;configured\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: null, \u0026quot;mgmtPort\u0026quot;: 8043, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-f9abd9de-3978-4383-a951-514deaec522f.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048, \u0026quot;nfcAddress\u0026quot;: null, \u0026quot;lwdAddress\u0026quot;: null, \u0026quot;lwdPort\u0026quot;: null, \u0026quot;lwdPublicAddress\u0026quot;: \u0026quot;lw-f9abd9de-3978-4383-a951-514deaec522f.tnexus.io\u0026quot;, \u0026quot;lwdPublicPort\u0026quot;: 8048 }, \u0026quot;effective\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;172.17.33.1\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8043, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-f9abd9de-3978-4383-a951-514deaec522f.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048, \u0026quot;nfcAddress\u0026quot;: null, \u0026quot;lwdAddress\u0026quot;: \u0026quot;172.17.33.1\u0026quot;, \u0026quot;lwdPort\u0026quot;: 44045, \u0026quot;lwdPublicAddress\u0026quot;: \u0026quot;lw-f9abd9de-3978-4383-a951-514deaec522f.tnexus.io\u0026quot;, \u0026quot;lwdPublicPort\u0026quot;: 8048 } } Note: Because the Cloud Replicator appliance is already prepared for tunneling, the mgmtPublicAddress parameter has this value tn-\u0026lt;\u0026lt;uuid\\.tnexus.io. It should NOT be changed in the next step but should be used as it is.\nTwo parameters require changing:\n  mgmtAddress – this is the IP address of the interface that will be used for communicating with the other VMware Cloud Director Availability appliances in the local site\n  lwdAddress – this is the IP address of the interface that will be used for communicating with the replication vmkernel interface of the ESXi host(s).\n  Change the mgmtAddress and lwdAddress. Example command:  h4 rtrsetendpoints \u0026quot;172.17.33.1\u0026quot; \u0026quot;8043\u0026quot; \u0026quot;tn-f9abd9de-3978-4383-a951-514deaec522f.tnexus.io\u0026quot; \u0026quot;8048\u0026quot; \u0026quot;\u0026quot; \u0026quot;192.168.3.1\u0026quot; \u0026quot;lw-f9abd9de-3978-4383-a951-514deaec522f.tnexus.io\u0026quot; \u0026quot;8048\u0026quot;\nNote: The parameters need to be in this exact order:\nh4 rtrsetendpoints **mgmtAddress** mgmtPort mgmtPublicAddress mgmtPublicPort nfcAddress **lwdAddress** lwdPublicAddress lwdPublicPort\nExpected output:\n{ \u0026quot;configured\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;172.17.33.1\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8043, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-f9abd9de-3978-4383-a951-514deaec522f.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048, \u0026quot;nfcAddress\u0026quot;: null, \u0026quot;lwdAddress\u0026quot;: \u0026quot;192.168.3.1\u0026quot;, \u0026quot;lwdPort\u0026quot;: null, \u0026quot;lwdPublicAddress\u0026quot;: \u0026quot;lw-f9abd9de-3978-4383-a951-514deaec522f.tnexus.io\u0026quot;, \u0026quot;lwdPublicPort\u0026quot;: 8048 }, \u0026quot;effective\u0026quot;: { \u0026quot;mgmtAddress\u0026quot;: \u0026quot;172.17.33.1\u0026quot;, \u0026quot;mgmtPort\u0026quot;: 8043, \u0026quot;mgmtPublicAddress\u0026quot;: \u0026quot;tn-f9abd9de-3978-4383-a951-514deaec522f.tnexus.io\u0026quot;, \u0026quot;mgmtPublicPort\u0026quot;: 8048, \u0026quot;nfcAddress\u0026quot;: null, \u0026quot;lwdAddress\u0026quot;: \u0026quot;192.168.3.1\u0026quot;, \u0026quot;lwdPort\u0026quot;: 44045, \u0026quot;lwdPublicAddress\u0026quot;: \u0026quot;lw-f9abd9de-3978-4383-a951-514deaec522f.tnexus.io\u0026quot;, \u0026quot;lwdPublicPort\u0026quot;: 8048 } } Note: You might get the following output:\n \u0026quot;code\u0026quot;: \u0026quot;TrafficIsolationConfigurationFailure\u0026quot;, \u0026quot;msg\u0026quot;: \u0026quot;Traffic isolation configuration could not be applied to hbr server.\u0026quot;, \u0026quot;args\u0026quot;: [], \u0026quot;stacktrace\u0026quot;: In such cases, just check if the configuration has been updated correctly using:\nh4 rtrendpoints\nWith this, the configuration of the Cloud Replicator is completed.\nWhen the mgmtAddress parameter is changed, the Cloud Replicator needs to be re-registered in the Cloud Replication Manager via the Manager service UI (\u0026lt;https://manager_appliance_IP_address:8441).\nUpgrade #  Upgrading the VMware Cloud Director Availability appliances will not affect the network interface configuration.\n"},{"id":112,"href":"/docs/cloud-director-service/cds-gcve-deployment-guide-msp/","title":"VMware Cloud Director Service for Google Cloud VMware Engine Deployment Guide","section":"VMware Cloud Director service","content":"Introduction #  This white paper is intended for VCPP Cloud Providers who need guidance on how to configure Google Cloud VMware Engine with VMware Cloud Director service (CDs). The content below describes the manual deployment process required to setup the Google Cloud projects, configure them, deploy a Software Defined Data Center (SDDC), associate it to CDs, and the process to configure a virtual private network (VPN) solution for connectivity to isolated networks.\nA virtual private network (VPN) provides traffic tunneling through an encrypted connection, preventing it from being seen or modified in transit. VMware NSX® Data Center for vSphere includes a remote access VPN feature (IPsec) that allows the connection from a remote site to connect securely to the private networks and applications in the organization virtual data center.\nDue to a limitation in VPN technology in Google Cloud, the provider will need to select an alternative solution such as an open source or commercially available, depending on the required features and available support. Examples of open source solutions include OpenVPN or StrongSwan. This deployment guide will walk through the steps required to implement the StrongSwan solution to provide the VPN connectivity between the provider-managed customer project and the T1 edge that sits in front of the tenant networks. The VPN solution is deployed and configured manually in addition to being managed separately from CDs.\nDisclamer\nVMware does not endorse, recommend, or support any third-party utility or solution.\nA general knowledge of networking and security, as well as on VMware Cloud Director concepts is also required.\nConfigure Provider Project and Create Required Resources #  The following section describes the steps required to setup the cloud provider project. Before proceeding, the projects should be created, and the account used to configure them have the appropriate permission to configure all aspects of the projects.\nSetup the Provider Project #  The following steps describes the steps required to configure the provider project.\n Log into the Google Cloud console and click \u0026ldquo;Select a project\u0026rdquo; dropdown.     On the \u0026ldquo;Select a project\u0026rdquo; box, click the link for the name of the provider project.     In the top left pane, click the three horizontal bars and navigate down to Network -\u0026gt; Network Services -\u0026gt; and click Cloud DNS.      If prompted to enable the API first, click Enable API.\n  In the top left pane, click the three horizontal bars and navigate down to Compute -\u0026gt; and select VMware Engine. Note that this will open a second browser tab, keep both tabs open for easier navigating when configuring later.\n     Click Enable API.     In the top left pane click the three horizontal bars and navigate to Networking -\u0026gt; VPC Network -\u0026gt; and select VPC Networks.     Click CREATE VPC NETWORK.      Enter in the following:\n  Name: Subnet name such as the region the environment is in such as \u0026ldquo;asia-southeast1\u0026rdquo;\n  Region: Select the region the environment is in to host the subnet such as \u0026ldquo;asia-southeast1\u0026rdquo;\n  IP Address Range: Provide a range such as 100.64.0.0/20\n  Check the box for \u0026ldquo;I confirm that my subnet configuration includes a range outside of the RFC 1918 address space\u0026rdquo;\n  Private Google Access: Select the ON radial button\n        Under Dynamic Routing Mode:\n  Select Global\n  Set the Maximum MTU to 1500\n  Click Create\n       Once the task has completed, scroll to the bottom of the page, and click the name of the provider management network that was just created.     In the VPC network details screen, click the PRIVATE SERVICE CONNECTION tab and click the Enable API Button.     Once enabled, click ALLOCATE IP RANGE.      For Allocate an internal IP range enter:\n  Name: service-network\n  IP Range: The next subnet available in the provider range previously entered, 100.64.16.0/24 in this case\n  Click ALLOCATE\n       Click the PRIVATE CONNECTIONS TO SERVICES tab and click CREATE CONNECTION.     On the private connection screen, ensure Google Cloud Platform is selected and select the service-network that was created under Assigned Allocation and click Connect.    Create and Configure the Software Defined Data Center #  The following section describes the steps required to setup the Software Defined Data Center (SDDC) that tenants will consume for resources.\n Go to the browser tab that has GCVE open and click Create a Private Cloud.      Enter the following information:\n  Private Cloud Name: Name of the SDDC to create\n  Location: The GCP data center to create the SDDC\n  Node Type: Multi Node for production deployments\n  Node Count: Number of nodes to initially use for the SDDC (4 minimum)\n  vSphere/vSAN Range: IP range to use for vSphere and vSAN\n  HCX Deployment Range: IP range to use for HCX (while the input is required, using HCX is not required)\n  Click Review and Create when ready\n     Click Create\n  The SDDC creation process takes around one hour to complete.\n    Once the SDDC completion process works, the next steps are completed most easily by have two browser tabs open: one for the GCVE environment and one on the provider project settings.\n  On the browser tab with GCVE, in the left pane click Network and in the right pane click Add Private Connection.\n      Enter the following information:\n  Service: VPC Network\n  Region: The region the SDDC was created in\n  Peer Project ID: this will be the provider project name, which can be found in the browser tab with the provider project by clicking Google Cloud Platform and then copying the Project Name field and pasting it into the Peer Project ID field\n       Peer Project Number: This is the project ID, which can be found in the tab where the Project Name filed is immediately under that; copy and paste the value into the Peer Project Number field      Peer VPC ID: This will be \u0026ldquo;provider-mgmt-network\u0026rdquo; unless it was named differently. If it was name differently, enter the name used.\n  Tenant Project ID: To get the tenant project ID value, on the browser tab with the provider project, in the left pane click VPC Network -\u0026gt; VPC Network Peering and in the right pane, copy the value for Peered Project ID and paste it into this field.\n     Verify the Routing Mode is set to Global and click Submit.     After about 5 minutes, the Region Status should show Connected.     Navigate back to VPC Network -\u0026gt; VPC Networks -\u0026gt; and click on the provider-mgmt-network.     Click on the VPC NETWORK PEERING tab and click into the servicenetworking name.     Click on EDIT.     Under Exchange Custom Routes, check the boxes for Import Custom Routes and Export Custom Routes and click SAVE.     After saving, the route Status should all change to a Status of accepted.     On the GCVE browser tab, click Network in the left pane and then in the right pane click the REGIONAL SETTINGS tab and click Add Region.     On the Add Region screen, select the Region the SDDC is in, enable Internet Access and Public IP Service, and use the next provider CIDR block for the Edge Services CIDR and click Submit. After a few minutes, it should show that the status is Operational and Enabled.    Setup the Tenant Projects #  The following steps describes the steps required to configure the tenant projects. Many of the steps are the same done in the provider tenant in creating a tenant service network and peering projects.\n In the Google Cloud Portal, click the project name dropdown beside Google Cloud Platform.     On the Select a project screen, click the ALL tab and select the tenant project.     In the top left pane click the three horizontal bars and navigate to VPC Network -\u0026gt; VPC Networks -\u0026gt; and click the Default network name.     Click DELETE VPC NETWORK.      Click DELETE when prompted to confirm\n  Click CREATE VPC NETWORK.\n      Enter the following:\n  Name: Name for the network such as \u0026ldquo;tenantname-transit\u0026rdquo;\n  New Subnet Name: Name to match the region such as asia-southeast1\n  Region: The region the SDDC is in\n  IP Address Range: A CIDR range out of the next available range. Check the box for \u0026ldquo;I confirm the subnet configuration includes a range outside the RFC 1918 address space\u0026rdquo;\n  Private Google Access: Turn On\n  Click Done on the Subnet Section\n  Dynamic Routing Mode: Global\n  MTU: 1500\n  Click CREATE\n    Once the network creation has completed, click into the network name.\n     Click the PRIVATE SERVICE CONNECTION tab and then click ENABLE API.     Once completed, click ALLOCATE IP RANGE.      Set the following:\n  Name: service-network\n  IP Range Custom: Next available CIDR range\n  Click Allocate\n       Click the PRIVATE CONNECTIONS TO SERVICES tab and then click CREATE CONNECTION.     On the private connection screen, ensure Google Cloud Platform is selected and for Assigned Allocation, select the service-network that was just created and click CONNECT.     In the left pane click on VPC Network Peering and in the right pane click into the servicenetworking name.     Click EDIT.     Under Exchange Custom Routes, check the boxes for Import Custom Routes and Export Custom Routes and click SAVE.     Navigate to the GCVE page and in the left pane click Network and in the right pane click Add Private Connection.      Enter the following information:\n  Service: VPC Network\n  Region: Region the SDDC is in\n  Peer Project ID: this will be the provider project name, which can be found in the browser tab with the provider project by clicking Google Cloud Platform and then copying the Project Name field and pasting it into the Peer Project ID field\n       Peer Project Number: This is the project ID, which can be found in the tab where the Project Name filed is immediately under that; copy and paste the value into the Peer Project Number field      Peer VPC ID: This will be \u0026ldquo;tenantname-transit\u0026rdquo; unless it was named differently. If it was name differently, enter the name used.\n  Tenant Project ID: To get the tenant project ID value, on the browser tab with the provider project, in the left pane click VPC Network -\u0026gt; VPC Network Peering and in the right pane, copy the value for Peered Project ID and paste it into this field.\n     Verify the Routing Mode is set to Global and click Submit.      After about 5 minutes the Region status should show Connected.\n  Repeat the previous steps for configure each tenant project.\n  Create a Jumphost in the Provider Project and Allow Network Access #  The following section describes the steps required to create a jumphost in the provider project to use for vCenter and NSX access as well as other potential tasks made easier with local access.\n In a browser navigate to the provider project as previously described and in the top right pane click the three horizontal bars and select Compute Engine -\u0026gt; VM Instances.     Click CREATE INSTANCE.      Enter the following information:\n  Name: A name for the VM to help the region and function\n  Region: Same region as the SDDC\n  Zone: Zone in the region of the SDDC\n       Scroll down to the Boot Disk section and click CHANGE      Change the following:\n  Operating System: Windows Server\n  Version: Select a current version, such as 2019 Datacenter\n  Size: Change the default size if desired\n  Click SELECT\n       Scroll down and expand NETWORKING, DISKS, SECURITY, MANGEMENT, SOLE-TENANCY     Under \u0026ldquo;Edit network interface\u0026rdquo;, click the Network drop down and select the provider-mgmt-network that was previously created and then click DONE\u0026lt; then click CREATE     After several minutes the jumphost should show ready; click on the name of it to open the settings.     Click SET WINDOWS PASSWORD     On the pop-up screen, it will fill in the Username of the person logged in, click SET to set the password.     After a few moments it will display the password that is set. Copy the password and then click CLOSE.     Allow access through the firewall by clicking the three horizontal bars in the top left and select VPC Network -\u0026gt; Firewall.     Click CREATE FIREWALL RULE.      Set the following for the firewall rule:\n  Name: Name stating the service provided such as \u0026ldquo;rdp-in\u0026rdquo;\n  Network: The provider-mgmt-network that was created previously\n  Direction of Traffic: Ingress\n  Targets: All instances in the network\n  Source IPv4 ranges: 0.0.0.0/0\n  Protocols and ports: TCP 3389\n  Click CREATE\n    Click CREATE FIREWALL RULE again\n  Set the following for the firewall rule:\n  Name: This will be for east-west connectivity, so name it to identify what it is such as \u0026ldquo;ew\u0026rdquo; or \u0026ldquo;east-west\u0026rdquo;\n  Network: The provider-mgmt-network that was created previously\n  Direction of Traffic: Egress\n  Targets: All instances in the network\n  Source IPv4 ranges: The range of the management network, such as 100.64.0.0/16\n  Protocols and ports: Allow all\n  Click CREATE\n    On the settings of the jumphost that was created, copy the External IP to use in RDP.\n     Log into the jumphost with the external IP and the credentials previously created to verify access.  Prepare for and Deploy the Reverse Proxy #  The following section describes the steps required to prepare the environment for the proxy, generate it, and then deploy and associate the proxy to the SDDC that was created.\nCreate the CDs Instance (If not already created) #  The following steps describes the steps required to create a CDs instance if one does not already exist that the SDDC should be associated to.\n In Partner Navigator, navigate to VMware Cloud Director service and click CREATE INSTANCE.     Enter the required information and click CREATE INSTANCE.   The CDs instance will take around 30 minutes to complete.  Generate the Proxy #  The following steps describes the steps required to generate the proxy that will be used for the connection from CDs to the SDDC. These steps are completed from the partner navigator portal and require the CDs instance to already exist.\n  On the GCP provider based jumphost, log into Partner Navigator, navigate to VMware Cloud Director service.\n  On the CDs instance to associate the SDDC to click Actions and select Generate VMware Reverse Proxy OVF.\n      Enter the following:\n  API Token: API token from your account in Partner Navigator\n  Datacenter Name: Datacenter\n  vCenter FQDN: The FQDN of the VCSA appliance under Google Cloud VMware Engine -\u0026gt; Resources -\u0026gt; VSHPERE MANAGEMENT NETWORK\n       Management IP for vCenter: The IP address of the VCSA appliance     NSX URL: URL of the NSX manager     Additional hosts within the SDDC to proxy: The IP address of the ESXi hosts that are part of the SDDC. Note that each IP MUST be on a separate line     Once the information has been entered, click GENERATE VMWARE REVERSE PROXY OVF      The Activity Log on the CDs instance can be monitored for the status of the task. Skip ahead to Prepare the Environment for the Proxy if desired to complete those steps while waiting for the proxy to generate.\n  Once the task has completed, click the three horizontal dots, and select View Files.\n     Click the down arrow icon to download the OVF file to the provider jumphost locally.    Prepare the Environment for the Proxy #  Before deploying the proxy, a network segment must be created and DHCP setup so that it can get an IP address. The following steps describe how to create the segment and configure DHCP.\n On the GCVE page in the Google Cloud Portal, click Resource in the left pane and click the name of the SDDC.     Click on VSPHERE MANAGEMENT NETWORK tab and in the right click the NSX Manager FQDN and copy the link location.      RDP to the jumphost that was created on the provider network previously, open a browser and navigate to the FQDN of the NSX manager from the link that was copied.\n  Back on the GCVE browser, click the SUMMARY tab and then in the NSX-T Login Info section, click View.\n     In the Password section, click Copy.      Log into the NSX-T manager URL as admin with the password that was coped.\n  In the NSX-T manager UI, click the Networking tab in the left pane click DHCP.\n     Click ADD DHCP PROFILE.      Enter the following:\n  Profile Name: A name for the DHCP profile\n  Profile Type: DHCP Server\n  Server IP Address: A CIDR subnet for the scope\n  Edge Cluster: The edge cluster that was created\n  Click SAVE\n       In the left pane click Tier-1 Gateways and in the right pane beside Tier1, click the three vertical dots and select Edit.     Click Set DHCP Configuration.     For Type select DHCP Server and for DHCP Server Profile select the DHCP Profile that was created and click SAVE.     Click SAVE.     In the left pane click Segments, then click ADD SEGMENT.      Enter the following:\n  Segment Name: Proxy\n  Connected Gateway: Tier1 | Tier1\n  Transport Zone: TZ-Overlay\n  Subnet: The subnet CIDR\n  Click EDIT DHCP CONFIG\n       Check the DHCP Config enabled, set a DHCP range, enter the DNS servers from GCVE, and then click APPLY (the DNS servers can be found on the GCVE page, clicking Resources in the left tab and then clicking the name of the SDDC, and on the SUMMARY tab under Private Cloud DNS Servers.    Deploy and Connect the Proxy #  The following steps describes the steps required to deploy the proxy and associate it to the CDs instance in Partner Navigator.\n  On the GCP provider based jumphost, open a browser to the vCenter UI.\n  Right click Cluster and select Deploy OVF Template.\n     Select Local File and navigate to the reverse proxy OVF that was downloaded, select it and click NEXT.     Provide a virtual machine name and click NEXT.     Select the Cluster name and click NEXT.      Click Next.\n  Select the vsanDatastore and click NEXT.\n      Select the Proxy network that was previously created and click NEXT.\n  On the Customize Template page, copy and save the root password and click NEXT.\n  Click FINISH to being the deployment.\n  After deployment, power on the appliance.\n  Log into the proxy appliance and verify it has an IP address by running \u0026ldquo;ip a\u0026rdquo;.\n  Run the command \u0026ldquo;systemctl status transporter-client.service\u0026rdquo; and ensure it shows running.\n     If the transporter-client.service is showing an error, verify that DNS resolution is working properly and that it can access the Internet. The below screenshot shows an error when DNS is not working.     Run the command \u0026ldquo;transporter-status.sh\u0026rdquo; and verify it shows connected.     In Partner Navigator, go to the CDs instance the proxy was generated from and click Actions -\u0026gt; Associate a Datacenter via VMware Proxy.      Enter the following:\n  Datacenter name: Datacenter\n  vCenter FQDN: VCSA FQDN that was used to generate the proxy\n  NSX URL: URL of NSX manager that was used to generate the proxy\n  It will attempt an initial connection to the proxy and if it connects, it will display Connection Established\n        On the Credentials page, enter the following:\n  vCenter Username: cloudowner@gve.local\n  vCenter Password: The password for the supplied username\n  Disconnected Network Segment: Enter the name of the network the proxy is on (Proxy)\n  Authentication to NSX Type: Authenticate via NSX Username and Password\n  NSX Username: admin\n  NSX Password: The password for NSX admin account\n       Check the box to acknowledge charges will begin and click SUBMIT.     The Activity Log on the CDs instance can be monitored for the status of the association task.      It should take about 5 to 10 minutes for the task to completed.\n  Once the task has finished, it can take up to 4 hours to show up as an associated SDDC in the CDs instance. Opening the VCD instance to bring up the UI should show the SDDC as a PVCD that can be used to create VDCs for tenants; you do not have to wait for it to show up as associated in the Partner Navigator portal.\n  Deploy and Configure IPsec Tunnel #  The following section describes the steps required to deploy and configure a StrongSwan VPN appliance in the tenant\u0026rsquo;s project to connect to their T1 in the SDDC that was deployed via an IPsec tunnel. This is merely a demonstration of how to deploy a VPN appliance and any suitable appliance can be used.\nThe steps below are based on CentOS 7 as the operating system; using another flavor of Linux may result in different steps or actions required to get it to work properly.\nThe default routes to the Internet will use instance tags to keep from the routes leaking back into the GCVE environment. This tag can be whatever the provider desires, but it must be uniform across all routes that point to the Internet and be applied to any VM that will need to be access to/from to the Internet in the provider owned customer project.\nDeploy a Linux Instance and Configure StrongSwan #  The following steps describes the steps required to deploy a virtual machine, install StrongSwan and configure it for an IPSec tunnel connection to a tenant T1.\n First create a firewall rule in the tenant project by going to VPC Network -\u0026gt; Firewall and click CREATE FIREWALL RULE.      Enter the following:\n  Name: gcve-transit\n  Network: tenatname-transit\n  Priority: 100\n  Direction of Traffic: Ingress\n  Action on match: Allow\n  Targets: All instances in the network\n  Source IPv4 Ranges: Range for transit network \u0026ndash; such as 100.64.0.0/16\n  Protocols and ports: Allow all\n  Click Save\n    Click CREATE FIREWALL RULE again and enter the following:\n  Name: ipsec-egress\n  Network: tenatname-transit\n  Priority: 100\n  Direction of Traffic: Egress\n  Action on match: Allow\n  Targets: All instances in the network\n  Destination IPv4 Ranges: Range for transit network \u0026ndash; such as 100.64.0.0/16\n  Protocols and ports: IPsec Ports\n  Click Save\n    Create a new instance in the tenant and set:\n  Boot Disk: Change to CentOS 7\n  Expand NETWORKING, DISKS, SECRUITY, MANGEMENT, SOLE-TENANCY\n  IP Forwarding: Check the box to Enable\n  Ensure the network interface is on the \u0026ldquo;tenantname-transit\u0026rdquo; network\n  Click CREATE\n      Once completed, click on the name of the instance to bring up its settings.\n     At the top of the screen, click EDIT.\n     Scroll down and in the Network Tags box, put the network tag name, then save the settings.\n     Under the Connect column click SSH to connect to it.\n  Run sudo su and then run \u0026ldquo;yum install strongswan -y\u0026rdquo; to install strongswan.\n  Copy the command below and paste into the shell with ctrl v\n   cat \u0026gt;\u0026gt; /etc/sysctl.conf \u0026lt;\u0026lt; EOF\nnet.ipv4.ip_forward = 1\nnet.ipv4.conf.all.accept_redirects = 0\nnet.ipv4.conf.all.send_redirects = 0\nEOF\n   Run the command sysctl -p\n  CD to /etc/strongswan/swanctl/conf.d and run vi nsxt.conf.\n Enter the following information in the nsxt.conf file replacing localAddr with the local IP of the tunnel, remoteAddr with the remote IP of the tunnel, remoteTS with the network CIDR of the remote end of the tunnel, and PresharedKey with the secret used for the tunnel.     connections {\ngw-gw {\nlocal_addrs = localAddr\nremote_addrs = remoteAddr\nlocal {\nauth = psk\nid = localAddr\n}\nremote {\nauth = psk\nid = remoteAddr\n}\nchildren {\nnet-net {\nlocal_ts = 0.0.0.0/0\nremote_ts = remoteTS\nstart_action = start\nupdown = /usr/local/libexec/ipsec/_updown iptables\nesp_proposals = aes128gcm128-modp2048\n}\n}\nversion = 2\nproposals = aes128-sha256-modp2048\n}\n}\nsecrets {\nike-1 {\nid-1 = localAddr\nsecret = PresharedKey\n}\nike-2 {\nid-2 = remoteAddr\nsecret = PresharedKey\n}\nike-3 {\nid-3a = localAddr\nid-3b = remoteAddr\nsecret = PresharedKey\n}\nike-4 {\nsecret = PresharedKey\n}\nike-5 {\nid-5 = localAddr\nsecret = PresharedKey\n}\n}\n   Run the command swanctl --load-all\n  CD to /etc and run \u0026ldquo;vi ipsec.secrets\u0026rdquo;\n Enter the following line, replacing the words with their values: localTunnelIP remoteTunnelIP : PSK \u0026lsquo;PresharedKey\u0026quot; and save the file.        Run the command sudo strongswan restart\n  Run the command yum install iptables-services and once installed run systemctl start iptables\n  Add the following iptables rules in to allow traffic to be forwarded. Any line that contains remoteNet should have that replaced with the CIDR of the remote network in GCVE. Note that each line must be copied and pasted into the SSH session on the VPN server one by one.\n   iptables -A INPUT -i eth0 -p esp -j ACCEPT\niptables -A INPUT -i eth0 -p ah -j ACCEPT\niptables -A INPUT -i eth0 -p udp -m udp --sport 500 --dport 500 -j ACCEPT\niptables -A INPUT -i eth0 -p udp -m udp --sport 4500 --dport 4500 -j ACCEPT\niptables -A INPUT -p tcp -m tcp --dport 22 -j ACCEPT\niptables -A FORWARD -s remoteNet -d 0.0.0.0/0 -i eth0 -m policy --dir in --pol ipsec --reqid 1 --proto esp -j ACCEPT\niptables -A FORWARD -s 0.0.0.0/0 -d remoteNet -o eth0 -m policy --dir out --pol ipsec --reqid 1 --proto esp -j ACCEPT\niptables -A OUTPUT -o eth0 -p esp -j ACCEPT\niptables -A OUTPUT -o eth0 -p ah -j ACCEPT\niptables -A OUTPUT -o eth0 -p udp -m udp --sport 500 --dport 500 -j ACCEPT\niptables -A OUTPUT -o eth0 -p udp -m udp --sport 4500 --dport 4500 -j ACCEPT\niptables -A OUTPUT -p tcp -m tcp --sport 22 -j ACCEPT\niptables -A FORWARD -s 0.0.0.0/0 -d remoteNet -i eth0 -m policy --dir in --pol ipsec --reqid 1 --proto esp -j ACCEPT\niptables -A FORWARD -s remoteNet -d 0.0.0.0/0 -o eth0 -m policy --dir out --pol ipsec --reqid 1 --proto esp -j ACCEPT\n  Delete the two listed REJECT rules by running \u0026ldquo;iptables -D SECTION_NAME position#\u0026rdquo;. For example, in the screen shot below, the REJECT under INPUT is the 5^th^ rule down, so the command to delete it is \u0026ldquo;iptables -D INPUT 5\u0026rdquo;. Notice after running the command the REJECT rule under INPUT is no longer present.      To delete the REJECT under FORWARD, run \u0026ldquo;iptables -D FORWARD 1\u0026rdquo; as it is in position 1.\n  Run the command service iptables save\n  Run systemctl restart iptables\n  In the GCP console in the tenant project navigate to VPC Network -\u0026gt; Routes and click CREATE ROUTE.\n  Enter the following:\n  Name: tenantname-networkcidr\n  Network: tenantname-transit\n  Destination Range: IP CIDR range in the SDDC for the tenant\n  Priority: 100\n  Next Hop: Specify an instance\n  Next Hop Instance: The StrongSwan VM.\n  Click CREATE\n      Configure IPSec VPN in NSX and Configure Tenant Firewall Rules #  The following steps describes the steps required to create a CDs instance if one does not already exist that the SDDC should be associated to.\n  Log into Partner Navigator and navigate to Cloud Director Service and open the instance that is managing the GCVE SDDC.\n  In the left pane click Edge Gateways and in the right pane click on the name of the tenant\u0026rsquo;s edge.\n     Click on IPSec VPN and then click NEW.      Enter the following:\n  General Settings:\n  Name: Name the IPSec tunnel such as tenantname-gcve-ipsec\n  Click NEXT\n    Peer Authentication Mode:\n  Authentication Mode: Pre-Shared Key\n  Pre-Shared Key: Enter the PSK used for the tunnel\n  Click NEXT\n    Endpoint Configuration:\n  Local Endpoint:\n- IP Address: Local IP address of the tunnel (edge external network address) - Networks: Local network CIDR(s) for the tunnel    Remote Endpoint:\n- IP Address: Remote IP address of the VPN appliance - Networks: 0.0.0.0/0   Remote ID: Remote IP address of the VPN appliance            Click NEXT, then click FINISH to save the IPSec tunnel configuration.\n  Click on VIEW STATISTICS.\n     After a few moments, the tunnel should show the Tunnel Status and IKE Service Status as Up.      Log into the GCP provider jump host, navigate the NSX URL and log in as admin.\n  Click the Security tab, then in the left pane select Gateway Firewall, and in the right pane click the Gateway dropdown and select the tenant\u0026rsquo;s T1 to add the firewall rule to.\n     Click ADD POLICY.     Click in the Name box for the policy and provide a name such as \u0026ldquo;TenantName Tenant Rules\u0026rdquo;.     Click the three horizontal dots to the left of the policy name and select Add Rule.      Enter the following:\n  Sources: Add the remote GCP tenant project\u0026rsquo;s CIDR block\n  Destination: Select Any for any local network or alternatively it can be locked down to a single CIDR\n  Services: Any (or filter to specifics if desired)\n  Action: Allow\n        Add another rule called Allow Outbound and set the following:\n  Sources: Select Any for any local network or alternatively it can be locked down to a single CIDR\n  Destination: Add the remote GCP tenant project\u0026rsquo;s CIDR block\n  Action Allow\n  Once ready, click PUBLISH.\n       Test the tunnel connectivity by deploying an instance in the GCP tenant project that was configured for the tunnel and the tenant in the SDDC to confirm it is functioning. Here we see that SSH/HTTP is connected between both tenant workloads.    Peer Existing Customer VPC #  The following section describes the steps required to pair a tenant owned customer VPC to an existing customer VPC. This step is optional as a customer may not have an existing GCP project.\nThe steps below will require information from the customer and given to the customer to complete the peering process.\nConfigure Provider Owned Customer VPC for Peering #  The following steps describes the steps required to peer the provider owned customer VPC to an existing customer owned VPC to enable connectivity between them.\n In the GCP console, switch to the tenant to configure project and go to VPC Network -\u0026gt; VPC Network Peering.     Click CREATE PEERING CONNECTION.     Click CONTINUE.      Enter the following:\n  Name: name the VPC connection something obvious such as \u0026ldquo;tenantname-to-gpc-vpc\u0026rdquo;\n  Your VPC Network: Select the tenant\u0026rsquo;s transit network\n  Peered VPC Network: In another project\n  Project ID: The name of the customer owned project\n  VPC Network Name: The default network name in the customer\u0026rsquo;s project\n  Exchange Custom Routes: Ensure both Import and Export custom routes are checked\n  Exchange Subnet Routes with Public IP: Select Export subnet routes with public IP\n  Click CREATE\n       The status of the peering will show with a Status of Inactive until the peering process is completed on the customer VPC side.    Customer to Configure the Customer Owned VPC for Peering #  The following steps describes the steps required to peer the customer owned VPC to the provider owned customer VPC to enable connectivity between them.\n  Complete the same process as shown in the previous step and provide the customer the following information to complete the peering:\n  Peered VPC Network: In another project\n  Project ID: The name of the provider owned customer project\n  VPC Network Name: The default network name in the tenant owned customer\u0026rsquo;s project \u0026ldquo;tenantname-transit\u0026rdquo;\n  Exchange Custom Routes: Ensure both Import and Export custom routes are checked\n  Exchange Subnet Routes with Public IP: Select Export subnet routes with public IP\n  Click CREATE\n    Once the customer has completed the peering process, click REFRESH on the VPC network peering page and the Status should change to Active.\n     Click on Routes on the VPC Network page, then click on the PEERING tab and it should display a list of peering routes discovered through the peering process.     To test the connectivity, try to SSH/ping from a workload on the customers GCVE environment into a workload in the GCP peering VPC. A firewall rule will need to be in place on the customer\u0026rsquo;s VPC side allowing the connectivity if it is not already present.    Setup NAT VMs for Internet Access (Optional) #  Note that this section is optional and only required if the customer will have Internet traffic egressing from the provider owned customer project.\nThe following section describes the steps required to setup a group of VMs for NAT for Internet access for workloads within GCVE.\nThese steps are required if the Internet access is egressing from the provider owned customer project or if a customer is routing all traffic to their peered project. The NAT VMs should be created and configured in the project that Internet access is egressing from.\nPrepare and Deploy NAT VMs #  The following steps describes the steps required to prepare the environment to deploy the VMs used for NAT for Internet access and should be run from the project where the traffic will egress using NAT\u0026rsquo;s and ILB\u0026rsquo;s based on GCP compute instances.\nAnother third party solution can be used for this part which is encouraged for more flexible configuration and easier day two operations.\nTwo NAT VMs will be deployed, one in a different AZ in the region for redundancy in an active/passive configuration. The machine size for the NAT VMs below is small for testing purposes, these should be sized appropriately based on the expected throughput.\nThe shell commands are embedded in the attached text document here. ![Graphical user interface, application Description automatically\n generated](/images/cloud-infrastructure-cds-gcve/cloud-infrastructure-cds-gcve130.emf)\n  In the project where the Internet traffic will egress, in the top blue bar, click the Cloud Shell icon to launch the shell.      Prior to copying the shell commands, do a find and replace and replace the following entries. Note: Be careful not to insert any extra spaces or carriage returns to avoid syntax errors.\n  Find: gcve-team-project ; Replace with: tenant-project-name (ex: tenant1-project)\n  Find: --subnet=cds-tenant01-us-west2 ; Replace with: --subnet=tenant-transit-subnet (ex: asia-southeast1)\n  Find: cds-tenant01 ; Replace with: tenant-transit-network (ex: tenant1-transit)\n  Find: -region=us-west2 ; Replace with: -region=project-region-name (ex: asia-southeast1)\n  Find: --zone=us-west2-a ; Replace with: --zone=project-region-az-a (ex: asia-southeast1-a)\n  Find: --zone=us-west2-b ; Replace with: --zone=project-region-az-b (ex: asia-southeast1-b)\n  Find: cds-natgw-startupscripts/nat_gateway_startup.sh ; Replace with: tenant-bucket-name/name_of_startup_script.sh (ex: tenant1-storage/nat_gateway_startup.sh)\n  Find: us-west2 ; Replace with: project-region-name (ex: asia-southeast1)\n  Fine: n1-standard-2 ; Replace with: name of properly sized instance type requried\n    If there are known instances with private Ips that need public Internet routing, run the command below to allocate public IP(s) to add to the NAT startup script prior to uploading. This would need to be done for each instance that needs incoming Internet traffic.\n  gcloud compute addresses create natgw-asia-southeast1-forwarding-external-01 --region asia-southeast1\n Change the region to match where the project is located    Run the following command to display the IP that was allocated:\n gcloud compute addresses describe natgw-asia-southeast1-forwarding-external-01 --region asia-southeast1          Note this IP address to use in the startup script section below.\n  Create a storage bucket and save the startup script:\n  Under the Google Cloud Platform menu, click Cloud Storage.\n     Click CREATE BUCKET.\n     Enter a name for the bucket such as \u0026ldquo;tenantname-storage\u0026rdquo; and click CREATE.\n  Open the below attached text file.Replace the text line \u0026ldquo;iptables -t nat -A PREROUTING -d $nlb_vip -i ens4 -j DNAT --to $test_endpoint_ip \u0026quot; for $nbl_vip with the public IP allocated for the workload requiring incoming Internet connections and $test_endpoint_ip with the private IP of the workload servicing the traffic (web server, etc).   If there as a public IP address allocated for a device that needs incoming Internet traffic, replace the line below with the public IP that was allocated and the correct private IP. Also delete the other line if it is not required; this iptables command would be a line for each public IP that will be forwarded. Change the public IP after -d to what was previously allocated and the IP after DNAT to the private IP of the host (not the T1 gateway, the private IP of the device, such as the Windows server)\n iptables -t nat -A PREROUTING -d 35.236.94.128 -i ens4 -j DNAT --to 10.0.0.3    Save the file locally as \u0026ldquo;nat_gateway_startup.sh\u0026rdquo; or something similar and close it.\n  Back in the storage bucket that was created, click into the bucket name, and then click UPLOAD FILES.\n  Upload the nat_gateway_startup.sh file that was saved locally.\n    From the text file with the shell commands, copy and paste the contents to create and configure the NAT and ILB:\n  Open the GCP cloud shell\n  Copy and paste first line into Google cloud shell to create the SSH firewall rule.\n  Skip the two lines that being with \u0026ldquo;glcoud compute networks\u0026rdquo; as they should already be created.\n  Copy the two lines with \u0026ldquo;gcloud compute addresses create\u0026rdquo; and paste those into the shell and hit enter to create the addresses.\n  Copy the next two lines with \u0026ldquo;nat_#_ip=$\u0026rdquo; and paste those into the shell and hit enter to set the NAT IP variables.\n  Copy the block commands with \u0026ldquo;gcloud compute instance-templates\u0026rdquo; and paste those into the shell and hit enter the create the templates.\n  Copy the lines \u0026ldquo;gcloud compute health-checks create\u0026rdquo; down through the three lines with \u0026ldquo;glcoud compute firewall-rules create\u0026rdquo; and paste them into the shell and hit enter to create the health check and firewall rules.\n  Copy the lines \u0026ldquo;gcloud compute instance-groups managed create\u0026rdquo; and paste them into the shell and hit enter to create the instances.\n  Copy the line \u0026ldquo;gcloud compute health-checks create\u0026rdquo; and paste it into the shell and hit enter to create the next health check.\n  Copy the line \u0026ldquo;gcloud compute backend-services create\u0026rdquo; and paste it into the shell and hit enter to create the natgw backend.\n  Copy the two lines \u0026ldquo;gcloud compute backend-services add-backend\u0026rdquo; and paste them into the shell and hit enter to add the two nats to the backend that was just created.\\\n  The lines under Just Outbound NAT can be skipped if the customer has both incoming and outgoing traffic.\n  Copy the line \u0026ldquo;gcloud compute forwarding-rules create\u0026rdquo; and paste it into the shell and hit enter to create the forwarding rule.\n  Copy the lines for \u0026ldquo;gcloud compute routes create\u0026rdquo; and paste them into the shell and hit enter to create the two routes.\n  Under Public IP Exposure settings, copy the line \u0026ldquo;gcloud compute backend-services create\u0026rdquo; and paste it into the shell and hit enter to create the backend service for the ILB.\n  Copy the two lines with \u0026ldquo;gcloud compute backend-services add-backend\u0026rdquo; and paste them into the shell and hit enter to add the hosts to the backend.\n  If a public IP was allocated previously for an existing workload, copy the last line with \u0026ldquo;gcloud beta compute forwarding-rules\u0026rdquo; and paste it into the shell and hit enter to add the forwarding rule.\n  Note: When adding a new public IP for a workload, the last two lines in this file would need to be reran to allocate the public IP, then create a forwarding rule for it.\n    Configure Firewall and Routes #  The following steps describes the steps required create the firewall rule and routes required to load balancer Internet traffic across the 3 NAT internet gateways that were previously deployed.\nThe default routes for the NAT will use instance tags to keep from the routes leaking back into the GCVE environment. This tag can be whatever the provider desires, but it must be uniform across all 3 routes that will direct traffic to the Internet via the NAT gateways. This applies to the routes created below for nat1, nat2, and nat3. This tag must match the one used on the instances created previously (VPN host).\n  In the provider owned customer tenant, navigate to Cloud shell and enter the following command to allow intervpc communication, changing the \u0026ldquo;\u0026mdash;network=tenant1-transit\u0026rdquo; to the customer\u0026rsquo;s transit network.\n gcloud compute firewall-rules create intervpc-communication1 --direction=INGRESS --priority=100 --network=tenant1-transit --action=ALLOW --rules=all --source-ranges=10.0.0.0/8,172.16.0.0/12,192.168.0.0/16,100.64.0.0/16 --target-tags=natgw    Create a firewall rule for the NAT health check by running the following command, changing the \u0026ldquo;\u0026mdash;network-tenant1-transit\u0026rdquo; to the name of the customer\u0026rsquo;s transit network.\n gcloud compute firewall-rules create \u0026quot;natfirewall\u0026quot; --allow tcp:80 --target-tags natgw --source-ranges \u0026quot;209.85.152.0/22\u0026quot;,\u0026quot;209.85.204.0/22\u0026quot;,\u0026quot;35.191.0.0/16\u0026quot; --network=tenant1-transit    Click on Routes in the left pane and click CREATE ROUTE and enter the following:\n  Name: natgatewayout\n  Network: tenantname-transit\n  Destination IP range: 0.0.0.0/0\n  Priority: 50\n  Next Hope: Default internet gateway\n  Click CREATE\n        Click CREATE ROUTE and enter the following:\n  Name: nat1\n  Network: tenantname-transit\n  Destination IP range: 0.0.0.0/0\n  Priority: 100\n  Instance tags: intravpcdefault\n  Next Hop: Specify an instance\n  Next Hop Instance: nat-1\n  Click CREATE\n        Create two more routes, one named nat2 and one nat3 with the same priority of 100 and specify the next instance as nat-2 and nat-3 respectively for their routes as well as the same instance tag.\n  To test the functionality of the NAT VMs:\n  Open an SSH session to each NAT VM and installing tcpdump with \u0026ldquo;sudo apt install tcpdump -y\u0026rdquo;\n  On each host, run tcpdump with a filter set to the IP of a test workload in GCVE with \u0026ldquo;tcpdump -ni ens4 host ip_of_workload\u0026rdquo;\n  On the GCVE workload, repeatedly curl a public URL such as vmware.com and the traffic hits should spread across the three NAT VMs.\n      Conclusion #  At this point, the VMware Cloud Director service Instance is ready to deploy tenant VMs. For more information see the documentation for VMware Cloud Director service and VMware Cloud Director.\n"},{"id":113,"href":"/docs/cloud-director-service/cds-vmc-deployment-guide-msp/","title":"VMware Cloud Director Service for VMware Cloud on AWS Deployment Guide","section":"VMware Cloud Director service","content":"VMware Cloud Director Service for VMware Cloud on AWS Deployment Guide #  VMware Cloud Director™ service enables cloud providers to use VMware Cloud on AWS in multi-tenant modality with enhanced VMware NSX-T support, allowing provisioning of custom-sized, tenant-based, isolated, and secure VMware Cloud resources. This ability to service multiple smaller and medium sized tenants on the same infrastructure, offers flexibility to right-size the VMware Cloud on AWS environments to meet customer needs and requirements of all customer tiers.\nVMware Cloud Director service is a container-based SaaS version of the proven VMware Cloud Director on-premises service-delivery platform. The service, available through VMware Cloud Partner Navigator, helps cloud providers gain better economies of scale and generate new value and revenue for their cloud businesses.\nThis guide details the process of deploying a VMware Cloud Director service Instance, associating it with a VMware Cloud on AWS SDDC designed for use with VMware Cloud Director service, configuring the Provider Virtual Datacenter to use the resources of the associated VMware Cloud on AWS SDDC, configuring the VMware Cloud on AWS SDDC networking to prepare it for multi-tenant use and deploying the first tenant organization.\nBefore using this guide, it is necessary to join the VMware Managed Service Provider Program and have the require contracts in place to use the VMware Cloud services mentioned in this guide. See the MSP VMware Cloud on AWS Operations Handbook and the Cloud Director service Operations Handbook for more details.\nPrepare a VMware Cloud Partner Navigator Provider Organization #  Provision a new VMware Cloud Partner Navigator Organization\n  Click on Administration, then Add Organization\n  Fill out the Add Organization form and click Add Organization\nRequest access to VMware Cloud Director service by emailing: ask_cloud_director_service@VMware.com\n  Supply the Long ID of the Organization that will be used.\n  A onetime use invitation will be returned to activate VMware Cloud Director service.\nEnable the VMware Cloud on AWS and VMware Cloud Director service services in the new Organization\n  Select the new Provider Organization and click Manage Services\n  Click Continue\n  Click Open on both service tiles to activate the services   Click Open to continue\n  NOTE: It is also acceptable to use an existing Provider Organization enabled for VMware Cloud on AWS [which has no SDDCs currently deployed.]{.underline}\nDeploy a SDDC #  Deploy the SDDC in the same VMware Cloud Partner Navigator Organization activated above.\n  Select the VMware Cloud on AWS service tile   Select SDDCs and click Create SDDC\n  Fill out the form to deploy the SDDC according to your requirements. For more details about the deployment process for VMware Cloud on AWS SDDCs see Deploy an SDDC from the VMC Console.\n  NOTE: All VMware Cloud on AWS SDDCs used with VMware Cloud Director service must be deployed in Organizations that have been enabled for VMware Cloud Director service. SDDCs deployed in other Organizations are not compatible with VMware Cloud Director service.\nDeploy VMware Cloud Director service Instance #    Select the VMware Cloud Director service tile  If someone other than the Organization Owner will be deploying VMware Cloud Director service Instances the Organization Owner must first establish a trust relationship between VMware Cloud services and VMware Cloud Director service.\na. In the Cloud Director Instances screen select Configuration then Configure OAuth Trust Relationshipb. Select Dismiss once the trust is established\n![Graphical user interface, text, application Description automatically generated](/images/cloud-infrastructure-cds-vmc/cloud-infrastructure-cds-vmc12.png)    Select Create Instance to begin the instance deployment process.   Enter the data needed in the form and click on NEXT\n  Note: For the Upgrade Category, selecting Preview (if enabled) identifies this Cloud Director service Instance to be patched or upgraded earlier than when Production is selected. Use Preview for service development environments. The Upgrade Category cannot be changed after deployment.\n Acknowledge costs and then click on CREATE INSTANCE\n  Click on Activity Log for detailed information about the deployment progress.\n  When theÂ VMware Cloud DirectorÂ instance deployment is complete, its card displays aÂ ReadyÂ status.\nGenerate API Token #  An API token for the Organization holding the SDDC is used to associate the SDDC with VMware Cloud Director service.\n  Click on your name in the top right and then click on My Account\n  Click on API Tokens\n  Click on GENERATE TOKEN\n  Enter form fields and then click on GENERATE\n  Notes: This token is only used during the association process, so its Token TTL should be short. Minimum required Organization Role is Organization Member. Minimum required Service Roles are VMware Cloud on AWS - Administrator and VMware Cloud on AWS - NSX Cloud Admin. Make sure to store the generated token in a safe place.\nCreate a DHCP Network #  Need to create a network segment that has routed access to the SDDC management network, provides DHCP service and has a DNS server configured. Note: This step can be skipped if you only have one host in your SDDC.\n  Click on ADD SEGMENT\n  Enter segment details and then click on SET DHCP CONFIG\n  Enter details and then click on APPLY\n  Click SAVE\n  S3 Configuration #  If your SDDC is in Oregon (us-west-2), you will need to either disable S3 or configure a S3 VPC endpoint prior to associating the SDDC. If your SDDC is in any other region, this step can be skipped. By default, S3 traffic in the local region fails until either a VPC endpoint is configured or S3 is disabled. Part of the associate process automatically deploys a proxy appliance into the SDDC. That proxy appliance currently is stored on an S3 bucket in Oregon (us-west-2), which given the default configuration makes it inaccessible.\nDisable S3 #   Click DISABLE\n  Configure S3 VPC endpoint #  See the Amazon Virtual Private Cloud AWS PrivateLink documentation: Endpoints for Amazon S3\nAssociate VMware Cloud Director service Instance #    Click Associate a VMC SDDC\n  Enter fields and then click on ASSOCIATE a VMC SDDC\n  Note: If you only have one host in your SDDC, you can use the predefined network named \u0026ldquo;sddc-cgw-network-1\u0026rdquo; for the Proxy VM Network field.\nAssociate Custom Domain (Optional) #  Allows the provider to use their own domain name for VMware Cloud Director service Instances.\n  Click on ACTIONS and then click on Associate Custom Domain\nSee the VMware Cloud Director service documentation Customize the DNS and Certificate Settings for more details.\n  VMware Cloud Director service Instance Configuration #  Launch the Provider Portal #    To use VMware Cloud Services as an Identity Provider for VMware Cloud Director service Instances, select Configure VMware Cloud Services as instance IDP from the Actions menu of each VMware Cloud Director service Instance.   Select Configure IDP\n  Click on OPEN INSTANCE\n  NOTE: To control user access when VMware Cloud Services is used as the VMware Cloud Director service Instance IDP, use the Role Assignment feature in VMware Cloud Partner Navigator to grant users Admin, Read Only or No Access roles to all IDP enabled VMware Cloud Director service Instances. The Admin role will login to instances with the CDS Provider Admin role. The Read Only role will login to instances with the CDS Provider Admin Read Only role.\nCreate Provider VDC #    Click on NEW\n  Enter details and then click on NEXT\n  Select vCenter and then click on NEXT\n  Select Resource Pool, Hardware version and then click on NEXT\n  Select the VMC Workload Storage Policy \u0026ndash; Cluster-1 and then click on NEXT.   Note: Make sure that the other storage policies are left unselected.\n Select NSX-T manager and Geneve Network pool and then click on Next.\n  Click on FINISH\n  Update External Network with valid IP range #    Click on Tier-0 Gateways in the left pane and then click the name of the pre-existing External Network.\n  Click on Network specification and then Edit.\n  Delete existing network spec by selecting it and then clicking on DELETE\n  Click on NEW\n  Enter Gateway CIDR and click on the pencil.\n  Note: We recommended that you use a subnet in the 100.64.0.0/10 range (RFC-6598 \u0026ndash; Carrier-grade NAT) to avoid conflicts with RFC-1918 private address space used in on premises locations and allow for extensive NATing of tenant IPs to the External Network. For example, you may choose 100.68.1.1/24 for the first SDDC deployed and use 100.68.2.1/24 for the second SDDC and so on. It is important to note that NSX-T uses 100.64.0.0/16 for T0-T1 interlink and is not available for use in an NSX-T environment like VMware Cloud on AWS.\n Enter Static IP Pools, click ADD and then click on SAVE\n  Click on **Save\n**  Create Inventory Group for External Networks #    Click Add Group\n  Enter Name and click on Set Members\n  Click on IP Addresses, enter the range associated with the external network previously specified and then click on APPLY\n  Click on SAVE\n  Create Firewall Rule to Allow VMware Cloud Director service Tenant Traffic #    Click Add Rule\n  Add rule details and then click on PUBLISH.\n  Notes: For Sources, make sure to select the Group created previously (VMware Cloud Director service External Network Ips). For Applied To, make sure to select Internet Interface.\nCreate First Tenant #  Create Organization #   Click on New  Fill in details and click on CREATE\n  Create Organization VDC #    Click on NEW\n  Fill in General details and click NEXT\n  Select Organization and click NEXT\n  Select Provider VDC and click NEXT\n  Select Allocation Model and click NEXT\n  Enter details and click NEXT\n  Select Storage Policy and click NEXT\n  Note: Thin provisioning and Fast provisioning are recommended, but not required.\n Select Network Pool and click NEXT\n  Confirm and click FINISH\n  Create Edge Gateway #    Click on NEW\n  Select Organization VDC and click on NEXT\n  Enter Name and click on NEXT\n  Select External Network and click on NEXT\n  Select Edge Cluster and click on NEXT\n  Add IP Allocation, click ADD, then click on NEXT\n  Review and click FINISH\n  Request a public IP for Tenant\u0026rsquo;s edge #    Click REQUEST NEW IP\n  Enter Notes and then click SAVE\n  Create a NAT pointing to the tenant\u0026rsquo;s edge gateway #    Click on ADD NAT RULE.\n  Select previously created public IP and make sure that the Internal IP matches the IP assigned to the edge gateway.\n  Click SAVE\n  Create Organization network #    Open Tenant portal by click on the box with the arrow next to the selected organization\n  Click on NEW\n  Select Scope and then click NEXT\n  Select Routed and then click NEXT\n  Select edge and the click NEXT\n  Enter name and CIDR and then click on NEXT\n  Enter Static IP Pool and then click on NEXT\n  Enter DNS and then click on NEXT  Review and click FINISH\n  Create SNAT to allow outbound traffic #    Select proper edge gateway and then under NAT click on NEW\n  Enter SNAT information and then click on SAVE.\n  Note: Make sure External IP is on the Edge and that the Internal IP matches the org network subnet\nConclusion #  At this point, the VMware Cloud Director service Instance is ready to deploy tenant VMs. For more information see the documentation for VMware Cloud on AWS, VMware Cloud Director service and VMware Cloud Director.\n"},{"id":114,"href":"/docs/cloud-director-service/implementation/","title":"VMware Cloud Director service Implementation","section":"VMware Cloud Director service","content":"VMware Cloud Director service Implementation #  This guidance provides a prescriptive path for deploying VMware Cloud Director service and software defined datacenters (SDDCs) as endpoints to consume for tenant workloads. This provides for an asset light model based on VMware stack deployments on public hyperscalers.\nPrerequisites #   You must first have access to the VMware Cloud Services portal (CSP), for more information see VMware Cloud Services Documentation. You should have an existing VMware Cloud Director services instance to manage the SDDC endpoint you wish to deploy, for more information see What is VMware Cloud Director service and How Does it Work.  Procedure #    Deploy and configure VMC on AWS SDDC for VMware Cloud Director service The following secion describes the procedure to deploy and configure VMC on AWS for VMware Cloud Director service.\n  Deploy and configure Google Cloud VMware Engine SDDC for VMware Cloud Director service The following secion describes the procedure to deploy and configure Google Cloud VMware Engine for VMware Cloud Director service.\n  "},{"id":115,"href":"/docs/cloud-infrastructure/vcf-metering/","title":"VMware Cloud Foundation Metering and Reporting","section":"Cloud Infrastructure","content":"VMware Cloud Foundation Metering and Reporting #  Configuration #  The Usage Meter administrator configures a vCenter and selects any of the VCF license editions to enable VCF for metering. Metering Time-based average of host CPU core count aggregated by the following different VCF editions:\n VMware Cloud Foundation for Cloud Providers Standard VMware Cloud Foundation for Cloud Providers Advanced VMware Cloud Foundation for Cloud Providers Enterprise VMware Cloud Foundation for Cloud Providers Standard without vSAN VMware Cloud Foundation for Cloud Providers Advanced without vSAN VMware Cloud Foundation for Cloud Providers Enterprise without vSAN  Time-based average capped billed vRAM GB per VM VCF edition:\n VMware Cloud Foundation for SDDC Manager  Feature Detection #  When metering VMware Cloud Foundation, Usage Meter performs two types of usage collections: event-based collections and inventory collections. What is reported are the host core CPUs and vRAM. Host core CPUs are collected from vCenter event-based collections and inventory collections. vRAM is collected from vCenter usage collections.\nHost Core Reporting #  Usage is calculated on a per ESXi host level for the duration the host is in use. The logic applies to editions with or without vSAN. Avg number of Cores = (sum of cores consumed per-hourly collections) / (hours in month)\n If at least one VM is running on a host (VM is in powered-on state), the host cores are reported for the duration of the VM is powered-on. If a host, whether it’s been modified, added, or placed into migration mode (i.e., host state changes) If a host is running with no powered-on VMs, the host cores will not be reported no matter if storage is consumed or not. Change of the VCF edition: Edition is applied to all cores of a host for the duration the edition is configured. When the VCF edition changes, the new edition is immediately applied to all cores of the host.  vRAM Reporting #  Usage is calculated as an average of the hourly vRAM usage over a month on vSphere instances marked as Rental (the same as vCenter). Avg Capped Billed vRAM (GB) = (sum of consumed GB per-hourly collections) / (hours in month) Hourly GB = min(max(memorySizeMB/2,reserved-memoryReservation),memory cap) memory cap = 24 * 1024 (24 GBs)\n Only powered-on VMs will be reported. Only one edition, SDDC Manager, will be reported as a vRAM metering. It is an add-on product, separate from the host core metering. It is not bundled with any other product.  Sample Monthly Usage Report #  Monthly Usage Units\n   Product Hostname Version VC UUID Unit of Measure Units to be Reported     VMware Cloud Foundation for Cloud Providers Standard    Avg Number of Cores 50   VMware Cloud Foundation for Cloud Providers Advanced    Avg Number of Cores 100   VMware Cloud Foundation for Cloud Providers Enterprise    Avg Number of Cores 100   VMware Cloud Foundation for Cloud Providers Standard without vSAN    Avg Number of Cores 50   VMware Cloud Foundation for Cloud Providers Advanced without vSAN    Avg Number of Cores 100   VMware Cloud Foundation for Cloud Providers Enterprise without vSAN    Avg Number of Cores 100   VMware Cloud Foundation for SDDC Manager    Avg Capped Billed vRAM (GB) 456    "},{"id":116,"href":"/docs/cloud-infrastructure/um-design/","title":"VMware vCloud Usage Meter Design","section":"Cloud Infrastructure","content":"VMware vCloud Usage Meter Design #  Detailed design information for Usage Meter goes here.\n Deployment model Design decisions Sizing Others  "},{"id":117,"href":"/docs/cloud-infrastructure/ta-design/","title":"VMware vRealize Tenant App Design","section":"Cloud Infrastructure","content":"VMware vRealize Tenant App Design #  VMware supports thousands of partners to host and sell clouds built on VMware technology using vCenter and Cloud Director (VCD). While vCenter provides the core of virtualization, Cloud Director provides needed constructs for segmenting the virtual infrastructure appropriately and offering it as a service to tenants of these partners.\nAs can be imagined, there are several variants of infrastructure that can be sold by these partners such as “Pay as you go”, “Raw capacity” aka “Allocation based”, “Raw capacity with minimum guarantee” aka “Reservation based”, “Flex” i.e. “a combination of others”. Potentially combination of these could be offered to same tenants. It becomes challenging to track usage over a period and charge appropriately due to this complexity. In addition, tenants demand for a transparency in this billing, and it is imperative that service providers offer it.\nvRealize Operations Tenant App (TA) sets out to solve these problems by metering the infrastructure. Further, it provides options to configure different models for pricing this metered infrastructure. Finally, it closes the loop by providing tenant specific views that help tenants validate their charges by looking at usage.\nArchitecture of TA is based on\n Data collector that collects data from vCenter, VCD and NSX, Pricing engine, that applies the charging policies defined by provider on the collected data  The collector and the pricing engine reside inside vRealize Operations Manager (vROps). TA appliance acts as a simple interface for creating pricing policies and storing generated “Bill”. TA appliance also provides a plugin to expose Tenant views inside VCD.\nBecause of these criterion, deployment of TA needs two Virtual Appliances namely the TA Virtual Appliance and the vROps Virtual Appliance. Partners who are already running vROps will be able to just connect Tenant App and begin, and those who do not can start with deploying the Chargeback Licensed edition of vROps.\nConfiguration of TA post deployment involves configuring vROps, Cloud Director, vCenter, and NSX. vROps connection is used for metering of collected data and bill generation. Cloud director connection is used for user management, providing Tenant view, and for collection of data from VCD using vROps VA. vCenter connection is used for collecting inventory changes and metering data about virtual machines using vROps. NSX connection is used for collecting usage information on network elements such as edges, load balancers, firewalls, etc. using vROps data collectors.\nA functional flow of using TA involves\n Defining pricing policies Associating these pricing policies to Org- VDCs coming from VCD Generating bills and reports (showback) using this combination Exposing these bills and other usage data to Tenants Providing an isolated view of the infrastructure and services for each tenant  Functional Flow Diagram\nPricing policies have several variants such as their infrastructure scope of application (e.g.: Allocation pool, PAYG, Reservation pool), charge rates for different resources (e.g.: 2$/vCPU/Day, 1$/GB RAM configuration/Day) and conditions for applying the rates (E.g.: Only when powered on, slabbed rate or overage). Associating pricing policies to org VDCs sets up a combination that can be used henceforth for all metering and billing. Bills are created on-demand based on provider’s request and contain a detailed result of applying a pricing policy on and Org-VDC. Reports are customizable entities containing historical data about pricing and usage. They can be scheduled and exported to formats such as CSV and PDF. A plugin to VCD allows these bills and usage data to be exposed to tenants. In addition, Tenant App provides a set of dashboards that can be exposed to tenants.\nLicensing #  Tenant App works in one of the two license modes.\n Chargeback License: This license mode enables basic functionalities of Tenant App including metering for Cloud Director, vCenter and NSX based infrastructure. The license key is applied from vROps UI, post which the UI of vROps is turned off and can be used only as a headless data collection and pricing engine. vROps entitled mode: If the partner is entitled to any variant of vROps already, he can continue to use the same vROps as a backend for Tenant App. In such cases, the partner gets additional flexibility of using vROps UI and perform customizations such as custom reports and dashboards based on his entitlement.  Deployment Architecture for vRealize Operations Tenant App for vCloud Director #  The following architecture provides an overview of integration of Tenant App with vCenter, vCloud Director, and NSX Management Packs.\nYou can receive data from vCenter, vCloud Director, and NSX Management Packs.\n vRealize Operations Manager collects resources from vCenter, vCloud Director, and NSX Management Packs using their respective Management Pack plugins and displays it in the vRealize Operations Manager Database. vRealize Operations Tenant App for vCloud Director interacts with vRealize Operations Manager using the Suite APIs (internal/external) to collect resources and pricing information. A service provider performs configuration actions using the standalone Tenant App UI. The tenant can either use vRealize Operations Manager Tenant App Plugin UI or the standalone Tenant App UI. All requests from Tenant App for vRealize OperationsvCloud Director are sent through Nginx Forward Proxy and the configuration is as displayed in the Deployment Architecture workflow diagram.  As can be seen in the diagram, combination of Tenant App appliance and vROps appliance together help service providers meter their infrastructure. vROps acts as the data collection engine talking to endpoints such as vCenter and Cloud Director using its management packs. Installation and configuration of these management packs are covered in Administration Guide of Tenant App. Tenant App adds a pricing layer on top of these collected metrics by allowing configuration of the pricing engine. The pricing engine itself runs inside the vROps appliance and outputs the pricing metrics back into vROps. So in essence for a provider, Tenant App VA acts as the configuration interface for pricing policies, whereas vROps acts as the single source of metrics for all collected and processed information. Full list of collected and processed metrics can be found in the addendum at the end of this white paper.\nTenant App VA also acts as the User interface that can be configured and plugged into Cloud Director to be accessed by Tenant Administrators. It provides summary information of usage and metered charges to Tenants of a provider.\nVirtual Machines are priced depending on how long they live in the environment. Tenant App and vROps can track VMs to a minimum granularity of 5 minutes and charge them i.e. even if the VM is alive only for 5 minutes, pricing engine will be able to associate a charge with this VM and roll it up.\nArchitecture and Port Requirements #  The following architecture provides the port requirement for the integration of vRealize Operations Tenant App for vCloud Director.\nIntegration of vRealize Operations Tenant App for vCloud Director as a plug-in #  The following architecture provides the port requirement of the vRealize Operations Tenant App for vCloud Director as a stand-alone app.\nIntegration of vRealize Operations Tenant App for vCloud Director as a stand-alone App #  Deployment Model #  If the deployment is in a vCloud Director based cloud deployment, follow the design for vRealize Operations Tenant App for vCloud Director as a plug-in.\nDesign Decisions #  Deploy a vRealize Operations Tenant App appliance at each physical site where there\u0026rsquo;s a vCloud Director deployment that will use the plug-in. IE - if you have two physical sites; one in New York and one in Los Angeles, deploy a Tenat App appliance at each site that will connect to the local vCloud Director.\nA public DNS name and IP will need to be allocated for each site that will resolve to the local Tenant App appliance, such as vta01.ny.cloud.mycompany.com. You can DNAT the public IP to the private IP assigned to the Tenant App appliance.\nPricing Policies #  This section provides details on various elements of pricing policy and how each of the components work in different scenarios, computation algorithm is described in detail.\nBase Settings #  Policy Name #  Service provider admin will provide a relevant name to policy; one policy can be eventually assigned to multiple organization VDC. Each Organization in Cloud Director corresponds to one tenant, so pricing policy provides flexibility at much granular level (Org-VDC) so that differential charging can be done for different tenants (organizations) as well as multiple Org-VDCs within same tenant (organization).\nPricing Policy Type #  This corresponds to types of allocation models (Allocation pool, Reservation pool and Pay-as-you-go) in VCD. This field is just used as an identifier only, so that when you create a policy you can assign a label to it so as to later associate it with appropriate organization VDC of same allocation model selected.\nThe choice here decides how you charge for CPU and memory. For details, refer to Table 1.1\nCurrency #  This is the currency in which pricing is setup and bills are generated, this currency is same as set in vROps. In vROps navigate to Administration \u0026gt; Management \u0026gt; Global Settings \u0026gt; Currency to set this value. Please note that this can be set only once per installation and cannot be modified once set.\nPolicy Description #  Any additional details to be mentioned about pricing policy.\nCPU Rate #  Charge CPU based on #  This is applicable when admin selects policy type as PAYG, where pricing happens at virtual machine level, and admin can choose to charge CPU based on either gHZ or based on vCPU count.\nCharge Period #  A specific price can be applied with different periodicity such as Hourly, Daily and Monthly. The base rate and fixed cost mentioned will get applied based on this frequency.\nCharge Based on #  For each allocation model in VCD admin can define specific rules based on which chargeback can happen, it can be based on resource allocation, usage or reservation (guaranteed resource) or max of two entities (usage vs allocation, usage vs reservation). The details of which value will be considered in computation based on this set rule is described in the below table.\nTable 1.1\n   Pricing Policy, Type / Allocation Model Charge Based Power State CPU Memory     Allocation Pool Charged on  Org-VDC Org-VDC    Allocation Not Applicable / No Impact CPU Allocation (GHz) Memory Allocation (GB)    Reservation Not Applicable / No Impact CPU Resoures Guaranteed (GHz) Memory Resources Guranteed (GB)    Usage Not Applicable / No Impact CPU Allocation Used (GHz) Memory Allocation Used (GB)    Max (Allocation, Usage) Not Applicable / No Impact Usage can go beyond what is allocated, so take whichever is higher Usage can go beyond what is allocated, so take whichever is higher    Max (Reservation, Usage) Not Applicable / No Impact Usage can go beyond what is guaranteed, so take whichever is higher Usage can go beyond what is guaranteed, so take whichever is higher   Reservation Pool Charged on  Org-VDC Org-VDC    Allocation Not Applicable / No Impact Same as allocation, as 100% is guranteed Same as allocation, as 100% is guranteed    Usage Not Applicable / No Impact CPU Reservation Used (GHz) Memory Reservation Used (GB)    Max (Allocation, Usage) Not Applicable / No Impact Usage can go beyond what is allocated, so take whichever is higher Usage can go beyond what is allocated, so take whichever is higher    Max (Reservation, Usage) Not Applicable / No Impact Usage can go beyond what is guaranteed, so take whichever is higher Usage can go beyond what is guaranteed, so take whichever is higher   Pay As You Go Charged on  VM VM    Allocation Not Applicable / No Impact Amount of configured CPU GHz at the VM level Amount of configured Membory GB at the VM level    Usage Not Applicable / No Impact CPU demand at the VM level Memory demand at the VM level    Default Base Rate #  Specific the rate or price at which you would like to charge the resource under consideration, this value will be multiplied accordingly with resource metered value to arrive at final charge to tenant in the bill generated.\nChage Based on Power State #  This rule is applicable for PAYG type of polices, where charging is done at virtual machine level and chargeback can be done based on three available options: Always, Only when powered-on, Powered-on at least once.\n Always: do not consider VM uptime, charge irrespective of that Only when powered-on: Charge will be prorated based on uptime  Example: if daily charge is 10$ per gHZ for CPU and specific VM was only 20 min a day, then charge will be prorated based on the fraction (20/1440), where 1440 is total minutes in day.   Power-on at Least Once: In this case full charge is applied even if VM is switched on at least once for minimum duration of minute.  Charge Overage #  This rule is applicable only to allocation pool model, where guaranteed resources are some % of total available resources. In this case till guaranteed %, normal base rate will be applied. If usage goes beyond guaranteed %, the rate mentioned in overage will be applied (for the delta usage which is higher than guaranteed).\n Example: in allocation pool model for specific Org-VDC if allocated CPU is 10 gHZ and guaranteed is 50%, which is 5 gHZ, the normal base rate is 3$ per gHZ and overage base rate is 4$, then if usage is found to be 6.5 gHZ, then for 1.5 gHZ the overage rate of 4$ is applicable and below which normal base rate of 3$ will be applicable.  CPU Base Rate Slab #  The service provider may want to charge differently based on the volume of resources consumed.\n Example: If usage is under 2 vCPUs, then default Base Rate $4 per vCPU will be applied for whole usage. If usage is greater than 2 vCPU, then Base Rate $6 per vCPU will be applied for whole usage.  Fixed Cost #  This price is applied to resource under consideration irrespective of resource metering. The difference between base rate and fixed cost is that base rate gets multiplied with resource metered quantity, if there is no resource consumption/allocation base rate will not be applied whereas fixed cost gets applied irrespective of metered resource. Fixed cost follows the charge period.\n Example: charge period = If the per vCPU rate is $2 and a fixed cost of $10 is specified for a VM that has 4 vCPUs, charges will be computed as 4vCPUs*$2 + $10 = $18  Memory Rate #  Please refer to the “CPU rate” section, as all the fields and rules are similar in nature except that resource under consideration will be memory metered in MBs.\nPrice Based on Sizing Policy #  There may be Service Providers that do not want to charge per vCPU or per GB RAM, instead they want standard pricing templates for charging their customers (similar to the concept in AWS where they have Small, Medium, Large, T2 Small, R2 Large etc.)\nSizing policies are predefined templates that are present in Cloud Director wherein you create a combo of vCPU and memory sizes and enter a rate against it.\nIn this, the price is based on VM Size instead of per CPU or Memory GB Charge individually.\nStorage Rate #  Charge Storaged Based on #  Admin has two options here, Storage policies and Default rate.. When ‘storage polices’ option is selected, admin can do a ‘differential’ pricing based on storage tiers as set in VCD, for specific Org-VDC. When ‘Default rate’ is selected, for all the datastore same base rate mentioned will be applicable irrespective of storage tiers (Default Rate is a legacy option and will be deprecated soon).\n Example: if the storage policies created in Cloud Director are Gold, Silver and Bronze tiers, a differential price of 4$, 3$ and 2$ per GB per month can be applied based on storage tiers.  Storage charges are not only applicable at the Org-VDC and VM level. But, they are also applicable for independent disks, media files, vApp templates.\nCharge Based on: VMs can be charged based on configured storage by selecting ‘Limit’ as an option or based on the actual storage consumed by them based on ‘Usage’ as the option in pricing policy.\nStorage Base Rate Slab #  The service provider may want to charge differently based on the storage consumed by the VM. So, in Storage also, we can charge based on the slab of consumption. Many Service providers provide a discounted rate if the consumption by VMs is higher.\n Example: If you want to charge a VM consuming 100GB of storage at a lower rate ($1 per month) compared to a VM consuming 50GB of storage that is charged at $1.5 per GB per month. In such a case, base rates will be configured as “greater than or equal to:50GB”, “base rate:1”, “default base rate:1.5”. In such a case, a VM having 150GB of storage will be charged $150 a month and a VM having 30GB of storage will be charged $45 a month.  Price Settings #  There are two types of Storage Pricing Policy Settings\n Aggregate storage charges from Storage profiles for PAYG Org-VDCs - this is the default mode for Storage Policy settings, and it includes overhead storage such as swap disks and log disks. Aggregate storage charges from VMs, media, vApp templates and independent disks for PAYG Org-VDCs – When the provider doesn’t want to charge the overheads to the users.  Please refer to the “CPU rate” section for other configuration parameters and rules, as all the fields and rules are similar in nature except that resource under consideration will be storage metered in GBs.\nNetwork Rate #  Tenant app charges network only at edge gateway level and not at the individual VM level.\nTenant App can charge for Edge gateways that are backed either by NSXV or NSXT. The same pricing rate card fields are used for charging either of these networks. The details of which metrics will be used in each case are given in the metrics table towards the end of this document.\nExternal Network Transmit #  Tenant app captures the egress data from edge gateway which in turn is associated with specific Org-VDC. Admin can apply a specific base rate ‘per mb’ of data transfer. The data is measured per edge gateway. All the traffic going through the network is charged here regardless of whether it’s going through the internet or not.\nExternal Network Receive #  Tenant app captures the ingress data from edge gateway which in turn is associated with specific Org-VDC. Admin can apply a specific base rate ‘per mb’ of data transfer. The data is measured per edge gateway. All the traffic going through the network is charged here regardless of whether it’s going through the internet or not.\nNetwork Transmit Rate (Bandwidth) #  There are 3 ways of charging bandwidth here.\n Conservative – In this this case the Service Providers charge for the average bandwidth consumed by the customer. This is more in favour of the customer and less in that of the Service Provider. Aggressive – Here, the Service Provider charges the whole usage at the peak bandwidth usage. This is more in favour of the Service Provider and less in that of the Customer  Example: The consumption rate is $10 per GBPS. If the average bandwidth usage is 5GBPS. But, the peak bandwidth used is 8GBPS. In this case, the tenant be charged $80 and not $50.   Moderate – In this case, the Service Provider would charge at the 95th Percentile value of the bandwidth.  Example: The user has had 100 usage samples of Bandwidths 1 to 100 GBPS each respectively. In this case, the peak bandwidth is 100 GBPS and average bandwidth is 50 GBPS. But, in a moderate pricing mechanism, the charge would be calculated on the basis of 95th percentile i.e. with respect to 95 GBPS.    Network Receive Rate (Bandwidth) #  There are 3 ways of charging bandwidth here.\n Conservative – In this this case the Service Providers charge for the average bandwidth consumed by the customer. This is more in favour of the customer and less in that of the Service Provider.  Example: You have a 10 GBPS line and the rate is $10 per GBPS. But your average bandwidth usage is 5GBPS. Here you’ll be charged $50.   Aggressive – Here, the Service Provider charges the whole usage at the peak bandwidth usage. This is more in favour of the Service Provider and less in that of the Customer.  Example: The consumption rate is $10 per GBPS. If the average bandwidth usage is 5GBPS. But, the peak bandwidth used is 8GBPS. In this case, the tenant be charged $80 and not $50.   Moderate – In this case, the Service Provider would charge at the 95th Percentile value of the bandwidth.  Example: The user has had 100 usage samples of bandwidths 1 to 100 GBPS each respectively. In this case, the peak bandwidth is 100 GBPS and average bandwidth is 50 GBPS. But, in a moderate pricing mechanism, the charge would be calculated on the basis of 95th percentile i.e. with respect to 95 GBPS.    Advanced Network Rate #  Edge Services #  Apart from the basic data transfer, there are additional value added services offered in Cloud Director in combination with NSX.\nAll the network services associated with specific edge such as HA, DHCP, IPV6, IP Sec, Load Balancer, NAT, SSL VPN, L2 VPN, Firewall, Static Routing, BGP Routing, OSPF Routing are considered for charging based on these services are ‘Enabled’ or not. If services are enabled for specific day and base rate is applied for that service, then that particular service gets charged for that specific day. If the service is disabled on any day then base rate will not get applied.\nIP Count #  These are the unique IP counts available on the external network of the Org-VDC. Pricing can be performed based on the count of these IPs.\nEdge Gateway Sizes #  Tenant app understands the size of the edge gateway (Compact, Large, Extra Large and Quad Large) and differential price can be assigned based on the edge size.\nNSXT Services #  Tenant app now allows you to price for NSXT services like Firewall Charges (per firewall rule count), L2VPN charges (per L2VPN count), Load Balancer Charges (per load balancer count).\nGuest OS Rate #  Guest OS for a specific VM can be charged to apply based on licensing costs. The Guest OS name should be mentioned as displayed in the VCD for specific VM.\nIn future, Guest OS name will be a dropdown in tenant app policy creation for the admin to select from the available list.\nCloud Director Availability #  Cloud Director availability services can be priced on the basis of replication objects that are created in a Cloud Director availability solution.\nReplication objects occupy certain amount of storage and have special qualities dependent on SLA profile that they belong to.\n Example: If the storage policies created in Cloud Director are Gold, Silver and Bronze tiers, a differential price of 4$, 3$ and 2$ per GB per month can be applied based on storage tiers. These prices for the replication objects will be the same depending on the storage profile the belong to.  Replication objects are also charged on the basis of the SLA profiles that they belong to. SLA profile defines attributes of these replication objects such as how frequently is the backup taking place, how many back-ups are preserved etc. Based on these SLA profiles, you can add additional costs on top of it.\n Example: If it is a ‘High frequency’ SLA profile, then you may want to charge an additional $100 per month for the given replication object.  There is ‘Storage Usage Charge’ section to set additional pricing for storage used by Cloud Director Availability replications in Cloud Director. Please note that the storage usage defined here will be added additionally to the Storage Policy Base Rate.\nThese replication objects will now be visible in the bill with their corresponding charges.\nvCenter Tag Rate #  If a VM is tagged with specific key (tag category) and value (tag value) in vCenter then this key-value can be specified to charge a VM or bunch of VMs differentially. Any VM having the specific tag will get this charge applied based on charge period.\nvCenter tag based charges that are added can be individually saved or obtained based on a setting ‘meteringTagDetailedMetricsEnabled’. When this setting is enabled, you can see each of the charges added here in this vCenter tag based section as an individual metric in vROps and hence in Tenant app as well.\nHow to Use the Confige File #  In EACH NODE within the vROps cluster should be performed the following steps:\n Connect the vROps node via SSH. Open and add/edit appropriate configuration in \u0026ldquo;$ALIVE_BASE/user/conf/analytics/advanced.properties\u0026rdquo; file. Restart the analytics service via \u0026ldquo;service vmware-vcops restart analytics\u0026rdquo; command.  Below shows a flag to enable/disable the publishing of particular flag specific prices as metrics on VMs.\n   Item Value     Confige Name meteringTagDetailMetricsEnabled   Default Value false   Possible Values true/false   Example meteringTagDetailedMetricsEnabled=true    These can be used when you want to apply additional charge for the applications running on the VM.\n Example: You want to charge additional $10 if there is an SQL server installed (across all VMs). In this case you can set a tag like “SQL Server = True” for these VMs in vCenter. Then, in Tenant App’s Pricing Policy, add a tag “SQL Server” with the value “True” and a rate of “$10” per month. This would apply an additional charge of $10 per month for all the VMs with the tag “SQL Server = True”.  vCenter Tag Alternative Pricing Policy #  Within vCenter Tag rate, there is an ability to configure ‘Alternate Pricing Policy’, that allows the user to configure an additional charge for each vCPU that may have value added services enabled.\n Example: For all VMs that have SQL server, you want to charge a different rate per vCPU per month. Say, a VM is charged at $1 per vcpu per month and you want to charge the SQL enabled VMs at $2 per vcpu per month. Here, you can create an alternate pricing policy like ‘SQL Server pricing policy’ that charges $2 per vCPU and $2 per GB RAM. In Tenant App Pricing Policy, you can apply a condition that if ‘SQL Server’ tag = ‘True’ then the Alternate pricing policy should be ‘SQL server pricing policy’  VCD Metadata Rate #  Very similar to VM Tags (as defined in the vCenter), admin can make use of VCD specific tags which are known as VCD Metadata. Objects with which specific metadata is associated will get the charge based on pricing attached to it in VCD metadata rate section of pricing policy.\nThese can be used when you want to apply additional charge for the applications running on the VM.\nMetadata based charges that are added can be individually saved or obtained based on a setting ‘meteringTagDetailedMetricsEnabled’. When this setting is enabled, you can see each of the charges added here in this metadata based section as an individual metric in vROps and hence in Tenant app as well. \u0026ldquo;ref to section above\u0026rdquo;.\n Example: You want to charge additional $10 if there is an SQL server installed (across all VMs). In this case you can use a VCD metadata like “SQL Server = True” for these VMs in VCD. Then, in Tenant App pricing policy, add the metadata tag “SQL Server” with the value “True” and a rate of “$10” per month. This would apply an additional charge of $10 per month for all the VMs with the tag “SQL Server = True”.  VCD Alternative Pricing Policy #  Within VCD Metadata, there is an ability to configure ‘Alternate Pricing Policy’, that allows the user to configure an additional charge for each vCPU that may have value added services enabled.\n Example: For all VMs that have SQL server, you want to charge a different rate per vCPU per month. Say, a VM is charged at $1 per vcpu per month and you want to charge the SQL enabled VMs at $2 per vcpu per month. Here, you can create an alternate pricing policy like ‘SQL Server pricing policy’ that charges $2 per vCPU and $2 per GB RAM. In Tenant App Pricing Policy, you can apply a condition that if ‘SQL Server’ tag = ‘True’ then the Alternate pricing policy should be ‘SQL server pricing policy’.  Note: This mechanism can effectively be used when charging for FLEX Org-VDCs\nOne Time Fixed Cost #  One time fixed cost is a charge levied by the Service Providers for the events (service or resource provisioning) that happen at a point in time (not regularly or periodically).\n Example: The charge of a new VM creation can be added as a ‘one time fixed cost’. Or, the Service Provider may address a support ticket that can be charged additionally, every time there’s a ticket that is addressed. This can also be configured with tags i.e. whenever you address a service request, you can add the tag (or VCD metadata)‘SR addressed’, the value ‘true’ on the VM. In Tenant App, if you have configured the Pricing Policy to add a ‘one time fixed cost’ when ‘SR Addressed’ = ‘True’ and one time fixed cost = ‘$50’, then the VM will get an additional ‘one time fixed cost’ of ‘$50’ in the bill. This one time fixed cost will be added every time the VM gets a tag ‘SR Addressed’ = ‘True’.  Note: In the above example, if the Service Provider intends to add ‘SR Addressed’ = ‘True’ cost every time an SR is addressed, then the recommended way is to set the tag ‘SR addressed =True’, leave it for a period of time (e.g. 2 hours) and then remove the tag.\nRate Factors #  Rate factors are used to either bump up or discount the prices either against individual resources consumed by the Virtual Machines, or whole charges against the Virtual Machine.\nFor VCD Metadata, you can change the price per vCPU, Memory, Storage Policy, Data In, Data Out, Bandwidth In, Bandwidth Out\nFor vCenter tag, you can change the price per vCPU, Memory, Storage Policy\n Example 1: Discount overall charge on VM by 50% (Rate Factor 0.5) for all VMs tagged with Promo=True. So, if the cost of VM as per the base rate is $100 then after applying the Rate Factor for promotional VMs (or Promo = True), it’ll be $50'   Example 2: Increase Storage rate by 100% (Rate Factor 2) for all VMs backed up by Avamar with tag ‘Avamar_Backed_Up = True’. In this case, the storage cost of VM as per the base rate is $100, then after applying the mentioned tag, it’ll become $200.  Tanzue Kubernetes Clusters #  ‘Tanzu Kubernetes Clusters’ section of the Pricing Policy helps you charge for Tanzu Kubernetes clusters and objects below an Org VDC based on certain attributes of Kubernetes like CPU, Storage, Memory and fixed cost per cluster.\n Example: You could apply a fixed charge of $100 per cluster per month with additional CPU charge of $0.1 per CPU ghz based on usage or allocation, similarly $0.05 per Memory GB based on usage or allocation and $0.05 per GB storage. You can also define a base rate slab to charge differently after different degree of usage.  CSE Kubernetes Clusters #  ‘CSE Kubernetes Clusters’ section of the Pricing Policy helps you charge for CSE Kubernetes clusters and objects below an Org VDC based on certain attributes of Kubernetes like CPU, Storage, Memory and fixed cost per cluster.\n Example: You could apply a fixed charge of $100 per cluster per month with additional CPU charge of $0.1 per CPU ghz based on usage or allocation, similarly $0.05 per Memory GB based on usage or allocation and $0.05 per GB storage. You can also define a base rate slab to charge differently after different degree of usage.  Additional Fixed Cost #  This section is used to add any other costs that are to be applied at Org-VDC level. This can be used for charges such as overall tax, overall discounts etc. These can be applied to selective Org-VDCs based on Org-VDC metadata.\n In the above screenshot, any Org-VDC with the above Pricing Policy enabled will be charged with $50 as an additional fixed cost per month Additionally, if the Org-VDC is tagged with the metadata ‘Snapshots Enabled = True’ will be charged $10 per day Also, if the Org-VDC has the ‘Installation Charge = True’ tag enabled, then an additional charge of $100 will be applied as a one-time fixed cost.  Reports and Bills #  Once these rates are set using the billing policy, they can be applied to organization VDCs in two different ways.\n You can assign a pricing policy to an organization VDC once, and vROps starts automatically calculating price metrics for the given Org-VDC and its resources using the assigned pricing policy. Subsequently, either customized reports can be created in vROps containing usage and price metrics, or prebuilt reports can be accessed from Tenant App. The advantage of setting up reports is that they can be scheduled and exported to formats such as PDF and CSV. You can also generate reports for the tenants to view directly at their end and send an email notification when reports become available. You can generate an On-Demand Bill by selecting an organization VDC and a pricing policy. This calculates the prices of Org-VDC and associated resources as per the values of the Pricing Policy at that point in time and presents a Bill inside Tenant App. This bill can be also shared with tenants. You can schedule bill generation, by selecting an Organization-VDC, a pricing policy and enable Schedule Bill setting. Then define the Recurrence (Monthly or Weekly), and detailed days of the billing period.  Note: This bill is typically used by the Service Providers via an API to read the details and feed to their own billing systems\nAlerts #  You can enable and select the type of alerts to be shared with the customer to view at their end. An email notification is also triggered to the tenants on the alerts enabled for them.\nDifferences Between Tenant App and Chargeback Manager / Usage Meter #  vRealize Operations Tenant App today does not present rollups of usage in units of MB.hours, but in terms of $ cost. This can be worked around by setting a cost of $1/MB.hr. vRealize Operations has all the individual data points, which can be accessed through the Tenant App APIs. A detailed description of the metrics used for the bill creation and API usage examples can be found in the Appendix.\nHowever, the collection interval, collection methods and rollup methods of vRealize Operations differs from Chargeback Manager / Usage Meter.\n"},{"id":118,"href":"/docs/cloud-infrastructure/vra-metering/","title":"vRealize Automation Metering and Reporting","section":"Cloud Infrastructure","content":"vRealize Automation Metering and Reporting #  VMware vRealize Automation (vRA) is available to service providers in two editions:\n vRealize Automation Advanced vRealize Automation Enterprise  Product Detection #  Service Provider registers vRA instance(s) in the Usage Meter 4.5.0.1 web application. Then the service provider enters a Cafe and IaaS hostname, port, username, and password. A validation of the user credentials is performed and if correct, the data collection starts. Usage Meter connects to the vRA Café server and collects its license edition. The appliance also connects to vRA IaaS and collects the number of managed VMs. Data is collected on an hourly basis.\nMetering #  The metering of vRealize Automation is per VM. The reported usage is calculated by the monthly average hourly count of non-unique VMs in the month. Example: If during the first 15 days of the month, there are 2 VMs and the last 15 days of the same reporting month, there are 4 VMs, the at the end of the month, the Monthly Usage Report will report 3 VMs (an average count of the non-unique VMs detected throughout the month).\nReporting #  Sample Monthly Usage Report adds a new line item for vRA.\n   Product Version Unit of Measure Units to be Reported     vRealize Automation Advanced  Managed VMs 1547    Note: When VMware Cloud Foundation is added for metering, all vRA lines are visible on vCloud Usage Insight but will not be sent to the VMware Commerce Portal. Providers update manually their vRA reporting in the Commerce Portal after reviewing the report in vCloud Usage Insight.\n"},{"id":119,"href":"/docs/cloud-infrastructure/vrni-metering/","title":"vRealize Network Insight Metering and Reporting","section":"Cloud Infrastructure","content":"vRealize Network Insight Metering and Reporting #  VMware vRealize Network Insight is available to service providers in two editions:\n vRealize Network Insight Advanced vRealize Network Insight Enterprise  Metering #  vRealize Network Insight is reported depending on the provider’s preference. The following are the available reporting options for vRealize Network Insight:\n Standalone – When vRNI is reported as a standalone product, then the metering is per VM or OSI per Month. The usage is calculated as the average hourly count of non-unique VMs in the month. Flex model add-on – When vRNI is reported as a Flex Add-on product, then the metering is per GB per Month.  Feature Detection #  Usage Meter detects if a VM is managed by vRealize Network Insight. If NSX-T Enterprise Plus edition and vRealize Network Advanced is detected for the same VM, the VM will not be reported for vRealize Network Insight.\n"},{"id":120,"href":"/docs/cloud-infrastructure/vrops-metering/","title":"vRealize Operations Metering and Reporting","section":"Cloud Infrastructure","content":"vRealize Operations Metering and Reporting #  Usage Meter supports several vRealize Operations (vROps) configurations:\n A Service Provider managed vRealize Operations server monitoring a single tenant. A Service Provider hosted vRealize Operations server for multiple tenants. A Service Provider hosted vRealize Operations server that manages VMs hosted by SP or hosted on customer’s premises. A vRealize Operations server configured with multiple vCenter servers.  Configuration #  vRealize Operations in Usage Meter 4.5.0.1 is added the same way as the rest supported VMware products. Providers need to enter the endpoint IP address or hostname, username, and password. If a vCenter server monitored by vROps is added to Usage Meter, then this vCenter will appear as a referenced vCenter in the details of the added vROps instance.\nvCenter servers monitored by a vRealize Operations server, which are also added for metering by Usage Meter, are named “Managed vCenter” servers. vCenter servers monitored by a vRealize Operations server but not added for metering to Usage Meter are named “Unmanaged Servers”. Both Managed and Unmanaged vCenter servers are listed in Usage Meter vRealize Operations report lines.\n“Unmanaged Servers” can be associated with only one vRealize Operations instance if monitored by multiple instances. This will be the vRealize Operations instance with the highest edition. Virtual machines part of that “Unmanaged Servers” will be billed once no matter how many vRealize Operations instances are monitoring them. For the billing of monitored VMs will be taken the vRealize Operations instance with the highest edition.\nUsage Meter connects to a vRealize Operations server using the account provided by the Usage Meter administrator. Usage Meter will meter all VMs that are visible through the provided account.\nTo meter only a subset of monitored VMs, for example, to divide monitoring by Tenant, vRealize Operations should be configured to filter the monitored virtual machines to include only a subset of the VMs deployed to the monitored vCenter instance.\nThis is accomplished by creating a new account in vRealize Operations and configuring Role Base Access Controls to restrict the view of the account to the desired Virtual Machines. The RBAC restricted account and credentials are provided to Usage Meter when the vRealize Operations server registration is completed.\nRefer to the Product Usage Guidefor detailed configuration instructions.\n) Figure 10\nMetering #  The vRealize Operations license edition is retrieved by Usage Meter from the vRealize Operations server during each data collection. vRealize Operations metering is based on Virtual Machines monitored by a vRealize Operations Server. Service providers are responsible for reporting usage for monitored VMs and OSI Instances (which represent non-virtualized servers). Usage Meter 4.5.0.1 does not track OSI instances monitored by vRealize Operations or add-on packages such as Blue Medora. Usage Meter 4.5.0.1 automatically detects the following vRealize Operations editions:\n vRealize Operations Standard vRealize Operations Advanced vRealize Operations Enterprise  When Usage Meter connects to a vRealize Operations instance, it checks for its version. If the version of the metered vRealize Operations instance is 8.6 or later, Usage Meter checks if there are VMs part of a license group. If there are such VMs, Usage Meter 4.5.0.1 reports them against the highest vRealize Operations edition assigned to that license group. In case there is a VM part of multiple license groups, then Usage Meter will report the highest edition of the first license group it queries.\nFor vRealize Operations instances with previous versions, Usage Meter 4.5.0.1 will only report the monitored VMs against the highest vRealize Operations edition that it detects. Usage Meter 4.5.0.1 will not check if there are VMs part of license groups for vRealize Operations before version 8.6.\nFor example, if Usage Meter 4.5.0.1 connects to vRealize Operations 8.5 and it detects two license editions: Advanced and Standard, then for all VMs monitored by that vROps, the reported license by Usage Meter 4.5.0.1 will be Advanced. In the Monthly Usage Report, the highest detected vROps license edition by Usage Meter will be reported irrespective of the vROps version. The highest license against which a VM is reported can be checked in the Virtual Machine History Report.\nReporting #  vRealize Operations is reported by Usage Meter 4.5.0.1 as either Flex Add-on or standalone. When usage is reported as a Flex Add-on, the metric is the Avg Capped Billed vRAM value of the monitored Virtual Machine. When reported standalone, the metric is the Average Number of Virtual Machines monitored by vRealize Operations during the reporting month.\nThe following rules apply to the reporting of vRealize Operations:\n vRealize Operations Standard, Advanced and Enterprise editions are reported as a Flex add-on or standalone depending on the customer’s preference. vCenter servers using vRealize Operations will always be reported as a standalone line item on the monthly usage report as (unmanaged) if they are not added to vCloud Usage Meter. When vRealize Operations edition is reported as standalone, and the vCenter servers monitored by it are added to Usage Meter 4.5.0.1, then the monthly usage report will include a single line vRealize Operations edition (managed). Unmanaged vCenter Servers are associated with only one vRealize Operations instances if monitored by multiple vRealize Operations instances. The VMs of those unmanaged vCenter Servers will be billed once based on the vRealize Operations instance with the highest edition.  Metering Scenarios #  Scenario One: vRealize Operations Server monitoring both SP and Tenant vCenters\nFigure 11\nConsider the following reporting scenario: A vCenter server is registered with Usage Meter.\nA vRealize Operations server that monitors the same vCenter is also added for metering to Usage Meter 4.5.0.1. Usage Meter queries the vRealize Operations server to determine what vCenter servers it monitors. The vRealize Operations server returns a list of three vCenter servers, only one of which is registered with Usage Meter. Usage Meter monthly report will include 2 Unmanaged vRealize Operations servers and 1 Managed vRealize Operations server line items.\n"},{"id":121,"href":"/docs/cloud-infrastructure/vsan-metering/","title":"vSAN Metering and Reporing","section":"Cloud Infrastructure","content":"vSAN Metering and Reporting #  vSAN is activated at a host-cluster level either while creating new clusters or updating existing host clusters. vSAN aggregates all local storage devices across all hosts in the vSAN cluster into a single datastore. More storage devices or hosts can be added to the cluster to expand its datastore capacity. If a host contributes to the vSAN datastore, it must provide at least one device for flash cache and another for persistent storage. Capacity devices are also called data disks. The devices on the contributing hosts form one or more disk groups, and each disk group contains one flash cache device and one or more capacity devices. Devices used for caching cannot be shared across disk groups. Each host can be configured to use multiple disk groups. The amount of physical capacity from the vSAN datastore consumed by one or more VMs at any point is called the consumed capacity.\nConfiguration #  With Usage Meter 4.5.0.1, vSAN is automatically detected. There should be at least one vSAN cluster per vCenter Server so that Usage Meter detects and meters it. When one or more clusters in the vCenter are enabled with vSAN, the vCenter product configuration list page in the Usage Meter web application indicates that vSAN is associated and used for that vCenter.\nFeature Detection #  vSAN usage is metered per vSAN enabled cluster (see Cluster History Report) and reported aggregated by vSAN license editions (see Monthly Usage Report). vSAN usage is collected on an hourly basis by the Usage Meter appliance. vSAN usage collection intervals are closed when one or more of the following scenarios occur:\n vSAN collection fails to send collected data for 24 hours or more vSAN enabled cluster is deleted vSAN license has changed When vCenter product is not metered and/or deleted from the Usage Meter web app Products page.  Note: The collection intervals are shown in the vSAN Cluster History Report.Specific space efficiency and QoS features are detected during these hourly collections and are used to determine the billing rate of vSAN usage.\nvSAN usage is metered at a cluster level. While there are many features and capabilities that vSAN offers, from the perspective of usage metering, Usage Meter 4.5.0.1 records the following cluster-level and VM-level features:\n Cluster level: Base , Deduplication, Compression, Stretched Cluster, Data-at-rest Encryption, File Services, HCI Mesh, Shared Witness, Data in Transit Encryption, and Cloud Native Storage. When these features are enabled, the entire cluster is marked as using these features. At a VM level, usage is reported per cluster: Raid 5/6 Erasure Coding feature is enabled at the individual virtual machine level but scoped and reported at the cluster level. If one or more virtual machines (regardless of the power state) have enabled this feature, then this feature is considered enabled for the entire cluster. Usage Meter 4.5.0.1 examines the vSAN features enabled for the cluster to determine the reported license edition. The following vSAN features are automatically detected by Usage Meter and reported in the vSAN Cluster History Report.     vSAN Features vSAN Standard vSAN Advanced vSAN Enterprise     Stretched Cluster   X   Raid 5/6 Erasure Coding  X X   File Services   X   Deduplication and Compression  X X   Data-at-rest Encryption   X   Base X X X   HCI Mesh   X   Shared Witness X X X   Data in Transit Encryption   X   Cloud Native Storage X X X    Note: Usage Meter 4.5.0.1 detects VMs compliant with Storage Policy - Raid 5/6 Erasure Coding. When one or more VMs in a vSAN enabled cluster are compliant with this policy, customers are billed at vSAN Advanced edition.\nvSAN Reporting #  vSAN usage is reported as monthly aggregated total used storage capacity by a vSAN license edition in the Monthly Usage Report generated by Usage Insight. More granular information about the vSAN usage can be seen in the vSAN Cluster History Report (see an example below). This report includes information about what storage capacity and features have been used by a cluster per time interval. It also shows the detected vSAN license edition of a cluster. The features that are used by a vSAN cluster can be calculated from the vSANFint column in that report. See the vSAN Cluster History Report information. The average used storage for vSAN is calculated as: Average GB = (Sum of consumed storage capacity in GB per-hourly collections) / (Hours in a month). The value can be zero if no vSAN usage exists or vSAN was not configured. Average Used Storage means the storage capacity consumed by all virtual machine disks (VMDK) and not available for new allocations in GB averaged during the applicable reporting period. This includes swap space (if utilized) and the RAID overhead set within the storage policy.\nNote: Usage Meter 4.5.0.1 only reports usage against the vSAN license the detected features are part of. For example, a cluster with a vSAN Enterprise license is detected to use features also part of vSAN Advanced, like Compression and Deduplication. In this case, if there are no other features used that are only part of vSAN Enterprise during the reporting month, then the Monthly Usage Report will report usage against the vSAN Advanced edition. The following vSAN editions are reported in the generated reports by Usage Insight:\n vSAN Standard. vSAN Advanced. vSAN Enterprise  Note: vSAN is not reported standalone and included in Horizon DaaS bundles. Also, vSAN with Desktop and ROBO licenses are excluded from the usage reports.\nvSAN Cluster History Report #  vSAN Cluster History Report contains the used capacity (in MB) per time interval for vSAN enabled clusters in vCenter Servers metered by Usage Meter 4.5.0.1. Additionally, it displays the vSAN license edition and the features used by a cluster. Note: To verify which vSAN cluster features were detected by Usage Meter 4.5.0.1, use the integer value in the table below and compare it with the vsanFInt column in the Cluster History Report.\nA vSAN cluster might use several features, and the way to find them is to subtract from the vSANFint value for a cluster the highest possible int value of a vSAN feature detected by Usage Meter.\nFor example, if you have a value of 6 in the vSANFint column in the cluster history report, subtract 4 (the highest possible value of a vSAN feature that can be subtracted from 6). The int value of 4 represents Compression, as seen from the table below. The result of the subtraction will be 2 (6-4), which stands for Deduplication. In conclusion, the cluster with a vSANFint value of 6 in the vSAN cluster history report uses two vSAN features: Compression and Deduplication.\n   Feature Feature Int Value     BASE 1   DEDUPLICATION 2   COMPRESSION 4   ERASURE_CODING 8   STRETCHED_CLUSTER 16   DATA_AT_REST_ENCRYPTION 32   FILE_SERVICES 64   DATA_IN_TRANSIT_ENCRYPTION 128   CLOUD_NATIVE_STORAGE 256   HCI_MESH 512   SHARED_WITNESS 1024    Sample Cluster History Report and Monthly Usage Report\n   VCHostName vSAN ClusterId vSAN ClusterName vSAN License vSAN Used (MB**)** From To Interval vSANFint     0UfypLEAUZCz domain-xyz 0UfypLEAUZCy std 2500 2021-12-18 11:32:14 2021-12-18 17:05:31 05:33:17 1   0UfypLEAUZCz domain-xyz 0UfypLEAUZCy std 3500 2021-12-19 11:32:14 2021-12-19 19:05:31 08:33:17 1   0UfypLEAUZCz domain-abc 0bxyzABCkMy ent 9500 2021-12-18 17:05:31 2021-12-19 18:05:31 1 day 00:59:59 6   0UfypLEAUZCz domain-abc 0bxyzABCkMy ent 2500 2021-12-20 11:05:31 2020-12-20 18:45:50 07:40:19 6    In the Cluster History Report, the vSAN license is the edition activated for a cluster and detected by Usage Meter 4.5.0.1. Another important column in the report is vSANFint. With the values in this column, you can identify the features used by a cluster per time interval. The detected features determine the vSAN license edition by which the aggregated usage will be reported in the Monthly Usage Report. There might be a difference between the detected license edition activated for a cluster and the reported license edition in the Monthly Usage Report. This happens when the cluster has used only a portion of the features part of the license. These features are also part of another license, e.g., a cluster with an Enterprise license has only used features that are also part of the vSAN Standard edition. As a result, only what has been used during the reporting period is reported against the respective license edition in the Monthly Usage Report. See below what the Monthly Usage Report will be for the vSAN consumption shown in the above Cluster History Report:\n   Product Hostname Version VC UUID Unit of Measure Units to be Reported     VMware Virtual SAN Standard    Avg Billed vSAN Storage (GB) 2   VMware Virtual SAN Advanced    Avg Billed vSAN Storage (GB) 5    The units reported in the Monthly Usage Report for vSAN are calculated based on the average vSAN storage capacity consumption throughout the month in GB per vSAN license edition, rounded down to the nearest whole number.\nNote: The vSAN storage consumption in the Cluster History Report is shown in MB; thus, it must be converted to GB to check if the usage in the Cluster History Report matches that in the Monthly Usage Report.\n"},{"id":122,"href":"/docs/developer-ready-cloud/implementation/","title":"Developer Ready Cloud Implementation","section":"Developer Ready Cloud","content":"Developer Ready Cloud Implementation #  Implementing {VVS for CP Title} validated solution includes configuring \u0026hellip; and enabling \u0026hellip;\nTo implement and configure {VVS for CP services}, two alternative methods exist. You can use the user interface of each component in the solution or you can use PowerShell cmdlets. You can directly reuse the PowerShell commands by replacing the provided sample values with values from your VMware Cloud Foundation Planning and Preparation Workbook.\nThis guidance provides a prescriptive path for deploying {VVS for CP solution} using \u0026hellip;, and sample {VVS for CP services} in a {management|VI workload} domain. For more information on other deployment options and configurations, read the {VVS for CP Products} Configuration and Management guide. See the {VVS for CP Products} documentation for more details.\nPrerequisites #   Verify that your environment is configured according to Before You Apply This Guidance and the Developer Ready Infrastructure tab of the VMware Cloud Foundation Planning and Preparation Workbook. If you want to use the included Microsoft PowerShell cmdlets to perform implementation and configuration procedures, verify that your system fulfils the following prerequisites.  Verify that your system has Microsoft PowerShell 5.1 installed. See Microsoft PowerShell. Install the PowerValidatedSolutions PowerShell module together with the supporting modules from the PowerShell Gallery by running the following commands. Install-Module -Name VMware.PowerCLI -MinimumVersion 12.4.1 Install-Module -Name VMware.vSphere.SsoAdmin -MinimumVersion 1.3.7 Install-Module -Name ImportExcel -MinimumVersion 7.1.1 Install-Module -Name PowerVCF -MinimumVersion 2.2.0 Install-Module -Name PowerValidatedSolutions -MinimumVersion 1.7.0  Import the PowerValidatedSolutions and the PowerCLI PowerShell modules by running the following commands. Import-Module -Name VMware.PowerCLI -MinimumVersion 12.4.1 Import-Module -Name PowerValidatedSolutions -MinimumVersion 1.7.0     Procedure #    [Configure Product 1](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  [Configure Product 2](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  [Deploy and Configure Product 3](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  [Deploy and Configure Product 4](link md file here)\nDescription of proceedure [//]: # (Add [[Read more]] and link to same md file here)\n  Developer-Ready Cloud Associated Products #  The following list of products enchances the capabilities of the out-of-the-box VMware Developer-Ready Cloud.\n   Product Description Use Cases     VMware Cloud Director Object Storage Extension Cloud Director Plug-in for supplying additional S3 storage to provder\u0026rsquo;s tenants. Storage-as-a-Service, Backup-as-a-Service,Archive-as-a-Service, Big Data-as-a-Service, Disaster Recovery-as-a-Service                   "},{"id":123,"href":"/docs/developer-ready-cloud/operations/","title":"Developer Ready Cloud Operations","section":"Developer Ready Cloud","content":"Developer Ready Cloud Operations #  After you complete the implementation of the Developer Ready Cloud, you perform common operations on the environment, such as \u0026hellip;\nFor operational guidance on the components that are deployed automatically in VMware Cloud Foundation or complement the basic VMware Cloud Foundation configuration, see the VMware Cloud Foundation Operations and Administration Guide in the VMware Cloud Foundation documentation.\nPersonas in Developer Ready Cloud #  Personas describe types of system users, aligned with real people and their functions within the organization. You build a persona set based on your organization\u0026rsquo;s requirements for role-based access control.[Read more]\nOperational Verification of Developer Ready Cloud #  After you add a {VVS Product/Suite} instance in your VMware Cloud Foundation environment during the implementation of the Developer Ready Cloud validated solution, verify that the newly-implemented and reconfigured components are operational and functioning within expected parameters.[Read more]\nCertificate Management for Developer Ready Cloud #  The security of your environment depends on the validity and trust of the SDDC component certificates. After you deploy and configure the standalone {VVS Product/Suite} instance to your VMware Cloud Foundation environment, you replace the component certificate if the certificate is expiring or compromised, or some of the certificate attributes, such as the host or organization name, must be changed.[Read more]\nPassword Management for Developer Ready Cloud #  Manage the account passwords of the components in your VMware Cloud Foundation environment according to the design objectives and design guidance of Developer Ready Cloud validated solution.[Read more]\nShutdown and Startup of Developer Ready Cloud #  In certain cases, for example, during hardware or power maintenance of the data center, you must shut down the standalone {VVS Product/Suite} instance in a VMware Cloud Foundation environment in a way that prevents data loss and appliance malfunction, and start it up restoring component integration after the maintenance operation is over.[Read more]\nMetering of Developer Ready Cloud #  After implementing Developer Ready Cloud you must take steps to ensure that proper usage metering of the new {VVS Product/Suite} begins.[Read more]\nAPI Tokens in Cloud Director #  VMware Cloud Director 10.3.1 introduced API Tokens. This allows a user to generate API tokens for programmatic access to VCD. It works for both, provider, and tenant users. An automation script or 3rd-party solution can then use the API token to make API requests to Cloud Director on behalf of the user.\nThese steps are used to create API tokens:\n The provider propagates the right to use and manage API token to the tenant The Cloud Director user (provider as well as tenant user) creates an API token An API client (e.g. an automation script) uses the API token to make requests (If needed) The user revokes the API token  Preparation #  As for most new features, fine-grained access control through rights bundles is possible. To enable a tenant to use API token, the provider must publish a rights bundle to the tenant. Privileges can be defined for a user to manage the user’s own tokens, and to manage all Organization user’s token (for example for an Organization Administrator).\nCreate the API Token #  As provider or tenant user with proper privileges you can use the “User Preferences” menu to create the API token. Each token can be labeled with a name. Be aware that the actual token key is only visible once in the creation wizard and cannot be retrieved afterwards.\nRevoke the API Token #  API tokens do not expire, but existing API tokens can be revoked. This also invalidates active API client sessions that used the token to authenticate. All users can revoke their own tokens. Administrators (those with \u0026lsquo;manage all user\u0026rsquo;s API tokens\u0026rsquo; right) can revoke other user\u0026rsquo;s tokens. Tenant administrators can do so within their own Organization, while system administrators can do so for any user.\nUse the API Token #  Semantically the API token usage follows the OAuth 2.0 specification (RFC 6749, section 6).\nThe API token can then be used by a 3rd-party solution or custom API client to access the VCD API as the user, without the need to authenticate with username and password credentials.\nAPI Client Example #  Request the bearer token for subsequent calls using the API token:\nPOST https://host_name/oauth/provider/token Accept: application/json Content-Type: application/x-www-form-urlencoded Body: grant\\_type=refresh\\_token\u0026amp;refresh\\_token=Generated\\_API_Token  Security note: It’s recommended to send the API Token as part of the request body (and not as part of the URL, even if that technically works for x-www-form-urlencoded type requests), to avoid it being logged in transit.\nResponse containing the Bearer token:\nHTTP/1.1 200 OK Content-Type: application/json Body: { \u0026quot;access\\_token\u0026quot;:\u0026quot;Generated\\_Access_Token\u0026quot;, \u0026quot;token_type\u0026quot;:\u0026quot;Bearer\u0026quot;, \u0026quot;expires_in\u0026quot;:86400, \u0026quot;refresh_token\u0026quot;:null }  Subsequent API call now can use the returned Bearer token in the \u0026ldquo;access_token\u0026rdquo; field as usual. There is no need for any changes in the client code.\nSubsequent Call using the Bearer token:\nGET https://host_name/api/org Accept: application/*+xml;version=36.1 Authorization: Bearer Generated\\_Access\\_Token  Notes #  The session expiration can be configured in the provider portal under General \u0026gt; Timeouts.\nThe VCD Provider for Terraform for example supports API Token authentication as of version 3.5:\nprovider \u0026quot;vcd\u0026quot; { user = \u0026quot;none\u0026quot; password = \u0026quot;none\u0026quot; auth\\_type = \u0026quot;api\\_token\u0026quot; api_token = Generated API token sysorg = \u0026quot;System\u0026quot; ...  For security reasons, certain tasks are not possible when authenticated through an API token:\n Change the user password Perform user management tasks Create more tokens View or revoke other tokens  When accessing VMware Cloud Director by using an API access token, applications have only view rights for the following resources.\n User Group Roles Global roles Rights bundles  The API Token feature in VMware Cloud Director offers a secure way for automation solutions to access its API, even in environments that enforce Multi-factor Authentication for user logins.\nReferences #   VMware Cloud Director Tenant Portal Documentation VMware Cloud Director Provider Portal Documentation OAuth 2.0 Specification (RFC 6749) VCD Provider for Terraform Documentation  "},{"id":124,"href":"/docs/cloud-infrastructure/cplcm-appliance-deployment/","title":"Cplcm Appliance Deployment","section":"Cloud Infrastructure","content":"#  Deploy VMware Cloud Provider Lifecycle Manager On VMware Cloud Foundation #  #  Deploy VMware Cloud Provider Lifecycle Manager on VMware Cloud Foundation for automated deployment of products like VMware Cloud director, vRealize Operations manager Tenant App, Usage Meter and Rabbit MQ.\nStarting with version 1.2, VMware Cloud Provider Lifecycle Manager is delivered as a virtual appliance. You must deploy the virtual appliance on an ESXi host or in a vCenter Server. Here are the steps you need to take to deploy VMware Cloud Provider Lifecycle Manager 1.4.\nUI Procedure #  You can deploy the VMware Cloud Provider Lifecycle Manager appliance as an OVA by using the vSphere Client (HTML5). For more details, check the following information.\n  In the vSphere Client, right-click any inventory object and click Deploy OVF Template.\n  Enter the path to the VMware Cloud Provider Lifecycle Manager.Ova file and click Next.\n  Enter a name for the virtual machine and browse the vCenter Server repository to select a data\ncenter or folder on which to deploy the appliance and click Next.\n  Select an ESXi host or cluster on which to deploy the appliance and click Next.\n  Review the template details and click Next.\n  Read and accept the license agreements and click Next.\n  Select the disk format and the datastore for the virtual machine configuration files and virtual\ndisks, and click Next.\nThick formats improve performance, and thin formats save storage space.\n  From the drop-down menus in the Destination Network cells, select the target networks for\nthe eth0 NIC of the appliance.\n  From the IP allocation Settings drop-down menus, select a Static-Manual IP allocation and an\nIPv4 protocol.\n  Click Next.\nYou are redirected to the Customize template page of the wizard to configure the VMware\nCloud Provider Lifecycle Manager details.\n  In the section Application Settings, configure the appliance details.\n  In section Additional Networking Properties, enter the network details for the VMware Cloud\nProvider Lifecycle Manager appliance, and click Next.\n  On the Ready to Complete page, review the configuration settings for the VMware Cloud\n  Provider Lifecycle Manager appliance, and click Finish to start the deployment.\n  VMware OVF Tool Procedure #  You can deploy the VMware Cloud Provider Lifecycle Manager appliance as an OVF template by using the VMware OVF Tool.\nFor information about installing OVF Tool, see the VMware OVF Tool Release Notes document. For information about using OVF Tool, see the OVF Tool User\u0026rsquo;s Guide.\nRead the following information for more details.\nAn Example Command for Deploying a Production Primary VMware Cloud Provider Lifecycle Manager Appliance\novftool \u0026ndash;name=vcplcm-demo-1 \u0026ndash;X:logFile=/tmp/vcplcm-deploy.log \u0026ndash;X:logLevel=info \\\n\u0026ndash;noSSLVerify \u0026ndash;acceptAllEulas \u0026ndash;allowAllExtraConfig \u0026ndash;diskMode=thin \\\n\u0026ndash;datastore=sfo-m01-cl01-ds-vsan01 \u0026ndash;network=sfo01-m01-cl01-vds01-pg-mgmt \u0026ndash;powerOn \\\n\u0026ndash;prop:varoot-password=\u0026lsquo;Root_pw1\u0026rsquo; \\\n\u0026ndash;prop:vcplcm-admin-password=\u0026lsquo;VCPlcm_pw1\u0026rsquo; \\\n\u0026ndash;prop:vcplcm-api-port=9443 \\\n\u0026ndash;prop:ntpserver=time.vmware.com \\\n\u0026ndash;prop:hostname=vcplcm-demo-1 \\\n\u0026ndash;prop:netipaddress0=x.x.x.x \\\n\u0026ndash;prop:netprefix0=24 \\\n\u0026ndash;prop:netgateway0=x.x.x.x \\\n\u0026ndash;prop:netdns0=x.x.x.x,y.y.y.y \\\n\u0026ndash;prop:domainname=test.dom \\\n\u0026ndash;prop:searchdomains=test1.dom,test2.dom \u0026ndash;prop:ceip_enable=True \\\n\u0026ndash;prop:nfs_mount=vsan-nfs.test.dom:/vsanfs/cplcmrepo \\\nVMware-Cloud-Provider-Lifecycle-Manager-version-number.ova \\ vi://vc_user_name:vc_password@vc_hostname_or_ip_address/vc_dataceter_name/host/vc_cluster_name\n"},{"id":125,"href":"/docs/cloud-infrastructure/cplcm-certificate-management-2/","title":"Cplcm Certificate Management 2","section":"Cloud Infrastructure","content":"Manage VMware Cloud provider Lifecycle Manager Certificates #  Configure VMware Cloud provider API and UI certificates.\nVMware Cloud Provider Lifecycle Manager API Certificate Management\nAfter deploying the VMware Cloud Provider Lifecycle Manager appliance, VMware Cloud Provider Lifecycle Manager generates a self-signed certificates for the API and the internally used vault.\nYou can configure VMware Cloud Provider Lifecycle Manager to either use the self-signed certificate or your own custom certificate by providing a PKCS12 keystore containing the certificate.\nVMware Cloud Provider Lifecycle Manager stores the properties for the alias, keystore name, type and password in the /opt/vmware/cplcm/config/application.properties file. To change these settings, you must update the application.properties file.\nIn /etc/environment, you can set the keystore password for the custom certificate by configuring the CPLCM_KEYSTORE_PW environment variable. Alternatively, you can configure it in the application.properties file for the server.ssl.key-store-password property.\nVMware Cloud Provider Lifecycle Manager UI Certificate Management\nAfter deploying the VMware Cloud Provider Lifecycle Manager appliance, VMware Cloud Provider Lifecycle Manager generates a self-signed certificates for the UI.\nYou can configure VMware Cloud Provider Lifecycle Manager to either use the self-signed certificate or your own custom certificate by providing the custom certificate and key files in PEM format.\nVMware Cloud Provider Lifecycle Manager stores the files with the certificate and key under the /opt/vmware/cplcm/security/certs/ directory. To change the certificate, you must replace the vcplcm-gui.pem and vcplcm-gui.key files, and restart the nginx service.\nConfigure custom certificate on VMware Cloud Provider Lifecycle Manager\nYou can configure VMware Cloud Provider Lifecycle Manager to use a custom certificate.\nTo configure a custom certificate on VMware Cloud Provider Lifecycle Manager, you must provide a PKCS12 keystore containing the certificate.\nProcedure\n Generate the custom certificate and create the keystore.  CPLCM_CERT_DIR=/opt/vmware/cplcm/security/certs\n mkdir -p $CPLCM_CERT_DIR\n key_alias=vcplcm\nkeystore_password=$CPLCM_KEYSTORE_PW\nsubj=\u0026quot;/CN=VCPLCM, O=VMware\\, Inc, c=US\u0026quot;\n openssl req -x509 -newkey rsa:4096 -subj \u0026ldquo;$subj\u0026rdquo; -keyout $CPLCM_CERT_DIR/tmpKey.pem -out $CPLCM_CERT_DIR/tmpCert.pem -days 365 -nodes\nopenssl pkcs12 -export -out $CPLCM_CERT_DIR/vcplcm.p12 -name $key_alias -passout \u0026ldquo;pass:$keystore_password\u0026rdquo; -inkey $CPLCM_CERT_DIR/tmpKey.pem -in $CPLCM_CERT_DIR/tmpCert.pem\n After importing the keystore, remove the tmp key and certificate.   rm $CPLCM_CERT_DIR/tmpKey.pem\nrm $CPLCM_CERT_DIR/tmpCert.pem\n "},{"id":126,"href":"/docs/cloud-infrastructure/cplcm-configuration/","title":"Cplcm Configuration","section":"Cloud Infrastructure","content":"Product Repository #  During the first boot of a newly deployed VMware Cloud Provider Lifecycle Manager appliance, the system automatically creates the product directories and sets their permissions. You can either upload the product binaries to the respective directories or mount an existing pre-configured repository directory. On VMware Cloud Provider Lifecycle Manager, you must store the product deployment and upgrade files in the respective product directories.\nUpload the Product OVA Files to the VMware Cloud Provider Lifecycle Manager Appliance #  You must upload the product OVA files and product update files to a specific pre-defined file structure. After the first boot, VMware Cloud Provider Lifecycle Manager creates a separate repository folder for every product that the appliance can manage. You can configure the permissions for every directory. As a result, the files within the directory inherit the permissions you configure on the directory level. At a later stage, if you add a new file to a product directory, the new file does not inherit the permissions from the directory and you must configure the 755 permissions on a directory level again.\nProcedure #  Create Repository directory structure for new deployment.\nmkdir -p /opt/vmware/cplcm/cplcmrepo/{rmq/rmq_version-number/ova,usage/um_version-number/ova,vcd/vcd_version-number/ova,vropsta/vrops_version-number/ova}\nExample\n[user@localhost]$ mkdir -p /opt/vmware/cplcm/cplcmrepo/{rmq/3.8.14/ova,usage/4.3.0/ova,vcd/10.2.2/ova,vropsta/2.5.0/ova}\nCreate repository directory for product update files\nmkdir -p /opt/vmware/cplcm/cplcmrepo/{rmq/rmq_version-number/update,usage/um_version-number/update,vcd/vcd_version-number/update,vropsta/vrops_version-number/update}\nExample\n[user@localhost]$ mkdir -p /opt/vmware/cplcm/cplcmrepo/{rmq/3.8.14/update,usage/4.3.0/update,vcd/10.2.2/update,vropsta/2.5.0/update}\nThe directory structure is the following:\n\u0026lt;product type\u0026gt;/\u0026lt;version\u0026gt;/ova|update/\u0026lt;file\u0026gt;\nNote: The solution subdirectory specifies the version of the OVA or the patch.\nBelow is an example of the directory structure to be created:\nWhat to do next #  Copy the product OVA files to the corresponding repository directory on the VMware Cloud Provider Lifecycle Manager appliance.\nExample:\n  To obtain the OVA for VMware Cloud Director, go to https://my.vmware.com/\n  To obtain the OVA for vCloud Usage Meter, go to https://my.vmware.com.\n  To obtain the OVA for vRealize Operations Manager Tenant App, go to https:// marketplace.vmware.com/vsx/solutions/management-pack-for-vcloud-director#resources\n  To obtain the OVA for RabbitMQ, go to https://downloads.bitnami.com/files/stacks/rabbitmq/ 3.8.14-0/bitnami-rabbitmq-3.8.14-0-linux-debian-10-x86_64-nami.ova.\n  Mount an Existing Shared Directory to VMware Cloud Provider Lifecycle Manager #  You can mount an existing pre-configured repository directory to the VMware Cloud Provider Lifecycle Manager appliance.\nIf you do not specify the OVF property during the OVA deployment, after the deployment, you can configure the NFS by using the following commands.\nProcedure\n Configure the automatic mounting of the NFS share with VMware Cloud Provider Lifecycle Manager.   echo \u0026ldquo;nfs-server:nfs_dir_path/cplcmrepo nfs defaults 0 0\u0026rdquo; \u0026gt;\u0026gt; /etc/fstab\n  Mount the NFS share to VMware Cloud Provider Lifecycle Manager.   mount /cplcmrepo\n VMware Cloud Provider Lifecycle Manager Certificate Management #  Configure VMware Cloud provider API and UI certificates.\nVMware Cloud Provider Lifecycle Manager API Certificate Management #  After deploying the VMware Cloud Provider Lifecycle Manager appliance, VMware Cloud Provider Lifecycle Manager generates a self-signed certificates for the API and the internally used vault.\nYou can configure VMware Cloud Provider Lifecycle Manager to either use the self-signed certificate or your own custom certificate by providing a PKCS12 keystore containing the certificate.\nVMware Cloud Provider Lifecycle Manager stores the properties for the alias, keystore name, type and password in the /opt/vmware/cplcm/config/application.properties file. To change these settings, you must update the application.properties file.\nIn /etc/environment, you can set the keystore password for the custom certificate by configuring the CPLCM_KEYSTORE_PW environment variable. Alternatively, you can configure it in the application.properties file for the server.ssl.key-store-password property.\nVMware Cloud Provider Lifecycle Manager UI Certificate Management #  After deploying the VMware Cloud Provider Lifecycle Manager appliance, VMware Cloud Provider Lifecycle Manager generates a self-signed certificates for the UI.\nYou can configure VMware Cloud Provider Lifecycle Manager to either use the self-signed certificate or your own custom certificate by providing the custom certificate and key files in PEM format.\nVMware Cloud Provider Lifecycle Manager stores the files with the certificate and key under the /opt/vmware/cplcm/security/certs/ directory. To change the certificate, you must replace the vcplcm-gui.pem and vcplcm-gui.key files, and restart the nginx service.\nConfigure custom certificate on VMware Cloud Provider Lifecycle Manager #  You can configure VMware Cloud Provider Lifecycle Manager to use a custom certificate.\nTo configure a custom certificate on VMware Cloud Provider Lifecycle Manager, you must provide a PKCS12 keystore containing the certificate.\nProcedure\n Generate the custom certificate and create the keystore.  CPLCM_CERT_DIR=/opt/vmware/cplcm/security/certs\n mkdir -p $CPLCM_CERT_DIR\n key_alias=vcplcm\nkeystore_password=$CPLCM_KEYSTORE_PW\nsubj=\u0026quot;/CN=VCPLCM, O=VMware\\, Inc, c=US\u0026quot;\n openssl req -x509 -newkey rsa:4096 -subj \u0026ldquo;$subj\u0026rdquo; -keyout $CPLCM_CERT_DIR/tmpKey.pem -out $CPLCM_CERT_DIR/tmpCert.pem -days 365 -nodes\nopenssl pkcs12 -export -out $CPLCM_CERT_DIR/vcplcm.p12 -name $key_alias -passout \u0026ldquo;pass:$keystore_password\u0026rdquo; -inkey $CPLCM_CERT_DIR/tmpKey.pem -in $CPLCM_CERT_DIR/tmpCert.pem\n After importing the keystore, remove the tmp key and certificate.   rm $CPLCM_CERT_DIR/tmpKey.pem\nrm $CPLCM_CERT_DIR/tmpCert.pem\n Configure the Maximum Number of Threads VMware Cloud Provider Lifecycle Manager Can Run in Parallel #  You can configure the maximum thread number that VMware Cloud Provider Lifecycle Manager can run in parallel.\nThe best practice recommendation is to configure VMware Cloud Provider Lifecycle Manager to run up to five parallel threads. If you need to configure a value greater than five, first you must increase the CPU and memory of the VMware Cloud Provider Lifecycle Manager appliance.\nProcedure\n SSH to the VMware Cloud Provider Lifecycle Manager appliance console and log in as vcplcm. Navigate to the /opt/vmware/cplcm/config directory. cd /opt/vmware/cplcm/config Configure the maximum number of parallel threads.   Open the application.properties file for editing.   vi application.properties\n  Configure the maximum number of parallel threads by editing the value for the execution.max.thread.count parameter. By default, the value is set to 0. To configure a new value, you must use a numeric character. Save the application.properties file.   :wq!\n "},{"id":127,"href":"/docs/cloud-infrastructure/cplcm-deployment-subpage/","title":"Cplcm Deployment Subpage","section":"Cloud Infrastructure","content":"Deploy VMware Cloud Provider Lifecycle Manager #  Begin implementation of this solution by deploying VMware Cloud Provider Lifecycle Manager\nPrerequisites #  Verify that your environment fulfils the prerequisites for the deployment of VMware Cloud Provider Lifecycle Manager \u0026lt;\u0026lt;Link to overall Prerequisites.xls\u0026gt;\u0026gt;\nProcedure #  Configure Product Binaries for VMware Cloud provider Lifecycle Manager\nThe binaries (ova files) for deploying the supported products must be downloaded and provided to the VMware Cloud Provider Lifecycle Manager application.\nThe files can be downloaded locally to the VMware Cloud Provider Lifecycle Manager at /cplcmrepo directory or mounted as NFS share to the same path.Read More\nDeploy VMware Cloud Provider Lifecycle Manager On VMware Cloud Foundation\nDeploy VMware Cloud Provider Lifecycle Manager on VMware Cloud Foundation for automated deployment of products like VMware Cloud director, vRealize Operations manager Tenant App, Usage Meter and Rabbit MQ Read More\n"},{"id":128,"href":"/docs/cloud-infrastructure/cplcm-deployment/","title":"Cplcm Deployment","section":"Cloud Infrastructure","content":"Implementation of VMware Cloud Provider Lifecycle Manager #  Implementation of VMware Cloud provider Lifecycle Manager(cplcm) includes deployment of the necessary components like VMware Cloud Provider Lifecycle Manager Appliance, NFS share for storing product binaries in VMware Cloud Foundation for automated deployment of products like VMware Cloud Director, Usage Meter, vRealize Operations Tenant App and RabbitQ\nFor information on the VMware Cloud Provider Lifecycle Manager design, refer to the Detailed design of VMware Cloud Provider Lifecycle Manager section.\nPrerequisites #  Verify that your environment is configured according to Before You Apply This Guidance and the Planning and Preparation of VMware Cloud Provider Lifecycle Manager for VMware Cloud Foundation section.\nProcedure #   Deploy VMware Cloud Provider Lifecycle Manager\n"},{"id":129,"href":"/docs/cloud-infrastructure/Deploy-vmware-cloud-provider-lifecycle-manager-2/","title":"Deploy Vmware Cloud Provider Lifecycle Manager 2","section":"Cloud Infrastructure","content":"Deploy VMware Cloud Provider Lifecycle Manager #  Begin implementation of this solution by deploying VMware Cloud Provider Lifecycle Manager\nPrerequisites #  Verify that your environment fulfils the prerequisites for the deployment of VMware Cloud Provider Lifecycle Manager \u0026lt;\u0026lt;Link to overall Prerequisites.xls\u0026gt;\u0026gt;\nProcedure #  Deploy VMware Cloud Provider Lifecycle Manager On VMware Cloud Foundation\nDeploy VMware Cloud Provider Lifecycle Manager on VMware Cloud Foundation for automated deployment of products like VMware Cloud director, vRealize Operations manager Tenant App, Usage Meter and Rabbit MQ Read More\nConfigure VMware Cloud provider Lifecycle Manager\nAfter deploying the VMware Cloud Provider Lifecycle Manager appliance, you must configure the repositories for the product OVA files and the VMware Cloud Provider Lifecycle Manager certificate Read More\n"},{"id":130,"href":"/docs/cloud-infrastructure/nsx-t-dc-register/","title":"Nsx T Dc Register","section":"Cloud Infrastructure","content":"Register NSX-T Datacenter #  To enable VMware Cloud Provider Lifecycle Manager to manage products, first, you must register a datacenter component.\nThe datacenter components are instances or services available in the datacenter that VMware Cloud Provider Lifecycle Manager does not manage. You can register vCenter Server, NSX-T, and vRealize Operations Manager as datacenter components.\nRegister NSX-T #  API Procedure\n  Download \u0026amp; import Postman collection Read More\n  Authenticate Session ID Read More\n  Validate API version Read More\n  Create POST Request - To deploy one or several products, Datacenter needs to be registered. Registration of Datacenter can be done using the below POST request.\n   Method: POST\nURL: /api/{api version}/lcm/datacenter?action=REGISTER\nHeader: name: JSESSIONID – value: a valid jsessionid\nSample Bodies:\nVersion\nDataCenter Component Type:“NSX-T”\nFully Qualified Domain Name\nUsername\nPassword\n Retrieve Task Status #   To verify the status of a running task, a GET request must be executed.\nMethod: GET\nURL: /api/{apiVersion}/task/{taskId}\nHeader: name: JSESSIONID - value: a valid jsessionid\nSample response:\n{\n\u0026ldquo;id\u0026rdquo;: 6,\n\u0026ldquo;taskType\u0026rdquo;: \u0026ldquo;DATACENTER_REGISTER\u0026rdquo;,\n\u0026ldquo;subTasks\u0026rdquo;: {\n\u0026ldquo;58e91ae1-5203-481d-af0f-9d32ee64a5d4\u0026rdquo;: {\n\u0026ldquo;name\u0026rdquo;: \u0026ldquo;DataCenterRegisterStep-NSXT-3.2.0-DC_DISCOVER\u0026rdquo;,\n\u0026ldquo;status\u0026rdquo;: \u0026ldquo;SUCCESS\u0026rdquo;,\n\u0026ldquo;message\u0026rdquo;: [\n{\n\u0026ldquo;name\u0026rdquo;: \u0026ldquo;Discover product\u0026rdquo;,\n\u0026ldquo;status\u0026rdquo;: \u0026ldquo;OK\u0026rdquo;,\n\u0026ldquo;message\u0026rdquo;: \u0026ldquo;Successfully updated product state.\u0026rdquo;,\n\u0026ldquo;start_time\u0026rdquo;: \u0026ldquo;2022-08-20-10:12:38UTC\u0026rdquo;,\n\u0026ldquo;end_time\u0026rdquo;: \u0026ldquo;2022-08-20-10:12:39UTC\u0026rdquo;\n},\n{\n\u0026ldquo;name\u0026rdquo;: \u0026ldquo;Retrieve NSX-T certificate.\u0026rdquo;,\n\u0026ldquo;status\u0026rdquo;: \u0026ldquo;OK\u0026rdquo;,\n\u0026ldquo;message\u0026rdquo;: \u0026ldquo;Successfully retrieved certificate from NSX-T.\u0026rdquo;,\n\u0026ldquo;start_time\u0026rdquo;: \u0026ldquo;2022-08-20-10:12:38UTC\u0026rdquo;,\n\u0026ldquo;end_time\u0026rdquo;: \u0026ldquo;2022-08-20-10:12:38UTC\u0026rdquo;\n},\n{\n\u0026ldquo;name\u0026rdquo;: \u0026ldquo;Discover NSX-T transport zones.\u0026rdquo;,\n\u0026ldquo;status\u0026rdquo;: \u0026ldquo;OK\u0026rdquo;,\n\u0026ldquo;message\u0026rdquo;: \u0026ldquo;Successfully discovered NSX-T transport zones.\u0026rdquo;,\n\u0026ldquo;start_time\u0026rdquo;: \u0026ldquo;2022-08-20-10:12:38UTC\u0026rdquo;,\n\u0026ldquo;end_time\u0026rdquo;: \u0026ldquo;2022-08-20-10:12:39UTC\u0026rdquo;\n},\n{\n\u0026ldquo;name\u0026rdquo;: \u0026ldquo;Discover NSX-T T0 gateways.\u0026rdquo;,\n\u0026ldquo;status\u0026rdquo;: \u0026ldquo;OK\u0026rdquo;,\n\u0026ldquo;message\u0026rdquo;: \u0026ldquo;Successfully discover NSX-T T0 gateways.\u0026rdquo;,\n\u0026ldquo;start_time\u0026rdquo;: \u0026ldquo;2022-08-20-10:12:39UTC\u0026rdquo;,\n\u0026ldquo;end_time\u0026rdquo;: \u0026ldquo;2022-08-20-10:12:39UTC\u0026rdquo;\n}\n],\n\u0026ldquo;nextSubTasks\u0026rdquo;: {},\n\u0026ldquo;ignoreStatus\u0026rdquo;: false\n}\n},\n\u0026ldquo;environmentId\u0026rdquo;: \u0026ldquo;ref:dc:xxxxxxx_admin\u0026rdquo;,\n\u0026ldquo;taskName\u0026rdquo;: \u0026ldquo;DATACENTER_REGISTER_ref:xxxxxxxx_admin_6\u0026rdquo;,\n\u0026ldquo;status\u0026rdquo;: \u0026ldquo;SUCCESS\u0026rdquo;,\n\u0026ldquo;message\u0026rdquo;: \u0026ldquo;\u0026rdquo;,\n\u0026ldquo;next_tasks\u0026rdquo;: []\n Possible values for the status are:\n  IN_PROGRESS\n  SUCCESS\n  ERROR\n  Note. Please refer to the API reference and POSTMAN sample collection on code.vmware.com for APIs.\n  "},{"id":131,"href":"/docs/cloud-infrastructure/rabbitmq-deployment-subpage/","title":"Rabbitmq Deployment Subpage","section":"Cloud Infrastructure","content":"Deployment of RabbitMQ using VMware Cloud Provider Lifecycle Manager #  Multi-node RabbitMQ to be deployed using API feature of VMware Cloud provider Lifecycle Manager\nBegin implementation of this solution by deploying VMware Cloud Provider Lifecycle Manager\nPrerequisites #  Verify that your environment fulfils the prerequisites for the deployment of RabbitMQ\nProcedure #    Download Postman collection from vmware site\n  Import Postman Collection\n  Verify API version\n  Authenticate API session\n   Once the API version is defined, a JSESSIONID must be retrieved for further working with the REST API.\nThis is done by executing a call to the session endpoint:\nMethod: POST\nURL: https://VMware Cloud Provider Lifecycle Manager IP:9443/api/v1/session\nBody:\n{ \u0026quot;username\u0026quot;: \u0026quot;vcplcm\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;password\u0026quot; } Response:\nThe username and password must be provided in the JSON body to this request.\nThe username and password are defined, depending on the VMware Cloud Provider Lifecycle Manager configuration. At this point, this is defined as an environment variable in its runtime.\nThis session ID must be used for all subsequent API calls – provided as a header “JSESSIONID”.\n Register Datacenter   To enable VMware Cloud Provider Lifecycle Manager to manage products, first, you must register a datacenter component.\nThe datacenter components are instances or services available in the datacenter that VMware Cloud Provider Lifecycle Manager does not manage. You can register the below components for integration.\n   vCenter Server Read More\n  NSX-T Read More\n  vRealize Operations Manager Read More\n  Deploy RabbitMQ using API   Execute the respective API call from the postman Collection after changing the environment variables and parameters.Read More\n "},{"id":132,"href":"/docs/cloud-infrastructure/rabbitmq-deployment-using-api/","title":"Rabbitmq Deployment Using API","section":"Cloud Infrastructure","content":"Deploy RabbitMQ using API #  Execute the respective API call from the postman Collection after changing the environment variables and parameters.\nAPI Procedure #  To deploy one or several products, a Lifecycle Manager environment must be created. An environment can be created using the below POST request.\nMethod: POST\nURL: /api/{apiVersion}/lcm/environment?action=DEPLOY\nHeader: name: JSESSIONID – value: a valid jsessionid\nSample bodies #  Deploy RabbitMQ - API call at a high level #    Define Environment Name and ID\n  Products\n  Product Type\n  Product ID\n  RabbitMQ version\n  Admin password\n  Product Properties\n  RabbitMQ Load Balancer Name, FQDN and IP\n  RabbitMQ SSL and Management port details.\n  User (svc_vcd) credentials\n  User (svc_vropsta) credentials\n    Deployment\n  vCenter name and user\n  Datacenter\n  Cluster\n  Resource pool\n  Datastore\n    Node Information\n  Below details for all the RabbitMQ nodes need to be provided.\n Hostname, VM name, CPU, Memory, root password and network details.         Note: We don’t need to provide deployment infrastructure details like the earlier version as we are registering the datacenter first using the methods mentioned [Read More] and then proceeding with product deployment or management.\nNote: Please refer to the API reference and POSTMAN sample collection on code.vmware.com for detailed APIs.\nResponse\n{ \u0026quot;taskId\u0026quot;: \u0026quot;1\u0026quot; } If the response is OK (200), the request to create the environment has been accepted and is being processed asynchronously.\nThe returned taskId can now be used to check the status of the deployment.\n Retrieve Task Status #   To verify the status of a running task, a GET request must be executed.\nMethod: GET\nURL: /api/{apiVersion}/task/{taskId}\nHeader: name: JSESSIONID - value: a valid jsessionid\nSample response:\n{ \u0026quot;id\u0026quot;: 1, \u0026quot;subTasks\u0026quot;: { \u0026quot;c6765081-c5bf-4386-a3d8-498c84e8e497\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;LcmDiscoverStep-USAGE-4.4.0-DISCOVER\u0026quot;, \u0026quot;status\u0026quot;: \u0026quot;SUCCESS\u0026quot;, \u0026quot;message\u0026quot;: \\[ { \u0026quot;name\u0026quot;: \u0026quot;Discover product\u0026quot;, \u0026quot;status\u0026quot;: \u0026quot;OK\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;Successfully updated product state.\u0026quot;, \u0026quot;start_time\u0026quot;: \u0026quot;2021-04-08-15:23:06UTC\u0026quot;, \u0026quot;end_time\u0026quot;: \u0026quot;2021-04-08-15:23:55UTC\u0026quot; } \\], \u0026quot;nextSubTasks\u0026quot;: { \u0026quot;SUCCESS\u0026quot;: \u0026quot;28d7b09e-d16c-4dc3-ba98-17679b989b2f\u0026quot; } } }, \u0026quot;status\u0026quot;: \u0026quot;SUCCESS\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;\u0026quot; }  Possible values for the status are:\n  IN_PROGRESS\n  SUCCESS\n  ERROR\n   The message field of the task contains response messages from different steps of the task. For example, pre- and post-validation results are listed in the corresponding sub-section within the messages.\n Cancel a Task #  To cancel a running task, a PUT request must be executed.\nMethod: PUT\nURL: /api/{apiVersion}/task/{taskId}?action=cancel\nHeader: name: JSESSIONID - value: a valid jsessionid\nExpected response code: 200\n"},{"id":133,"href":"/docs/cloud-infrastructure/rabbitmq-deployment/","title":"Rabbitmq Deployment","section":"Cloud Infrastructure","content":"Implementation of RabbitMQ using VMware Cloud Provider Lifecycle Manager #  Implementation of RabbitMQ includes deployment of VMware Cloud Director on VMware Cloud Foundation using API feature of VMware Cloud Provider Lifecycle Manager\nFor information on the VMware Cloud Provider Lifecycle Manager design, refer to the Detailed design of RabbitMQ section.\nPrerequisites #  Verify that your environment is configured according to Before You Apply This Guidance and the Planning and Preparation of RabbitMQ section.\nProcedure #  Deployment of RabbitMQ using VMware Cloud Provider Lifecycle Manager\nMulti-node RabbitMQ to be deployed using API feature of VMware Cloud provider Lifecycle Manager Read More\n"},{"id":134,"href":"/docs/cloud-infrastructure/usagemeter-deployment-subpage/","title":"Usagemeter Deployment Subpage","section":"Cloud Infrastructure","content":"Deployment of Usage Meter using VMware Cloud Provider Lifecycle Manager #  Multi-node Usage Meter to be deployed using API feature of VMware Cloud provider Lifecycle Manager\nBegin implementation of this solution by deploying VMware Cloud Provider Lifecycle Manager\nPrerequisites #  Verify that your environment fulfils the prerequisites for the deployment of Usage Meter\nProcedure #    Download Postman collection from vmware site\n  Import Postman Collection\n  Verify API version\n  Authenticate API session\n   Once the API version is defined, a JSESSIONID must be retrieved for further working with the REST API.\nThis is done by executing a call to the session endpoint:\nMethod: POST\nURL: https://VMware Cloud Provider Lifecycle Manager IP:9443/api/v1/session\nBody:\n{ \u0026quot;username\u0026quot;: \u0026quot;vcplcm\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;password\u0026quot; } Response:\nThe username and password must be provided in the JSON body to this request.\nThe username and password are defined, depending on the VMware Cloud Provider Lifecycle Manager configuration. At this point, this is defined as an environment variable in its runtime.\nThis session ID must be used for all subsequent API calls – provided as a header “JSESSIONID”.\n Register Datacenter   To enable VMware Cloud Provider Lifecycle Manager to manage products, first, you must register a datacenter component.\nThe datacenter components are instances or services available in the datacenter that VMware Cloud Provider Lifecycle Manager does not manage. You can register the below components for integration.\n   vCenter Server Read More\n  NSX-T Read More\n  vRealize Operations Manager Read More\n  Deploy Usage Meter using API   Execute the respective API call from the postman Collection after changing the environment variables and parameters.Read More\n "},{"id":135,"href":"/docs/cloud-infrastructure/usagemeter-deployment-using-api/","title":"Usagemeter Deployment Using API","section":"Cloud Infrastructure","content":"Deploy Usage Meter using API #  Execute the respective API call from the postman Collection after changing the environment variables and parameters.\nAPI Procedure #  Usage Meter can be deployed as well using an API call, sample postman collection can be referred for the deployment.\nHowever, the product documentation needs to be followed for successful deployment.\nTo deploy one or several products, a Lifecycle Manager environment must be created. An environment can be created using the below POST request.\nMethod: POST\nURL: /api/{apiVersion}/lcm/environment?action=DEPLOY\nHeader: name: JSESSIONID – value: a valid jsessionid\nSample bodies #  Deploy Usage Meter - API call at a high level #    Define Environment Name and ID\n  Products\n  Properties:\n  Auditor password (password for UM auditor account, having read-only access to config and logs)\n  Proxy (Type, Host IP, port, user, and password)\n    Product Type\n  Product ID\n  Usage Meter version\n  Admin password\n  Deployment\n  vCenter name and user\n  Datacenter\n  Cluster\n  Resource pool\n  Datastore\n    Integrations\n  Provide Usage Meter-vCenter integration id, vCenter host details with admin login credentials\n  Usage Meter-NSX integration id and NSX host details with admin login credentials\n  Usage Meter-VMware Cloud Director integration id, VCD host details with login credentials.\n  Usage Meter-vRealize Operations Manager integration id, VROPs host and login credentials\n    Node Information\n Hostname, VM name, root password and network details like port group name, gateway, subnet mask, domain name, etc. of usage meter to be deployed.       **Note: **Usage Meter should be registered in VCP after deployment (and then re-run deployment to configure the collectors).\nWe don’t need to provide deployment infrastructure details like the earlier version as we are registering the datacenter first using the methods mentioned and then proceeding with product deployment or management.\nNote: Please refer to the API reference and POSTMAN sample collection on code.vmware.com for detailed APIs.\nResponse\n{\n \u0026ldquo;taskId\u0026rdquo;: \u0026ldquo;1\u0026rdquo;\n}\nIf the response is OK (200), the request to create the environment has been accepted and is being processed asynchronously.\nThe returned taskId can now be used to check the status of the deployment.\n Retrieve Task Status #   To verify the status of a running task, a GET request must be executed.\nMethod: GET\nURL:  /api/{apiVersion}/task/{taskId}\nHeader: name: JSESSIONID - value: a valid jsessionid\nSample response:\n{ \u0026quot;id\u0026quot;: 1, \u0026quot;subTasks\u0026quot;: { \u0026quot;c6765081-c5bf-4386-a3d8-498c84e8e497\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;LcmDiscoverStep-USAGE-4.4.0-DISCOVER\u0026quot;, \u0026quot;status\u0026quot;: \u0026quot;SUCCESS\u0026quot;, \u0026quot;message\u0026quot;: \\[ { \u0026quot;name\u0026quot;: \u0026quot;Discover product\u0026quot;, \u0026quot;status\u0026quot;: \u0026quot;OK\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;Successfully updated product state.\u0026quot;, \u0026quot;start_time\u0026quot;: \u0026quot;2021-04-08-15:23:06UTC\u0026quot;, \u0026quot;end_time\u0026quot;: \u0026quot;2021-04-08-15:23:55UTC\u0026quot; } \\], \u0026quot;nextSubTasks\u0026quot;: { \u0026quot;SUCCESS\u0026quot;: \u0026quot;28d7b09e-d16c-4dc3-ba98-17679b989b2f\u0026quot; } } }, \u0026quot;status\u0026quot;: \u0026quot;SUCCESS\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;\u0026quot; }  Possible values for the status are:\n  IN_PROGRESS\n  SUCCESS\n  ERROR\n   The message field of the task contains response messages from different steps of the task. For example, pre- and post-validation results are listed in the corresponding sub-section within the messages.\n Cancel a Task #  To cancel a running task, a PUT request must be executed.\nMethod: PUT\nURL: /api/{apiVersion}/task/{taskId}?action=cancel\nHeader: name: JSESSIONID - value: a valid jsessionid\nExpected response code: 200\n"},{"id":136,"href":"/docs/cloud-infrastructure/usagemeter-deployment/","title":"Usagemeter Deployment","section":"Cloud Infrastructure","content":"Implementation of Usage Meter using VMware Cloud Provider Lifecycle Manager #  Implementation of Usage Meter includes deployment of VMware Cloud Director on VMware Cloud Foundation using API feature of VMware Cloud Provider Lifecycle Manager\nFor information on the VMware Cloud Provider Lifecycle Manager design, refer to the Detailed design of Usage Meter section.\nPrerequisites #  Verify that your environment is configured according to Before You Apply This Guidance and the Planning and Preparation of Usage Meter section.\nProcedure #  Deployment of Usage Meter using VMware Cloud Provider Lifecycle Manager\nUsage Meter to be deployed using API feature of VMware Cloud provider Lifecycle Manager Read More\n"},{"id":137,"href":"/docs/cloud-infrastructure/vc-dc-register/","title":"VC Dc Register","section":"Cloud Infrastructure","content":"Register Datacenter #  To enable VMware Cloud Provider Lifecycle Manager to manage products, first, you must register a datacenter component.\nThe datacenter components are instances or services available in the datacenter that VMware Cloud Provider Lifecycle Manager does not manage. You can register vCenter Server, NSX-T, and vRealize Operations Manager as datacenter components.\nRegister a Datacenter Component #  Using th below steps you can register vCenter, NSX-T or vROPS as a datacenter Component.\nUI Procedure\n To access the VMware Cloud Provider Lifecycle Manager UI, navigate to https://vcplcmhost-name and login as vcplcm. In the top navigation bar, click Datacenters. Click Register Datacenter. Enter the information about the data center component.    Register Datacenter using JSON File\n Expand the Upload datacenter Component section and by clicking on Browse navigate to the JSON file containing the datacenter configuration details. Upload the JSON and click Next.\n To confirm the information about the datacenter component, expand the Datacenter Component section and click Next.\n    Register Datacenter without JSON File\n Expand the Upload datacenter component section and click Next. To enter the information about datacenter componenr, expand the Datacenter Component drction and click Next. (Optional) In the case of a vCenter Server, Expand the Network section and enter the network configuration details. Click Next.\n    (Optional) To validate the registration of the data center component, on the Complete datacenter setup tab, click Validate.\n To complete the registration of the data center component, on the Complete datacenter setup tab, click Register.\nOptionally, you can download the information about the data center as a JSON file. If the registration completes successfully, the UI displays a Success message and you can find information about the data center when you select Datacenters from the top navigation.  "},{"id":138,"href":"/docs/cloud-infrastructure/vcd-deploy-subpage/","title":"Vcd Deploy Subpage","section":"Cloud Infrastructure","content":"Deployment of VMware Cloud Director using VMware Cloud Provider Lifecycle Manager #  Multi-node VMware Cloud Director to be deployed using API feature of VMware Cloud provider Lifecycle Manager\nBegin implementation of this solution by deploying VMware Cloud Provider Lifecycle Manager\nPrerequisites #  Verify that your environment fulfils the prerequisites for the deployment of VMware Cloud Director.\nTo deploy a product by using the VMware Cloud Provider Lifecycle Manager UI, you must first register an infrastructure vCenter Server as data center component.\nThe datacenter components are instances or services available in the datacenter that VMware Cloud Provider Lifecycle Manager does not manage. You can register the below components for integration.\n  vCenter Server Read More\n  NSX-T Read More\n  vRealize Operations Manager Read More\n  Procedure #   To access the VMware Cloud Provider Lifecycle Manager UI, navigate to https://vcplcmhost-name and login as vcplcm. In the top navigation bar, click Environments. Click Create Environments. Enter the product deployment details and type as per the deployment workbook.    Deploy VMware Cloud Director using JSON file:\n Expand the Environment Details section and by clicking on Choose File navigate to the JSON file containing the datacenter configuration details. Upload the JSON and click Next.\n To verify and confirm the information about VMware Cloud Director to be deployed, go through the Datacenter and Datacenter Configurations section by clicking on Next.\n Verify the Cluster, Resource Pool, Datastore and Datacenter details as per JSON\n Also verify the Product, Node, Integrations Certificates details from respective sections.\n    Deploy VMware Cloud Director without JSON File:\n  Expand the Environment Details section, enter the environment name and environment type, and click Next.\nOptionally, you can enter an environment ID. If you do not specify an ID, VMware Cloud Provider Lifecycle Manager uses the product name as an environment ID.\n  In the Datacenter section, select the data center in which you want to deploy the product, and click Next.\n  In the Datacenter Configurations section, enter the data center configuration details and click Next.\n    Expand the Products tab and provide the product details in the respective sections as per the implementation workbook. To use the simplified product deployment method by providing only the general product information without specifiyng the product nodes, integrations, and certificates, turn on the hide settings toggle.\n Configure the product nodes.  Expand the Nodes tab. On the displayed node card, click Configure.\n Provide the node details and click OK.\n   Add a consecutive node, click Add a node and repeat step 6. (Refer the Implementation workbook for specification about the nodes). Expand the Integrations tab and configure an integration with other product as required and mentioned in implementation workbook.  Click Add integration. Enter the integration settings and click OK. Click Next.\n   Expand the Certificates tab and configure the product certificate as per implementation workbook.\nNote The certificate and private key must be in PEM format.  Click Add certificate. In the Adding new certificate dialog box, enter the certificate settings and click OK. Click Next.\n   On the Complete deployment setup tab, verify the product summary and select from the options.  Validate : Run a pre-deploy validation operation for the specified product. Deploy : Deploy a Product Register : Register a deployed product with VMware Cloud Provider Lifecycle Manager and enable day 2 operations. Download environment as JSON : Download the product information as a JSON file.\n    "},{"id":139,"href":"/docs/cloud-infrastructure/vcd-deployment-using-api/","title":"Vcd Deployment Using API","section":"Cloud Infrastructure","content":"Deploy VMware Cloud Director using API #  Execute the respective API call from the postman Collection after changing the environment variables and parameters.\nAPI Procedure #  To deploy one or several products, a Lifecycle Manager environment must be created. An environment can be created using the below POST request.\nMethod: POST\nURL: /api/{apiVersion}/lcm/environment?action=DEPLOY\nHeader: name: JSESSIONID – value: a valid jsessionid\nSample bodies #  Deploy VMware Cloud Director - API call at a high level #    Define Environment Name and ID\n  Products\n  VMware Cloud Director Installation ID\n  Product ID\n  License\n  Admin Password\n  Properties:\n  Deployment type- You can either specify Small, Medium, Large or Extra Large.\n  Installation ID\n  System Name\n  Cluster Failover Mode\n  Public Address\n  Console Proxy external address \u0026lt;Provide the Load Balancer IP which has been preconfigured as a part of pre-requisite\u0026gt;\n  REST API, HTTP and HTTPS address \u0026lt;Provide the Load Balancer IP which has been preconfigured as a part of pre-requisite\u0026gt;\n  Tenant portal external HTTP and HTTPS address \u0026lt;Provide the Load Balancer IP which has been preconfigured as a part of pre-requisite\u0026gt;\n    Admin username, email, and full name\n  NFS mount point details \u0026lt;Provide the NFS share path from VSAN FS\u0026gt;\n    Certificate details\n  HTTP/Console Proxy Management (VAMI and Database)\n  REST API\n  Tenant Portal\n    Deployment\n  Component name of the registered vCenter (in the format: vcHostname_username)\n  Datacenter\n  Cluster\n  Resource pool\n  Datastore\n    Integrations:\n  Provide VCD-vCenter integration id, vCenter host details with integration user login credentials\n Details about Provider VDC like description, hardware version, thin provisioning resource pool name, storage profile, network pool name, etc.(Optional)    VCD-NSX Integration ID and NSX host details with integration user login credentials.\n Details about Network Pool and VCD External Network.(Optional)    VCD to RabbitMQ Integration ID, RabbitMQ host details \u0026lt;Provide Load Balancer IP if using multiple nodes\u0026gt;\n  Integration user login credentials.\n  RabbitMQ host properties like SSL, prefix, etc.\n  Provide VCD Node details\n  Below details for all the VMware Cloud Director nodes need to be provided.\n  Hostname, VM name, root password\n  Deployment Option \u0026lt;For Primary \u0026amp; Standby nodes you can mention either “Small, Medium, Large or Extra Large” but for Application nodes, you need to mention “Cell”\u0026gt;\n  Network details for both the Network Interface as described above.\n             Note: We don’t need to provide deployment infrastructure details like the earlier version as we are registering the datacenter first using the methods mentioned and then proceeding with product deployment or management.\nNote: Please refer the API reference and POSTMAN sample collection on code.vmware.com for APIs.\nResponse\n{ \u0026quot;taskId\u0026quot;: \u0026quot;1\u0026quot; } If the response is OK (200), the request to create the environment has been accepted and is being processed asynchronously.\nThe returned taskId can now be used to check the status of the deployment.\n Retrieve Task Status #   To verify the status of a running task, a GET request must be executed.\nMethod: GET\nURL: /api/{apiVersion}/task/{taskId}\nHeader: name: JSESSIONID - value: a valid jsessionid\nSample response:\n{ \u0026quot;id\u0026quot;: 1, \u0026quot;subTasks\u0026quot;: { \u0026quot;c6765081-c5bf-4386-a3d8-498c84e8e497\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;LcmDiscoverStep-USAGE-4.4.0-DISCOVER\u0026quot;, \u0026quot;status\u0026quot;: \u0026quot;SUCCESS\u0026quot;, \u0026quot;message\u0026quot;: \\[ { \u0026quot;name\u0026quot;: \u0026quot;Discover product\u0026quot;, \u0026quot;status\u0026quot;: \u0026quot;OK\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;Successfully updated product state.\u0026quot;, \u0026quot;start_time\u0026quot;: \u0026quot;2021-04-08-15:23:06UTC\u0026quot;, \u0026quot;end_time\u0026quot;: \u0026quot;2021-04-08-15:23:55UTC\u0026quot; } \\], \u0026quot;nextSubTasks\u0026quot;: { \u0026quot;SUCCESS\u0026quot;: \u0026quot;28d7b09e-d16c-4dc3-ba98-17679b989b2f\u0026quot; } } }, \u0026quot;status\u0026quot;: \u0026quot;SUCCESS\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;\u0026quot; }  Possible values for the status are:\n  IN_PROGRESS\n  SUCCESS\n  ERROR\n   The message field of the task contains response messages from different steps of the task. For example, pre- and post-validation results are listed in the corresponding sub-section within the messages.\n Cancel a Task #  To cancel a running task, a PUT request must be executed.\nMethod: PUT\nURL: /api/{apiVersion}/task/{taskId}?action=cancel\nHeader: name: JSESSIONID - value: a valid jsessionid\nExpected response code: 200\n"},{"id":140,"href":"/docs/cloud-infrastructure/vcd-deployment/","title":"Vcd Deployment","section":"Cloud Infrastructure","content":"Implementation of VMware Cloud Director using VMware Cloud Provider Lifecycle Manager #  Implementation of VMware Cloud Director(VCD) includes deployment of VMware Cloud Director on VMware Cloud Foundation using API feature of VMware Cloud Provider Lifecycle Manager\nFor information on the VMware Cloud Provider Lifecycle Manager design, refer to the Detailed design of VMware Cloud Director section.\nPrerequisites #  Verify that your environment is configured according to Before You Apply This Guidance and the Planning and Preparation of VMware Cloud Director section.\nProcedure #  Deployment of VMware Cloud Director using VMware Cloud Provider Lifecycle Manager\nMulti-node VMware Cloud Director to be deployed using API feature of VMware Cloud provider Lifecycle Manager Read More\n"},{"id":141,"href":"/docs/cloud-infrastructure/vrops-dc-register/","title":"Vrops Dc Register","section":"Cloud Infrastructure","content":"Register Datacenter vRealize Operations Manager #  To enable VMware Cloud Provider Lifecycle Manager to manage products, first, you must register a datacenter component.\nThe datacenter components are instances or services available in the datacenter that VMware Cloud Provider Lifecycle Manager does not manage. You can register vCenter Server, NSX-T, and vRealize Operations Manager as datacenter components.\nRegister vROPS #  API Procedure\n  Download \u0026amp; import Postman collection Read More\n  Authenticate Session ID Read More\n  Validate API version Read More\n  Create POST Request - To deploy one or several products, Datacenter needs to be registered. Registration of Datacenter can be done using the below POST request.\n   Method: POST\nURL: /api/{api version}/lcm/datacenter?action=REGISTER\nHeader: name: JSESSIONID – value: a valid jsessionid\nSample Bodies:\nVersion\nDataCenter Component Type:“VROPS”\nFully Qualified Domain Name\nUsername\nPassword\n Retrieve Task Status #   To verify the status of a running task, a GET request must be executed.\nMethod: GET\nURL: /api/{apiVersion}/task/{taskId}\nHeader: name: JSESSIONID - value: a valid jsessionid\nSample response:\n{\n\u0026ldquo;id\u0026rdquo;: 4,\n\u0026ldquo;taskType\u0026rdquo;: \u0026ldquo;DATACENTER_REGISTER\u0026rdquo;,\n\u0026ldquo;subTasks\u0026rdquo;: {\n\u0026ldquo;4acdc9bc-4747-405b-acf7-ba5cb1655efe\u0026rdquo;: {\n\u0026ldquo;name\u0026rdquo;: \u0026ldquo;DataCenterRegisterStep-VROPS-8.6.0-DC_DISCOVER\u0026rdquo;,\n\u0026ldquo;status\u0026rdquo;: \u0026ldquo;SUCCESS\u0026rdquo;,\n\u0026ldquo;message\u0026rdquo;: [\n{\n\u0026ldquo;name\u0026rdquo;: \u0026ldquo;Discover product\u0026rdquo;,\n\u0026ldquo;status\u0026rdquo;: \u0026ldquo;OK\u0026rdquo;,\n\u0026ldquo;message\u0026rdquo;: \u0026ldquo;Successfully updated product state.\u0026rdquo;,\n\u0026ldquo;start_time\u0026rdquo;: \u0026ldquo;2022-08-20-09:17:41UTC\u0026rdquo;,\n\u0026ldquo;end_time\u0026rdquo;: \u0026ldquo;2022-08-20-09:17:41UTC\u0026rdquo;\n},\n{\n\u0026ldquo;name\u0026rdquo;: \u0026ldquo;Retrieve vROPS certificate.\u0026rdquo;,\n\u0026ldquo;status\u0026rdquo;: \u0026ldquo;OK\u0026rdquo;,\n\u0026ldquo;message\u0026rdquo;: \u0026ldquo;Successfully retrieved certificate from vROPS.\u0026rdquo;,\n\u0026ldquo;start_time\u0026rdquo;: \u0026ldquo;2022-08-20-09:17:41UTC\u0026rdquo;,\n\u0026ldquo;end_time\u0026rdquo;: \u0026ldquo;2022-08-20-09:17:41UTC\u0026rdquo;\n}\n],\n\u0026ldquo;nextSubTasks\u0026rdquo;: {},\n\u0026ldquo;ignoreStatus\u0026rdquo;: false\n}\n},\n\u0026ldquo;environmentId\u0026rdquo;: \u0026ldquo;ref:dc:xxxxxx_admin\u0026rdquo;,\n\u0026ldquo;taskName\u0026rdquo;: \u0026ldquo;DATACENTER_REGISTER_ref:dc:xxxxxx_admin_4\u0026rdquo;,\n\u0026ldquo;status\u0026rdquo;: \u0026ldquo;SUCCESS\u0026rdquo;,\n\u0026ldquo;message\u0026rdquo;: \u0026ldquo;\u0026rdquo;,\n\u0026ldquo;next_tasks\u0026rdquo;: []\n}\n Possible values for the status are:\n  IN_PROGRESS\n  SUCCESS\n  ERROR\n  Note. Please refer to the API reference and POSTMAN sample collection on code.vmware.com for APIs.\n  "},{"id":142,"href":"/docs/cloud-infrastructure/vrops-ta-deployment-subpage/","title":"Vrops Ta Deployment Subpage","section":"Cloud Infrastructure","content":"Deployment of vRealize Operations Tenant App using VMware Cloud Provider Lifecycle Manager #  Multi-node Usage Meter to be deployed using API feature of VMware Cloud provider Lifecycle Manager\nBegin implementation of this solution by deploying VMware Cloud Provider Lifecycle Manager\nPrerequisites #  Verify that your environment fulfils the prerequisites for the deployment of vRealize Operations Tenant App\nProcedure #    Download Postman collection from vmware site\n  Import Postman Collection\n  Verify API version\n  Authenticate API session\n   Once the API version is defined, a JSESSIONID must be retrieved for further working with the REST API.\nThis is done by executing a call to the session endpoint:\nMethod: POST\nURL: https://VMware Cloud Provider Lifecycle Manager IP:9443/api/v1/session\nBody:\n{ \u0026quot;username\u0026quot;: \u0026quot;vcplcm\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;password\u0026quot; } Response:\nThe username and password must be provided in the JSON body to this request.\nThe username and password are defined, depending on the VMware Cloud Provider Lifecycle Manager configuration. At this point, this is defined as an environment variable in its runtime.\nThis session ID must be used for all subsequent API calls – provided as a header “JSESSIONID”.\n Register Datacenter   To enable VMware Cloud Provider Lifecycle Manager to manage products, first, you must register a datacenter component.\nThe datacenter components are instances or services available in the datacenter that VMware Cloud Provider Lifecycle Manager does not manage. You can register the below components for integration.\n   vCenter Server Read More\n  NSX-T Read More\n  vRealize Operations Manager Read More\n  Deploy vRealize Operations Tenant App using API   Execute the respective API call from the postman Collection after changing the environment variables and parameters.Read More\n "},{"id":143,"href":"/docs/cloud-infrastructure/vropsta-deployment-using-api/","title":"Vropsta Deployment Using API","section":"Cloud Infrastructure","content":"Deploy vRealize Operations Tenant App using API #  Execute the respective API call from the postman Collection after changing the environment variables and parameters.\nAPI Procedure #  vRealize Operations Tenant App can be deployed as well using an API call, sample postman collection can be referred for the deployment.\nHowever, the product documentation needs to be followed for successful deployment.\nTo deploy one or several products, a Lifecycle Manager environment must be created. An environment can be created using the below POST request.\nMethod: POST\nURL: /api/{apiVersion}/lcm/environment?action=DEPLOY\nHeader: name: JSESSIONID – value: a valid jsessionid\nSample bodies #  Deploy vRealize Operations Tenant App - API call at a high level #    Define Environment Name and ID\n  Products\n  Product Type\n  Product ID\n  vRealize Operations Manager Tenant App version\n  Admin password\n  Deployment\n  vCenter name and user\n  Datacenter\n  Cluster\n  Resource pool\n  Datastore\n    Integrations:\n  Provide vROps TA-vROPs integration id, vROPs host details with login credentials\n  Provide vROps TA-VCD integration id, VCD host details with login credentials\n  Properties:\n  RabbitMQ host, port, and SSL details.\n  vROPs Tenant App Proxy URL\n  Credentials for VCD-RabbitMQ and vROPS TenantApp-RabbitMQ\n      Node Information\n Hostname, VM name, root password and network details of vRealize Operations Manager Tenant App to be deployed.       Note: The Environment ID in the API call is important and should be unique for all executions; although there can be multiple product deployments or tasks under one Environment ID, but it is advisable to keep it separate for each task. We don’t need to provide deployment infrastructure details like the earlier version as we are registering the datacenter first using the methods mentioned and then proceeding with product deployment or management.\nNote: Please refer the API reference and POSTMAN sample collection on code.vmware.com for APIs.\nResponse\n{ \u0026quot;taskId\u0026quot;: \u0026quot;1\u0026quot; } If the response is OK (200), the request to create the environment has been accepted and is being processed asynchronously.\nThe returned taskId can now be used to check the status of the deployment.\n Retrieve Task Status #   To verify the status of a running task, a GET request must be executed.\nMethod: GET\nURL: /api/{apiVersion}/task/{taskId} \nHeader: name: JSESSIONID - value: a valid jsessionid\nSample response:\n{ \u0026quot;id\u0026quot;: 1, \u0026quot;subTasks\u0026quot;: { \u0026quot;c6765081-c5bf-4386-a3d8-498c84e8e497\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;LcmDiscoverStep-USAGE-4.4.0-DISCOVER\u0026quot;, \u0026quot;status\u0026quot;: \u0026quot;SUCCESS\u0026quot;, \u0026quot;message\u0026quot;: \\[ { \u0026quot;name\u0026quot;: \u0026quot;Discover product\u0026quot;, \u0026quot;status\u0026quot;: \u0026quot;OK\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;Successfully updated product state.\u0026quot;, \u0026quot;start_time\u0026quot;: \u0026quot;2021-04-08-15:23:06UTC\u0026quot;, \u0026quot;end_time\u0026quot;: \u0026quot;2021-04-08-15:23:55UTC\u0026quot; } \\], \u0026quot;nextSubTasks\u0026quot;: { \u0026quot;SUCCESS\u0026quot;: \u0026quot;28d7b09e-d16c-4dc3-ba98-17679b989b2f\u0026quot; } } }, \u0026quot;status\u0026quot;: \u0026quot;SUCCESS\u0026quot;, \u0026quot;message\u0026quot;: \u0026quot;\u0026quot; }  Possible values for the status are:\n  IN_PROGRESS\n  SUCCESS\n  ERROR\n   The message field of the task contains response messages from different steps of the task. For example, pre- and post-validation results are listed in the corresponding sub-section within the messages.\n Cancel a Task #  To cancel a running task, a PUT request must be executed.\nMethod: PUT\nURL: /api/{apiVersion}/task/{taskId}?action=cancel\nHeader: name: JSESSIONID - value: a valid jsessionid\nExpected response code: 200\n"},{"id":144,"href":"/docs/cloud-infrastructure/vropsta-deployment/","title":"Vropsta Deployment","section":"Cloud Infrastructure","content":"Implementation of vRealize Operations Tenant App using VMware Cloud Provider Lifecycle Manager #  Implementation of vRealize Operations Tenant App includes deployment of VMware Cloud Director on VMware Cloud Foundation using API feature of VMware Cloud Provider Lifecycle Manager\nFor information on the VMware Cloud Provider Lifecycle Manager design, refer to the Detailed design of vRealize Operations Tenant App section.\nPrerequisites #  Verify that your environment is configured according to Before You Apply This Guidance and the Planning and Preparation of Usage Meter section.\nProcedure #  Deployment of vRealize Operations Tenant App using VMware Cloud Provider Lifecycle Manager\nUsage Meter to be deployed using API feature of VMware Cloud provider Lifecycle Manager Read More\n"},{"id":145,"href":"/docs/developer-ready-cloud/ose-ref-architecture/","title":"VMware Cloud Director Object Storage Extension Architecture Reference","section":"Developer Ready Cloud","content":"What is VMware Cloud Director Object Storage Extension? #  The VMware Cloud Director Object Storage Extension (OSE) allows VMware Cloud Providers who are using VMware Cloud Director to offer object storage services to their customers. The extension acts as middleware which is tightly integrated with VMware Cloud Director to abstract third-party S3 API compatible storage providers in a multi-tenant fashion. OSE runs externally to VMware Cloud Director and integrates through a UI plug-in, which shows either provider or tenant information, depending on the type of logged-in user.\nOSE has a 1:1 relationship with VMware Cloud Director, which means that only one instance of OSE can be integrated with a single Cloud Director. OSE 2.1.1 is compatible with VMware Cloud Director version 10.0 and later and the Cloud Director Service.\nAn instance of VMware Cloud Director Object Storage Extension can work with a single instance of VMware Cloud Director or a single VMware Cloud Director server group.\nObject Storage Extension can be connected to the following storage providers: Cloudian HyperStore, Dell EMC ECS, AWS S3, or another S3-compatible storage platform1. The provider can selectively enable VMware Cloud Director organizations to consume the service. The unique counterparts for organizations and users are created at the storage provider. The users authenticate to the service with VMware Cloud Director or S3 credentials and access it only through the UI plug-in. The provider can directly access the underlying storage appliance to set quotas or collect usage information for billing purposes.\nProviders can switch between storage platforms with VMware Cloud Director Object Storage Extension but cannot use two different storage platforms simultaneously.\nIn addition to the storage platform that OSE will connect with Cloud Director, three or more (for high availability and scalability) RHEL/CentOS/Oracle Linux/Ubuntu/Debian/Photon VM nodes that run OSE, provided as an RPM or DEB package, are required. The number of the OSE VM nodes depends on the used S3 storage and the OSE use case. See for reference: Deployment Options. These VMs are essentially stateless and persist all their data in PostgreSQL DB version from 10. x to 12.x. This could be VMware Cloud Director external PostgreSQL DB (if available) or a dedicated database for Mware Cloud Director Object Storage Extension depending on the OSE use case.\nVMware Cloud Director Object Storage Extension (OSE) enables Cloud Director tenant users to use object storage by native UI experience and support S3 clients to consume the object storage by S3 APIs.\nTo connect Cloud Director with the selected S3 object storage platform, OSE uses the following user mapping: • VMware Cloud Director service provider is mapped to an ECS/Cloudian admin user, or AWS management account. • VMware Cloud Director tenant is mapped to an ECS namespace, Cloudian group, or AWS org unit. • VMware Cloud Director user is mapped to an ECS/Cloudian user, or AWS IAM user.\nOther S3-compatible storage can be connected to Cloud Director through the Object Storage Interoperability Service (OSIS).\nUse Cases #  VMware Cloud Director natively provides Infrastructure as a Service (Iaas) by integrating with the underlying VMware vSphere platform. All native storage services such as storage for virtual machines, named (independent) disks, and catalog storage for virtual machine templates and media are using storage attached to vSphere ESXi hosts such as block storage, NFS, or VMware vSAN.\nThere is, however, the need for highly scalable, durable, and network-accessible storage that could be utilized by tenants or their workloads without the dependency on the vSphere layer. The VMware Cloud Director Object Storage Extension (OSE) provides access to the object storage either through VMware Cloud Director UI extension or via standardized S3 APIs. This allows existing applications to easily access this new type of storage for various use cases.\nStoring Unstructured Data #  Through the VMware Cloud Director User Interface, users can create storage buckets and upload and tag unstructured files (objects) of various types.\nThese files can be easily accessed with Uniform Resource Locator (URL) links or directly previewed from the OSE plug-in. For protection, versioning and object lock can be applied to the S3 bucket objects. Archived objects in AWS S3 buckets can also be restored, which is basically changing their status from archived to frequently accessed objects to view their content. The objects of Cloudian buckets can also be replicated across data centers by setting up an org-level storage policy or changing it individually per a tenant.\nPersistent Storage for Application #  Users can create application credentials with limited access to a specific bucket. This allows (stateless) applications running in VMware Cloud Director (or outside) to persist their content such as configurations, logs, or static data (web servers) into the object store. The application is using S3 API over the Internet to upload and retrieve object data.\nStoring vApp Templates and Catalog #  Because of the close integration with VMware Cloud Director, VMware Cloud Director Object Storage Extension can directly capture and restore a user’s VMware Cloud Director vApps. Users can also share these vApps with other users. Thus, VMware Cloud Director Object Storage Extension provides an additional tier of storage for vApp templates that can be used, for example, for archiving old images.\nBecause of the close integration with VMware Cloud Director, VMware Cloud Director Object Storage Extension can directly capture and restore a user’s VMware Cloud Director vApps. Users can also share these vApps with other users. Thus, VMware Cloud Director Object Storage Extension provides an additional tier of storage for vApp templates that can be used, for example, for archiving old images.\nAn entire VMware Cloud Director catalog (consisting of vApp templates and media ISO images) can be captured from an existing Org VCD catalog or created from scratch by uploading an individual ISO and OVA files to VMware Cloud Director Object Storage Extension. Then, the catalog can be published, which allows any VMware Cloud Director organization (from any VMware Cloud Director instance) to subscribe to the catalog. As a result, this OSE functionality enables easy distribution of specific catalogs publicly or geographically across VMware Cloud Director instances.\nKubernetes Cluster Backup and Restore #  In OSE 2.1.1, Kubernetes cluster backups complement the storage of unstructured data, vApps, and catalogs. With the Kubernetes cluster protection, tenants can back up their critical Kubernetes clusters and restore the backups in case of accidental removal of namespaces or a Kubernetes upgrade failure. Tenants can also use the Kubernetes cluster backup to replicate the cluster for debugging, development and staging before rolling their app out in production.\nArchitecture #  OSE is a standalone server running on a Linux machine and multi-node deployment. It exposes SSL port 443 as the public endpoint. Both OSE UI plugins and S3 client applications connect to OSE APIs on this port. OSE supports S3-compliant XML APIs and Amazon Signature V4 authentication. It\u0026rsquo;s primarily compatible with any S3 compliant clients.\nOSE connects to Cloud Director and the object storage cluster from the backend. OSE makes REST API calls to Cloud Director for tenant and user mapping for object storage. It also supports object storage-backed catalog contents and vApp backups. OSE connects to the object storage cluster for tenancy management and data transfer. Depending on the type of object storage cluster, there could be one port or multiple ports for the communication between OSE and the object storage cluster.\nOSE uses S3 API to make queries to the underlying S3 storage vendor and user identity and access management service to map Cloud Director user types with those of the connected storage.\nOSE also uses a PostgreSQL database to store metadata. All management data, bucket metadata, and object metadata are stored in the database. If your object storage solution is for internal use or a small business, you can consider re-using Cloud Director\u0026rsquo;s PostgreSQL appliance. For a standard deployment, you should consider deploying a standalone PostgreSQL server for OSE.\nThe bandwidth consumption between OSE and the object storage cluster is much higher than the communication between OSE and Cloud Director, so you should consider deploying OSE server nodes into the network with as little latency as the communication with the storage cluster.\nOSE also makes REST API calls to VMware Cloud Analytics to send product usage data. This part of the OSE architecture comes into play only if the tenants agree with the VMware Customer Experience Improvement Program (CEIP) in Cloud Director UI to allow VMware to collect data for analysis.\nOSE also uses a Kubernetes agent called Velero to backup and restore Kubernetes clusters on the underlying S3 storage. This OSE feature uses a deployer that enables the Cloud Director tenants to perform Helm operations to external Kubernetes clusters.\nOSE Catalogs use vSphere catalog synchronization protocol to sync with the content of the Cloud Director Catalogs.\nFor vApps, OSE uses REST API to export vApps from Cloud Director to the underlying S3 storage.\nDeployment Options #  Small Deployment #  Usage: Niche use cases •\tRequirement: Minimum resources required. High availability, supported for production. •\tOne or more RHEL/CentOS VMs for VMware Cloud Director. External PostgreSQL database (used for VMware Cloud Director and VMware Cloud Director Object Storage Extension). NFS transfer share is needed when more than one VMware Cloud Director cell is used. Protected with vSphere HA. •\tOne CentOS Linux 7 or 8/RedHat Enterprise Linux 7/Oracle Linux 7/Ubuntu 18+/Photon 3+/Debian 10+ VM: (4 vCPU, 8 GB RAM, 120 GB HDD) running VMware Cloud Director Object Storage Extension. Protected with vSphere HA. •\tvSphere/NSX: As required for VMware Cloud Director resources. •\tStorage provider: Three CentOS virtual machines running Cloudian HyperStore, or Five CentOS virtual machines running Dell EMC ECS (4 vCPUs, 32 GB RAM, 32+100 GB HDD on shared storage) or AWS S3. •\tLoad balancing: VMware Cloud Director cells and Cloudian HyperStore or Dell EMC ECS nodes load balancing provided by NSX.\nMedium Deployment #  Usage: typical use cases •\tRequirement: High availability, supported for production. •\tMultiple RHEL/CentOS or appliance VMs for VMware Cloud Director. NFS transfer share. For non-appliance form factor external PostgreSQL database. •\tOne or more CentOS Linux 7 or 8/RedHat Enterprise Linux 7/Oracle Linux 7/Ubuntu 18+/Photon 3+/Debian 10+ VMs: (8 vCPU, 8 GB RAM, 120 GB HDD) running VMware Cloud Director Object Storage Extension. Protected with vSphere HA and optionally load balanced. If VMware Cloud Director is deployed in appliance form factor, an external PostgreSQL database is needed. •\tvSphere/NSX: As required for VMware Cloud Director resources. •\tStorage provider: Three CentOS virtual machines running Cloudian HyperStore, Five CentOS virtual machines running Dell EMC ECS on dedicated ESXi hosts with local disks (8 vCPUs, 64 GB RAM, 32 GB HDD + multiple large local disks) or AWS S3. •\tLoad balancing: VMware Cloud Director cells and Cloudian HyperStore, or Dell EMC ECS nodes load balancing provided by NSX or external hardware load balancer.\nLarge Deployment #  Usage: large scale, low cost per GB use cases •\tRequirement: High scale, performance, and availability, supported for production. •\tMultiple RHEL/CentOS or appliance VMs for VMware Cloud Director. NFS transfer share. For non-appliance form factor external PostgreSQL database. •\tMultiple CentOS Linux 7 or 8/RedHat Enterprise Linux 7/Oracle Linux 7/Ubuntu 18+/Photon 3+/Debian 10+ VMs (12 vCPU, 12 GB RAM, 120 GB HDD) running VMware Cloud Director Object Storage Extension. If VMware Cloud Director is deployed in an appliance form factor, an external HA PostgreSQL database is needed. •\tvSphere/NSX: As required for VMware Cloud Director resources. •\tStorage provider: Three or more dedicated bare-metal physical Cloudian HyperStore, Five or more physical Dell EMC ECS, or AWS S3. •\tLoad balancing: an external hardware load balancer\nMulti-site Deployment #  Object Storage Extension supports VMware Cloud Director multisite deployments where different VMware Cloud Director instances are federated (associated) with a trust relationship. As these instances can be deployed in different locations, the end-users can deploy their applications with a higher level of resiliency and not be impacted by local datacenter outages.\nEach VMware Cloud Director instance has its own VMware Cloud Director Object Storage Extension, which communicates with shared S3 object storage deployed in a multi-datacenter configuration. Objects are automatically replicated across all data centers, and VMware Cloud Director users can access them through either VMware Cloud Director or VMware Cloud Director Object Storage Extension endpoint.\nWithin a multisite architecture, you can configure VMware Cloud Director Object Storage Extension instances with a standalone virtual data center in each site. The following diagram illustrates the architecture.\nWhen you configure the multisite feature, you create a cluster of multiple VMware Cloud Director Object Storage Extension instances to create an availability zone. You can group the VMware Cloud Director Object Storage Extension instances together only in a single region. A region is a collection of the compute resources in a geographic area. Regions are isolated and independent of one another. VMware Cloud Director Object Storage Extension does not support multi-region architectures.\nYou can share the same buckets and objects across tenant organizations within a multisite environment. To share buckets and objects across sites, map all tenant organizations to the same storage group. See Edit Tenant Mapping Configuration.\nConfiguration #  OSE Scalability #  OSE can be deployed as a cluster for high availability and distribution of hardware resources. In the typical deployment topology, there are multiple OSE instances, multiple storage platform instances, and the database HA.\nDeploying an OSE Cluster #  Taking Cloudian HyperStore as an example, the steps to deploy the OSE cluster are described below. Procedure\n Prepare the OSE hosts. Install the OSE rpm/deb package and start the OSE keeper. Prepare the PostgreSQL database and check if it is accessible from the OSE hosts. Prepare the Cloudian HyperStore nodes. Prepare the Cloudian HyperStore load balancer so that it is accessible from the OSE hosts.  Configuring a Single OSE Instance #  Procedure\n Follow these instructions to configure the OSE certificate, database, and Cloud Director UI plugin. Configure the connection to the Cloudian HyperStore Admin endpoint via the load balancer. ose cloudian admin set \u0026ndash;url hyperstore-lb-admin-url \u0026ndash;user admin-user \u0026ndash;secret \u0026lsquo;password\u0026rsquo; Configure the connection to the Cloudian HyperStore S3 endpoint via the load balancer. ose cloudian s3 set hyperstore-lb-s3-url Configure the connection to Cloudian HyperStore IAM endpoint via the load balancer. ose cloudian iam set hyperstore-lb-iam-url Configure the connection to the HyperStore Web Console via the load balancer. ose cloudian console set \u0026ndash;url hyperstore-lb-cmc-url \u0026ndash;user admin-user \u0026ndash;secret cmc-sso-shared-key Validate the configuration. ose config validate Start OSE. ose service start Log in to Cloud Director and launch OSE to check whether it works normally.  Replicating Configuration on OSE Nodes behind a Load Balancer #  Procedure\n Connect to the first OSE host. ssh user@host-ip Export the OSE configuration. ose config export \u0026ndash;file=\u0026ldquo;configuration-file-name\u0026rdquo; \u0026ndash;secret=\u0026ldquo;the password\u0026rdquo; Copy the exported configuration file to the VMs of the other OSE instances. SSH connect to the VMs of the other OSE instances and replicate the configuration by importing the configuration file. ose config import \u0026ndash;file=\u0026ldquo;path-to-the-configuration-file\u0026rdquo; \u0026ndash;secret=\u0026ldquo;the password\u0026rdquo; Restart the OSE keeper to make the configuration effective. systemctl restart voss-keeper  Now the OSE cluster is created. In general, OSE instances are stateless, and all data is persisted in the shared database, so it is possible to add more nodes on demand.\nOSE Java Service #  OSE Java service is built with Spring Boot, which offers both administrative and S3 APIs for OSE UI plug-in and S3 API users.\nFirst, the command ose service [start|stop] can launch and shut down the OSE Java service. The dedicated OSE CLI, e.g., ose cloudian admin set, can set basic configuration for the OSE service. The system administrator can also tune the OSE service with many other configurable properties by using the CLI command ose args set. Here are two examples. •\tTo make OSE work in virtual-hosted style for S3 API, use the command: ose args set -k s3.client.path.style.access -v false •\tFor a huge bucket (containing more than one hundred thousand objects), the object count for the bucket is estimated by default for performance consideration. The estimation can be turned off by the command: ose args set -k oss.object.count.estimate -v false As a Java service, the JVM properties can also be set for the OSE instance. In some cases, the storage platform could be in another network that is accessible by OSE through a configured proxy server. The system administrator can set the JVM proxy options for OSE by using the command: ose jvmargs -v \u0026ldquo;Dhttp.proxyHost=proxy.cloud.com -Dhttp.proxyPort=3128\u0026rdquo;\nPostgreSQL Database #  OSE uses a PostgreSQL database for storing the metadata of its S3 storage-related operations. The recommended hardware requirements for the database are 8 Core CPUs and 12 GB RAM for most OSE deployments. An impact on the database disk usage will have the object count, not the object content size. The more objects you create in the system, the more disk space the database occupies. Many factors determine disk space consumption. Roughly one million objects cost about 0.6GB disk. Database indexes and logs will also consume disk. So, assuming you have one billion objects in an object storage cluster, you need to prepare more than 700GB of disk for the database machine.\nThere is a table object_info in the OSE database containing rows for each managed object. If OSE handles twenty million objects, the table will have twenty million rows. Querying such a table could be a performance bottleneck if the database machine has limited CPU and memory resources.\nNow that we have the estimation for the database disk consumption with object count (about 0.6GB/million objects), it’s recommended to allocate a buffer for the disk size at the beginning.\nPublic S3 Endpoint #  S3-compliant API has two path formats: •\tPath-Style Requests. The path pattern for Amazon S3 is https://s3.Region.amazonaws.com/bucket-name/key name, for example, https://s3.us-west-2.amazonaws.com/mybucket/puppy.jpg. •\tVirtual Hosted-Style Requests. The path pattern for Amazon S3 is https://bucket-name.s3.Region.amazonaws.com/key name, for example https://my-bucket.s3.us-west-2.amazonaws.com/puppy.png. OSE supports both styles of S3 endpoint, but the segment region is not on the S3 URI; assumed your organization\u0026rsquo;s root FQDN is https://acme.com.\nTable 2: S3 API Path Formats\n   S3 API Path Formats Description Examples     Path Style The path-style S3 URI has /api/v1/s3 as the root path.     Any FQDN can work.\nBy default, OSE S3 API works in path-style. | https://storage.acme.com:443/api/v1/s3/bucket-1/dog.png\nhttps://storage.acme.com:443/api/v1/s3/bucket-2/cat.png | | Virtual-Hosted Style | The virtual-hosted style S3 URI has s3. on the FQDN.\nFQDN must use prefix s3. and support wildcard subdomains, i.e., s3.acme.com and *.s3.acme.com. | https://bucket-1.s3.acme.com:443/dog.png\nhttps://bucket-2.s3.acme.com:443/cat.png |\nThere are additional steps to make OSE work in a virtual-hosted style.\nProcedure\n Run the command to turn off the path style and switch to the virtual-hosted style: ose args set -k s3.client.path.style.access -v false Restart the ose service. ose service restart Configure wildcard DNS mapping for OSE S3 endpoint, i.e., map all *.s3.acme.com to the OSE load balancer. Create a wildcard SSL certificate for the wildcard FQDN, i.e., make a common name as *.s3.acme.com.   OSE Performance Settings #  The following settings can be applied to your OSE deployment to improve its performance.\nLogging #  The OSE logging level has an impact on the performance. To improve the performance, do not turn on the DEBUG logging. Besides, every request access is logged by default. It can be turned off as well. The following examples show how to set the logging level to WARN or turn off logging. After changing the log level or turning it off, you need to restart the OSE service. •\tSetting OSE logging level to WARN ose args set --k logging.level.com.vmware.voss --v WARN •\tTurning off OSE logging ose args set --k server.undertow.accesslog.enabled --v false •\tRestarting the OSE service ose service restart\nTune I/O Thread Count #  By default, the Undertow server creates server I/O threads per CPU cores on the OSE machine. See for reference: http://undertow.io/undertow-docs/undertow-docs-1.2.0/listeners.html. If needed, you can increase the I/O thread count to gain performance out of I/O. However, the number should not be too high. For example, if OSE has 8 cores with 1 socket for each host, the default I/O threads for OSE is 2 * 8 = 16. You can increase the number to 24 with the command below: ose args set --k server.undertow.threads.io --v 24\nTune the Worker Thread Count #  The default working thread count of Spring Boot is 8 * I/O threads for the embedded Undertow server. Increasing the working thread count to match the concurrency is recommended to fully utilize the server capacity for a high concurrency workload. ```ose args set \u0026ndash;k server.undertow.threads.worker \u0026ndash;v 256``\nSet Max Connection Count to Storage Platform #  Concurrent connections to storage platform S3 API directly impact the system\u0026rsquo;s scalability and throughput. By default, the max connection count is 1000. ose args set --k s3.client.max.connections --v 1000\nSet max Connection Count to the PostgreSQL Server #  Concurrent connections to the database directly impact the system\u0026rsquo;s scalability and throughput. By default, the max connection count is 90.\nNote: The below setting is insufficient to increase the concurrency of database connections. You should consider increasing the max connection count on the PostgreSQL side simultaneously. For example, if the PostgreSQL server\u0026rsquo;s max connection count is 1000, and you have deployed 5 OSE server nodes, then the average connection count to each OSE node should be less than the max connection count divided by the OSE node count, e.g., \u0026lt; 200.\nose args set --k spring.datasource.hikari.maximumPoolSize --v 180\nOther settings for the database connection pool can be seen below. For term explanation, please refer to https://github.com/brettwooldridge/HikariCP#configuration-knobs-baby.\nose args set --k spring.datasource.hikari.maxLifetime --v 1800000 ose args set --k spring.datasource.hikari.idleTimeout --v 600000 ose args set --k spring.datasource.hikari.connectionTimeout --v 30000\nSet Multipart Request Threshold for Upload OSE middleware automatically splits the upload content stream into several parts for large objects. Depending on the network performance between the OSE middleware and storage platform, the threshold can be re-configured. The default setting is when the upload object size is over 1 GB, the upload is split, and each part is \u0026lt;= 1GB size. ose args set --k s3.client.upload.multipart.threshold --v 1073741824 ose args set --k s3.client.upload.multipart.mini-part-size --v 1073741824 ose args set --k s3.client.copy.multipart.threshold --v 1073741824 ose args set --k s3.client.copy.multipart.mini-part-size --v 1073741824\nTurn off Tenant Server-side Encryption #  Tenant Server-side Encryption (SSE) is a unique feature of the OSE middleware. This feature can be turned off globally if you don\u0026rsquo;t need it, which will improve OSE performance. ose args set --k oss.tenant.sse.enabled --v false\nTurn on OSE Virtual-hosted Style S3 Requests #  By default, OSE works with path-style S3 requests. The command below will make OSE work with virtual-hosted style S3 requests. ose args set -k s3.client.path.style.access -v false\nTune Object Count of Bucket #  OSE has a feature showing tenant users the object count of each bucket. However, for buckets containing over 10 million objects, counting the bucket’s objects will impact the performance. Object count estimation is adopted for such buckets. The threshold is a hundred thousand objects per bucket. Use the following commands to adjust the threshold or turn off the estimation. •\tChanging the object count estimate threshold oss.object.count.estimate.threshold=100000 •\tTurning off the object count estimate ose args set -k oss.object.count.estimate -v false Set Proxy for OSE There are cases in which the storage platform is on another network that is accessible by OSE through a proxy server. You can set the JVM proxy options for OSE by using the following command. ose jvmargs -v \u0026quot;Dhttp.proxyHost=proxy.cloud.com -Dhttp.proxyPort=3128\u0026quot;\nGetting Support #  Generate Support Bundle #  OSE has a native CLI for support bundle, which will collect OSE information and logs of a specific period. See an example below: ose support --start 2020-03-12 --end 2020-05-24\nThe optional argument --start defines the start time for the logs to be collected. The default value is 2018-01-01.\nThe optional argument --end defines the end time for the logs to be collected. If not specified, the end date is the current date.\n"}]